
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-07-11 13:09:00.599143: do_dummy_2d_data_aug: False 
2025-07-11 13:09:00.601746: Using splits from existing split file: /home/finds/Finds_share/nnUNet_environment/nnUNet_preprocessed/Dataset999_drl/splits_final.json 
2025-07-11 13:09:00.602128: The split file contains 5 splits. 
2025-07-11 13:09:00.602153: Desired fold for training: 4 
2025-07-11 13:09:00.602169: This split has 746 training and 186 validation cases. 
2025-07-11 13:09:59.923101: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 8, 'patch_size': [256, 112, 80], 'median_image_size_in_voxels': [493.0, 148.0, 116.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset999_drl', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [493, 148, 116], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 65535.0, 'mean': 6488.5908203125, 'median': 3600.0, 'min': 0.0, 'percentile_00_5': 597.0, 'percentile_99_5': 31668.0, 'std': 6411.76708984375}}} 
 
2025-07-11 13:10:01.855612: unpacking dataset... 
2025-07-11 13:10:06.239870: unpacking done... 
2025-07-11 13:10:06.258101: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-07-11 13:10:06.315353:  
2025-07-11 13:10:06.315441: Epoch 0 
2025-07-11 13:10:06.315568: Current learning rate: 0.01 
2025-07-11 13:13:57.815763: train_loss -0.4362 
2025-07-11 13:13:57.815931: val_loss -0.5912 
2025-07-11 13:13:57.815969: Pseudo dice [0.7487] 
2025-07-11 13:13:57.816006: Epoch time: 231.5 s 
2025-07-11 13:13:57.816033: Yayy! New best EMA pseudo Dice: 0.7487 
2025-07-11 13:13:58.938693:  
2025-07-11 13:13:58.939051: Epoch 1 
2025-07-11 13:13:58.939144: Current learning rate: 0.00999 
2025-07-11 13:16:21.957980: train_loss -0.6159 
2025-07-11 13:16:21.958949: val_loss -0.6448 
2025-07-11 13:16:21.959031: Pseudo dice [0.7841] 
2025-07-11 13:16:21.959106: Epoch time: 143.02 s 
2025-07-11 13:16:21.959146: Yayy! New best EMA pseudo Dice: 0.7522 
2025-07-11 13:16:24.146003:  
2025-07-11 13:16:24.146261: Epoch 2 
2025-07-11 13:16:24.146359: Current learning rate: 0.00998 
2025-07-11 13:18:48.217843: train_loss -0.6206 
2025-07-11 13:18:48.219580: val_loss -0.6596 
2025-07-11 13:18:48.219698: Pseudo dice [0.8284] 
2025-07-11 13:18:48.219783: Epoch time: 144.07 s 
2025-07-11 13:18:48.219831: Yayy! New best EMA pseudo Dice: 0.7599 
2025-07-11 13:18:50.779245:  
2025-07-11 13:18:50.779764: Epoch 3 
2025-07-11 13:18:50.779959: Current learning rate: 0.00997 
2025-07-11 13:21:14.497446: train_loss -0.6343 
2025-07-11 13:21:14.499791: val_loss -0.6559 
2025-07-11 13:21:14.500590: Pseudo dice [0.8218] 
2025-07-11 13:21:14.500937: Epoch time: 143.72 s 
2025-07-11 13:21:14.501142: Yayy! New best EMA pseudo Dice: 0.766 
2025-07-11 13:21:17.844925:  
2025-07-11 13:21:17.845706: Epoch 4 
2025-07-11 13:21:17.846046: Current learning rate: 0.00996 
2025-07-11 13:23:41.097428: train_loss -0.6593 
2025-07-11 13:23:41.098223: val_loss -0.652 
2025-07-11 13:23:41.098340: Pseudo dice [0.8336] 
2025-07-11 13:23:41.098466: Epoch time: 143.25 s 
2025-07-11 13:23:41.098523: Yayy! New best EMA pseudo Dice: 0.7728 
2025-07-11 13:23:43.848038:  
2025-07-11 13:23:43.848519: Epoch 5 
2025-07-11 13:23:43.848686: Current learning rate: 0.00995 
2025-07-11 13:26:05.367362: train_loss -0.6608 
2025-07-11 13:26:05.368628: val_loss -0.663 
2025-07-11 13:26:05.371722: Pseudo dice [0.8187] 
2025-07-11 13:26:05.371829: Epoch time: 141.52 s 
2025-07-11 13:26:05.371888: Yayy! New best EMA pseudo Dice: 0.7774 
2025-07-11 13:26:08.615048:  
2025-07-11 13:26:08.615685: Epoch 6 
2025-07-11 13:26:08.615923: Current learning rate: 0.00995 
2025-07-11 13:28:33.484097: train_loss -0.667 
2025-07-11 13:28:33.485184: val_loss -0.6582 
2025-07-11 13:28:33.485264: Pseudo dice [0.8364] 
2025-07-11 13:28:33.485363: Epoch time: 144.87 s 
2025-07-11 13:28:33.485406: Yayy! New best EMA pseudo Dice: 0.7833 
2025-07-11 13:28:36.710600:  
2025-07-11 13:28:36.711071: Epoch 7 
2025-07-11 13:28:36.711267: Current learning rate: 0.00994 
2025-07-11 13:30:53.943101: train_loss -0.6699 
2025-07-11 13:30:53.944468: val_loss -0.7153 
2025-07-11 13:30:53.944570: Pseudo dice [0.8801] 
2025-07-11 13:30:53.944655: Epoch time: 137.23 s 
2025-07-11 13:30:53.944698: Yayy! New best EMA pseudo Dice: 0.793 
2025-07-11 13:30:57.535504:  
2025-07-11 13:30:57.536240: Epoch 8 
2025-07-11 13:30:57.536554: Current learning rate: 0.00993 
2025-07-11 13:33:19.237905: train_loss -0.6836 
2025-07-11 13:33:19.238916: val_loss -0.731 
2025-07-11 13:33:19.238994: Pseudo dice [0.8606] 
2025-07-11 13:33:19.239074: Epoch time: 141.7 s 
2025-07-11 13:33:19.239120: Yayy! New best EMA pseudo Dice: 0.7997 
2025-07-11 13:33:22.887104:  
2025-07-11 13:33:22.887247: Epoch 9 
2025-07-11 13:33:22.887342: Current learning rate: 0.00992 
2025-07-11 13:35:46.903268: train_loss -0.6777 
2025-07-11 13:35:46.905067: val_loss -0.7069 
2025-07-11 13:35:46.905167: Pseudo dice [0.8542] 
2025-07-11 13:35:46.905285: Epoch time: 144.02 s 
2025-07-11 13:35:46.905350: Yayy! New best EMA pseudo Dice: 0.8052 
2025-07-11 13:35:50.111382:  
2025-07-11 13:35:50.111926: Epoch 10 
2025-07-11 13:35:50.112094: Current learning rate: 0.00991 
2025-07-11 13:38:10.293848: train_loss -0.6811 
2025-07-11 13:38:10.295015: val_loss -0.666 
2025-07-11 13:38:10.295095: Pseudo dice [0.833] 
2025-07-11 13:38:10.295190: Epoch time: 140.18 s 
2025-07-11 13:38:10.295234: Yayy! New best EMA pseudo Dice: 0.808 
2025-07-11 13:38:13.803873:  
2025-07-11 13:38:13.804568: Epoch 11 
2025-07-11 13:38:13.804914: Current learning rate: 0.0099 
2025-07-11 13:40:33.842196: train_loss -0.6669 
2025-07-11 13:40:33.843820: val_loss -0.6641 
2025-07-11 13:40:33.843964: Pseudo dice [0.8468] 
2025-07-11 13:40:33.844084: Epoch time: 140.04 s 
2025-07-11 13:40:33.844136: Yayy! New best EMA pseudo Dice: 0.8119 
2025-07-11 13:40:37.031949:  
2025-07-11 13:40:37.032578: Epoch 12 
2025-07-11 13:40:37.032873: Current learning rate: 0.00989 
2025-07-11 13:42:57.626037: train_loss -0.6739 
2025-07-11 13:42:57.627945: val_loss -0.691 
2025-07-11 13:42:57.628416: Pseudo dice [0.8623] 
2025-07-11 13:42:57.628958: Epoch time: 140.6 s 
2025-07-11 13:42:57.629279: Yayy! New best EMA pseudo Dice: 0.8169 
2025-07-11 13:43:01.163167:  
2025-07-11 13:43:01.163909: Epoch 13 
2025-07-11 13:43:01.164326: Current learning rate: 0.00988 
2025-07-11 13:45:24.440081: train_loss -0.7025 
2025-07-11 13:45:24.441980: val_loss -0.7182 
2025-07-11 13:45:24.442218: Pseudo dice [0.8837] 
2025-07-11 13:45:24.442361: Epoch time: 143.28 s 
2025-07-11 13:45:24.442429: Yayy! New best EMA pseudo Dice: 0.8236 
2025-07-11 13:45:28.235530:  
2025-07-11 13:45:28.236223: Epoch 14 
2025-07-11 13:45:28.236570: Current learning rate: 0.00987 
2025-07-11 13:47:48.037404: train_loss -0.7006 
2025-07-11 13:47:48.038545: val_loss -0.7197 
2025-07-11 13:47:48.038627: Pseudo dice [0.8738] 
2025-07-11 13:47:48.038723: Epoch time: 139.8 s 
2025-07-11 13:47:48.038771: Yayy! New best EMA pseudo Dice: 0.8286 
2025-07-11 13:47:51.143219:  
2025-07-11 13:47:51.143935: Epoch 15 
2025-07-11 13:47:51.144182: Current learning rate: 0.00986 
2025-07-11 13:50:15.481797: train_loss -0.6943 
2025-07-11 13:50:15.483677: val_loss -0.7335 
2025-07-11 13:50:15.483940: Pseudo dice [0.8831] 
2025-07-11 13:50:15.484166: Epoch time: 144.34 s 
2025-07-11 13:50:15.484649: Yayy! New best EMA pseudo Dice: 0.834 
2025-07-11 13:50:18.499959:  
2025-07-11 13:50:18.500457: Epoch 16 
2025-07-11 13:50:18.500810: Current learning rate: 0.00986 
2025-07-11 13:52:42.829543: train_loss -0.7039 
2025-07-11 13:52:42.830597: val_loss -0.7168 
2025-07-11 13:52:42.830684: Pseudo dice [0.8524] 
2025-07-11 13:52:42.830778: Epoch time: 144.33 s 
2025-07-11 13:52:42.830826: Yayy! New best EMA pseudo Dice: 0.8359 
2025-07-11 13:52:45.802088:  
2025-07-11 13:52:45.802815: Epoch 17 
2025-07-11 13:52:45.803183: Current learning rate: 0.00985 
2025-07-11 13:55:06.000288: train_loss -0.7158 
2025-07-11 13:55:06.001621: val_loss -0.7632 
2025-07-11 13:55:06.001711: Pseudo dice [0.8959] 
2025-07-11 13:55:06.001804: Epoch time: 140.2 s 
2025-07-11 13:55:06.001848: Yayy! New best EMA pseudo Dice: 0.8419 
2025-07-11 13:55:09.618731:  
2025-07-11 13:55:09.619483: Epoch 18 
2025-07-11 13:55:09.619808: Current learning rate: 0.00984 
2025-07-11 13:57:33.676594: train_loss -0.718 
2025-07-11 13:57:33.677823: val_loss -0.7449 
2025-07-11 13:57:33.677917: Pseudo dice [0.885] 
2025-07-11 13:57:33.678022: Epoch time: 144.06 s 
2025-07-11 13:57:33.678075: Yayy! New best EMA pseudo Dice: 0.8462 
2025-07-11 13:57:37.224444:  
2025-07-11 13:57:37.225276: Epoch 19 
2025-07-11 13:57:37.225641: Current learning rate: 0.00983 
2025-07-11 13:59:59.536141: train_loss -0.6633 
2025-07-11 13:59:59.537639: val_loss -0.7009 
2025-07-11 13:59:59.537905: Pseudo dice [0.8489] 
2025-07-11 13:59:59.538147: Epoch time: 142.31 s 
2025-07-11 13:59:59.538302: Yayy! New best EMA pseudo Dice: 0.8465 
2025-07-11 14:00:02.693057:  
2025-07-11 14:00:02.693489: Epoch 20 
2025-07-11 14:00:02.693685: Current learning rate: 0.00982 
2025-07-11 14:02:25.336118: train_loss -0.702 
2025-07-11 14:02:25.337472: val_loss -0.688 
2025-07-11 14:02:25.337621: Pseudo dice [0.8583] 
2025-07-11 14:02:25.337771: Epoch time: 142.64 s 
2025-07-11 14:02:25.337856: Yayy! New best EMA pseudo Dice: 0.8477 
2025-07-11 14:02:28.153708:  
2025-07-11 14:02:28.154086: Epoch 21 
2025-07-11 14:02:28.154200: Current learning rate: 0.00981 
2025-07-11 14:04:50.445628: train_loss -0.7018 
2025-07-11 14:04:50.447904: val_loss -0.7054 
2025-07-11 14:04:50.448235: Pseudo dice [0.8667] 
2025-07-11 14:04:50.448517: Epoch time: 142.29 s 
2025-07-11 14:04:50.448922: Yayy! New best EMA pseudo Dice: 0.8496 
2025-07-11 14:04:53.244056:  
2025-07-11 14:04:53.244723: Epoch 22 
2025-07-11 14:04:53.245000: Current learning rate: 0.0098 
2025-07-11 14:07:18.791723: train_loss -0.7144 
2025-07-11 14:07:18.792526: val_loss -0.6839 
2025-07-11 14:07:18.792587: Pseudo dice [0.8829] 
2025-07-11 14:07:18.792653: Epoch time: 145.55 s 
2025-07-11 14:07:18.792693: Yayy! New best EMA pseudo Dice: 0.8529 
2025-07-11 14:07:21.378151:  
2025-07-11 14:07:21.378489: Epoch 23 
2025-07-11 14:07:21.378731: Current learning rate: 0.00979 
2025-07-11 14:09:43.423187: train_loss -0.7313 
2025-07-11 14:09:43.424828: val_loss -0.7265 
2025-07-11 14:09:43.425095: Pseudo dice [0.8903] 
2025-07-11 14:09:43.425331: Epoch time: 142.05 s 
2025-07-11 14:09:43.425505: Yayy! New best EMA pseudo Dice: 0.8566 
2025-07-11 14:09:46.633735:  
2025-07-11 14:09:46.634360: Epoch 24 
2025-07-11 14:09:46.634604: Current learning rate: 0.00978 
2025-07-11 14:12:13.291782: train_loss -0.71 
2025-07-11 14:12:13.296732: val_loss -0.7011 
2025-07-11 14:12:13.297483: Pseudo dice [0.8667] 
2025-07-11 14:12:13.297797: Epoch time: 146.66 s 
2025-07-11 14:12:13.298273: Yayy! New best EMA pseudo Dice: 0.8576 
2025-07-11 14:12:16.285112:  
2025-07-11 14:12:16.285586: Epoch 25 
2025-07-11 14:12:16.285763: Current learning rate: 0.00977 
2025-07-11 14:14:38.021290: train_loss -0.6998 
2025-07-11 14:14:38.023747: val_loss -0.7378 
2025-07-11 14:14:38.024353: Pseudo dice [0.8932] 
2025-07-11 14:14:38.024607: Epoch time: 141.74 s 
2025-07-11 14:14:38.024744: Yayy! New best EMA pseudo Dice: 0.8612 
2025-07-11 14:14:40.968145:  
2025-07-11 14:14:40.969026: Epoch 26 
2025-07-11 14:14:40.969398: Current learning rate: 0.00977 
2025-07-11 14:17:06.129499: train_loss -0.7269 
2025-07-11 14:17:06.131808: val_loss -0.7508 
2025-07-11 14:17:06.132059: Pseudo dice [0.8959] 
2025-07-11 14:17:06.132311: Epoch time: 145.16 s 
2025-07-11 14:17:06.132451: Yayy! New best EMA pseudo Dice: 0.8647 
2025-07-11 14:17:11.453106:  
2025-07-11 14:17:11.453439: Epoch 27 
2025-07-11 14:17:11.453506: Current learning rate: 0.00976 
2025-07-11 14:19:32.364829: train_loss -0.7158 
2025-07-11 14:19:32.366257: val_loss -0.7358 
2025-07-11 14:19:32.366427: Pseudo dice [0.8743] 
2025-07-11 14:19:32.366597: Epoch time: 140.91 s 
2025-07-11 14:19:32.370642: Yayy! New best EMA pseudo Dice: 0.8656 
2025-07-11 14:19:34.908729:  
2025-07-11 14:19:34.909505: Epoch 28 
2025-07-11 14:19:34.909808: Current learning rate: 0.00975 
2025-07-11 14:21:49.342320: train_loss -0.719 
2025-07-11 14:21:49.343331: val_loss -0.7398 
2025-07-11 14:21:49.343407: Pseudo dice [0.8827] 
2025-07-11 14:21:49.343499: Epoch time: 134.44 s 
2025-07-11 14:21:49.343543: Yayy! New best EMA pseudo Dice: 0.8673 
2025-07-11 14:21:52.695530:  
2025-07-11 14:21:52.696429: Epoch 29 
2025-07-11 14:21:52.696728: Current learning rate: 0.00974 
2025-07-11 14:24:18.030940: train_loss -0.7265 
2025-07-11 14:24:18.031852: val_loss -0.7745 
2025-07-11 14:24:18.032269: Pseudo dice [0.898] 
2025-07-11 14:24:18.032351: Epoch time: 145.34 s 
2025-07-11 14:24:18.032391: Yayy! New best EMA pseudo Dice: 0.8704 
2025-07-11 14:24:20.144406:  
2025-07-11 14:24:20.144857: Epoch 30 
2025-07-11 14:24:20.145024: Current learning rate: 0.00973 
2025-07-11 14:26:41.205086: train_loss -0.7176 
2025-07-11 14:26:41.206167: val_loss -0.7275 
2025-07-11 14:26:41.206242: Pseudo dice [0.8567] 
2025-07-11 14:26:41.206353: Epoch time: 141.06 s 
2025-07-11 14:26:43.132322:  
2025-07-11 14:26:43.133235: Epoch 31 
2025-07-11 14:26:43.133640: Current learning rate: 0.00972 
2025-07-11 14:29:08.058161: train_loss -0.7126 
2025-07-11 14:29:08.059139: val_loss -0.7302 
2025-07-11 14:29:08.059231: Pseudo dice [0.8768] 
2025-07-11 14:29:08.059382: Epoch time: 144.93 s 
2025-07-11 14:29:10.057098:  
2025-07-11 14:29:10.058100: Epoch 32 
2025-07-11 14:29:10.058571: Current learning rate: 0.00971 
2025-07-11 14:31:35.342587: train_loss -0.7344 
2025-07-11 14:31:35.344988: val_loss -0.7514 
2025-07-11 14:31:35.345061: Pseudo dice [0.902] 
2025-07-11 14:31:35.345161: Epoch time: 145.29 s 
2025-07-11 14:31:35.345224: Yayy! New best EMA pseudo Dice: 0.873 
2025-07-11 14:31:38.857934:  
2025-07-11 14:31:38.859029: Epoch 33 
2025-07-11 14:31:38.859478: Current learning rate: 0.0097 
2025-07-11 14:34:03.335358: train_loss -0.7386 
2025-07-11 14:34:03.336373: val_loss -0.7139 
2025-07-11 14:34:03.336451: Pseudo dice [0.8913] 
2025-07-11 14:34:03.336558: Epoch time: 144.48 s 
2025-07-11 14:34:03.336607: Yayy! New best EMA pseudo Dice: 0.8749 
2025-07-11 14:34:05.887009:  
2025-07-11 14:34:05.887424: Epoch 34 
2025-07-11 14:34:05.887560: Current learning rate: 0.00969 
2025-07-11 14:36:25.807856: train_loss -0.7242 
2025-07-11 14:36:25.809295: val_loss -0.7814 
2025-07-11 14:36:25.809386: Pseudo dice [0.8839] 
2025-07-11 14:36:25.809484: Epoch time: 139.92 s 
2025-07-11 14:36:25.809537: Yayy! New best EMA pseudo Dice: 0.8758 
2025-07-11 14:36:28.745710:  
2025-07-11 14:36:28.746238: Epoch 35 
2025-07-11 14:36:28.746434: Current learning rate: 0.00968 
2025-07-11 14:38:52.936219: train_loss -0.7218 
2025-07-11 14:38:52.938889: val_loss -0.7405 
2025-07-11 14:38:52.939523: Pseudo dice [0.8919] 
2025-07-11 14:38:52.939695: Epoch time: 144.19 s 
2025-07-11 14:38:52.939800: Yayy! New best EMA pseudo Dice: 0.8774 
2025-07-11 14:38:56.452249:  
2025-07-11 14:38:56.453065: Epoch 36 
2025-07-11 14:38:56.453443: Current learning rate: 0.00968 
2025-07-11 14:41:16.991719: train_loss -0.7337 
2025-07-11 14:41:16.993328: val_loss -0.7245 
2025-07-11 14:41:16.993602: Pseudo dice [0.8844] 
2025-07-11 14:41:16.993706: Epoch time: 140.54 s 
2025-07-11 14:41:16.993765: Yayy! New best EMA pseudo Dice: 0.8781 
2025-07-11 14:41:20.330965:  
2025-07-11 14:41:20.331442: Epoch 37 
2025-07-11 14:41:20.331653: Current learning rate: 0.00967 
2025-07-11 14:43:42.697511: train_loss -0.7253 
2025-07-11 14:43:42.698871: val_loss -0.7482 
2025-07-11 14:43:42.698957: Pseudo dice [0.8856] 
2025-07-11 14:43:42.699092: Epoch time: 142.37 s 
2025-07-11 14:43:42.699151: Yayy! New best EMA pseudo Dice: 0.8788 
2025-07-11 14:43:46.156035:  
2025-07-11 14:43:46.156912: Epoch 38 
2025-07-11 14:43:46.157261: Current learning rate: 0.00966 
2025-07-11 14:46:12.003715: train_loss -0.738 
2025-07-11 14:46:12.005026: val_loss -0.7603 
2025-07-11 14:46:12.005163: Pseudo dice [0.9072] 
2025-07-11 14:46:12.005296: Epoch time: 145.85 s 
2025-07-11 14:46:12.005399: Yayy! New best EMA pseudo Dice: 0.8817 
2025-07-11 14:46:15.380248:  
2025-07-11 14:46:15.380998: Epoch 39 
2025-07-11 14:46:15.381321: Current learning rate: 0.00965 
2025-07-11 14:48:37.901516: train_loss -0.7303 
2025-07-11 14:48:37.902842: val_loss -0.7626 
2025-07-11 14:48:37.902941: Pseudo dice [0.8959] 
2025-07-11 14:48:37.903039: Epoch time: 142.52 s 
2025-07-11 14:48:37.903101: Yayy! New best EMA pseudo Dice: 0.8831 
2025-07-11 14:48:41.455326:  
2025-07-11 14:48:41.456168: Epoch 40 
2025-07-11 14:48:41.456520: Current learning rate: 0.00964 
2025-07-11 14:51:04.533802: train_loss -0.7263 
2025-07-11 14:51:04.536771: val_loss -0.7259 
2025-07-11 14:51:04.538226: Pseudo dice [0.8888] 
2025-07-11 14:51:04.538625: Epoch time: 143.08 s 
2025-07-11 14:51:04.538704: Yayy! New best EMA pseudo Dice: 0.8837 
2025-07-11 14:51:07.760995:  
2025-07-11 14:51:07.761543: Epoch 41 
2025-07-11 14:51:07.761746: Current learning rate: 0.00963 
2025-07-11 14:53:25.997051: train_loss -0.7245 
2025-07-11 14:53:25.998528: val_loss -0.7496 
2025-07-11 14:53:25.998622: Pseudo dice [0.8922] 
2025-07-11 14:53:25.998765: Epoch time: 138.24 s 
2025-07-11 14:53:25.998859: Yayy! New best EMA pseudo Dice: 0.8845 
2025-07-11 14:53:29.595242:  
2025-07-11 14:53:29.596166: Epoch 42 
2025-07-11 14:53:29.596517: Current learning rate: 0.00962 
2025-07-11 14:55:56.988180: train_loss -0.7319 
2025-07-11 14:55:56.989079: val_loss -0.7316 
2025-07-11 14:55:56.989142: Pseudo dice [0.89] 
2025-07-11 14:55:56.989238: Epoch time: 147.4 s 
2025-07-11 14:55:56.989298: Yayy! New best EMA pseudo Dice: 0.8851 
2025-07-11 14:56:00.213163:  
2025-07-11 14:56:00.213824: Epoch 43 
2025-07-11 14:56:00.214207: Current learning rate: 0.00961 
2025-07-11 14:58:24.440029: train_loss -0.7386 
2025-07-11 14:58:24.440999: val_loss -0.728 
2025-07-11 14:58:24.441093: Pseudo dice [0.9096] 
2025-07-11 14:58:24.441185: Epoch time: 144.23 s 
2025-07-11 14:58:24.441233: Yayy! New best EMA pseudo Dice: 0.8875 
2025-07-11 14:58:26.799804:  
2025-07-11 14:58:26.800212: Epoch 44 
2025-07-11 14:58:26.800363: Current learning rate: 0.0096 
2025-07-11 15:00:51.180292: train_loss -0.726 
2025-07-11 15:00:51.181950: val_loss -0.7676 
2025-07-11 15:00:51.182332: Pseudo dice [0.903] 
2025-07-11 15:00:51.182551: Epoch time: 144.38 s 
2025-07-11 15:00:51.182701: Yayy! New best EMA pseudo Dice: 0.8891 
2025-07-11 15:00:54.926418:  
2025-07-11 15:00:54.926614: Epoch 45 
2025-07-11 15:00:54.926704: Current learning rate: 0.00959 
2025-07-11 15:03:16.638093: train_loss -0.7417 
2025-07-11 15:03:16.639220: val_loss -0.7493 
2025-07-11 15:03:16.639321: Pseudo dice [0.8948] 
2025-07-11 15:03:16.639426: Epoch time: 141.71 s 
2025-07-11 15:03:16.639489: Yayy! New best EMA pseudo Dice: 0.8896 
2025-07-11 15:03:19.194706:  
2025-07-11 15:03:19.195158: Epoch 46 
2025-07-11 15:03:19.195296: Current learning rate: 0.00959 
2025-07-11 15:05:42.621517: train_loss -0.7207 
2025-07-11 15:05:42.623136: val_loss -0.7128 
2025-07-11 15:05:42.623265: Pseudo dice [0.877] 
2025-07-11 15:05:42.623388: Epoch time: 143.43 s 
2025-07-11 15:05:44.200236:  
2025-07-11 15:05:44.200864: Epoch 47 
2025-07-11 15:05:44.201098: Current learning rate: 0.00958 
2025-07-11 15:08:07.053530: train_loss -0.7221 
2025-07-11 15:08:07.055110: val_loss -0.7369 
2025-07-11 15:08:07.055283: Pseudo dice [0.8914] 
2025-07-11 15:08:07.055490: Epoch time: 142.85 s 
2025-07-11 15:08:09.028114:  
2025-07-11 15:08:09.029025: Epoch 48 
2025-07-11 15:08:09.029393: Current learning rate: 0.00957 
2025-07-11 15:10:28.796146: train_loss -0.7347 
2025-07-11 15:10:28.800292: val_loss -0.6998 
2025-07-11 15:10:28.800909: Pseudo dice [0.8714] 
2025-07-11 15:10:28.801207: Epoch time: 139.77 s 
2025-07-11 15:10:30.925917:  
2025-07-11 15:10:30.927601: Epoch 49 
2025-07-11 15:10:30.928067: Current learning rate: 0.00956 
2025-07-11 15:12:55.513770: train_loss -0.7228 
2025-07-11 15:12:55.514885: val_loss -0.7342 
2025-07-11 15:12:55.514965: Pseudo dice [0.8989] 
2025-07-11 15:12:55.515051: Epoch time: 144.59 s 
2025-07-11 15:12:58.185555:  
2025-07-11 15:12:58.186237: Epoch 50 
2025-07-11 15:12:58.186526: Current learning rate: 0.00955 
2025-07-11 15:15:23.045273: train_loss -0.7267 
2025-07-11 15:15:23.046484: val_loss -0.7338 
2025-07-11 15:15:23.046581: Pseudo dice [0.8824] 
2025-07-11 15:15:23.046673: Epoch time: 144.86 s 
2025-07-11 15:15:24.681154:  
2025-07-11 15:15:24.682053: Epoch 51 
2025-07-11 15:15:24.682401: Current learning rate: 0.00954 
2025-07-11 15:17:47.621042: train_loss -0.7361 
2025-07-11 15:17:47.622285: val_loss -0.7503 
2025-07-11 15:17:47.622395: Pseudo dice [0.8973] 
2025-07-11 15:17:47.622539: Epoch time: 142.94 s 
2025-07-11 15:17:49.538176:  
2025-07-11 15:17:49.539151: Epoch 52 
2025-07-11 15:17:49.539582: Current learning rate: 0.00953 
2025-07-11 15:20:13.839847: train_loss -0.737 
2025-07-11 15:20:13.841021: val_loss -0.7338 
2025-07-11 15:20:13.841084: Pseudo dice [0.9101] 
2025-07-11 15:20:13.841159: Epoch time: 144.3 s 
2025-07-11 15:20:13.841211: Yayy! New best EMA pseudo Dice: 0.8907 
2025-07-11 15:20:16.174349:  
2025-07-11 15:20:16.174596: Epoch 53 
2025-07-11 15:20:16.174707: Current learning rate: 0.00952 
2025-07-11 15:22:38.518049: train_loss -0.7405 
2025-07-11 15:22:38.519911: val_loss -0.7661 
2025-07-11 15:22:38.520272: Pseudo dice [0.9142] 
2025-07-11 15:22:38.520481: Epoch time: 142.34 s 
2025-07-11 15:22:38.520668: Yayy! New best EMA pseudo Dice: 0.893 
2025-07-11 15:22:41.310531:  
2025-07-11 15:22:41.310862: Epoch 54 
2025-07-11 15:22:41.311010: Current learning rate: 0.00951 
2025-07-11 15:25:05.635337: train_loss -0.7226 
2025-07-11 15:25:05.636567: val_loss -0.7461 
2025-07-11 15:25:05.636700: Pseudo dice [0.8946] 
2025-07-11 15:25:05.636821: Epoch time: 144.33 s 
2025-07-11 15:25:05.636889: Yayy! New best EMA pseudo Dice: 0.8932 
2025-07-11 15:25:08.343524:  
2025-07-11 15:25:08.343887: Epoch 55 
2025-07-11 15:25:08.344057: Current learning rate: 0.0095 
2025-07-11 15:27:28.148541: train_loss -0.7319 
2025-07-11 15:27:28.149593: val_loss -0.7767 
2025-07-11 15:27:28.149665: Pseudo dice [0.9067] 
2025-07-11 15:27:28.149739: Epoch time: 139.81 s 
2025-07-11 15:27:28.149778: Yayy! New best EMA pseudo Dice: 0.8945 
2025-07-11 15:27:31.100440:  
2025-07-11 15:27:31.100817: Epoch 56 
2025-07-11 15:27:31.100947: Current learning rate: 0.00949 
2025-07-11 15:29:55.993091: train_loss -0.7389 
2025-07-11 15:29:55.994226: val_loss -0.7484 
2025-07-11 15:29:55.994303: Pseudo dice [0.8896] 
2025-07-11 15:29:55.994391: Epoch time: 144.89 s 
2025-07-11 15:29:57.362019:  
2025-07-11 15:29:57.362660: Epoch 57 
2025-07-11 15:29:57.362865: Current learning rate: 0.00949 
2025-07-11 15:32:19.782370: train_loss -0.7375 
2025-07-11 15:32:19.783936: val_loss -0.7477 
2025-07-11 15:32:19.784245: Pseudo dice [0.9136] 
2025-07-11 15:32:19.784560: Epoch time: 142.42 s 
2025-07-11 15:32:19.784731: Yayy! New best EMA pseudo Dice: 0.896 
2025-07-11 15:32:22.059736:  
2025-07-11 15:32:22.060121: Epoch 58 
2025-07-11 15:32:22.060213: Current learning rate: 0.00948 
2025-07-11 15:34:43.167824: train_loss -0.7153 
2025-07-11 15:34:43.170116: val_loss -0.7313 
2025-07-11 15:34:43.170610: Pseudo dice [0.8855] 
2025-07-11 15:34:43.170950: Epoch time: 141.11 s 
2025-07-11 15:34:45.096441:  
2025-07-11 15:34:45.097414: Epoch 59 
2025-07-11 15:34:45.097857: Current learning rate: 0.00947 
2025-07-11 15:37:06.996273: train_loss -0.7348 
2025-07-11 15:37:06.997244: val_loss -0.7556 
2025-07-11 15:37:06.997410: Pseudo dice [0.9015] 
2025-07-11 15:37:06.997505: Epoch time: 141.9 s 
2025-07-11 15:37:08.711959:  
2025-07-11 15:37:08.713000: Epoch 60 
2025-07-11 15:37:08.713344: Current learning rate: 0.00946 
2025-07-11 15:39:36.548457: train_loss -0.7401 
2025-07-11 15:39:36.549713: val_loss -0.7333 
2025-07-11 15:39:36.549789: Pseudo dice [0.8989] 
2025-07-11 15:39:36.549896: Epoch time: 147.84 s 
2025-07-11 15:39:38.171313:  
2025-07-11 15:39:38.171775: Epoch 61 
2025-07-11 15:39:38.172000: Current learning rate: 0.00945 
2025-07-11 15:42:01.183512: train_loss -0.742 
2025-07-11 15:42:01.184751: val_loss -0.7545 
2025-07-11 15:42:01.184914: Pseudo dice [0.9106] 
2025-07-11 15:42:01.185014: Epoch time: 143.01 s 
2025-07-11 15:42:01.185069: Yayy! New best EMA pseudo Dice: 0.8974 
2025-07-11 15:42:04.860841:  
2025-07-11 15:42:04.861632: Epoch 62 
2025-07-11 15:42:04.862130: Current learning rate: 0.00944 
2025-07-11 15:44:28.659006: train_loss -0.7347 
2025-07-11 15:44:28.659992: val_loss -0.7864 
2025-07-11 15:44:28.660066: Pseudo dice [0.8981] 
2025-07-11 15:44:28.660144: Epoch time: 143.8 s 
2025-07-11 15:44:28.660185: Yayy! New best EMA pseudo Dice: 0.8975 
2025-07-11 15:44:31.050373:  
2025-07-11 15:44:31.050720: Epoch 63 
2025-07-11 15:44:31.050812: Current learning rate: 0.00943 
2025-07-11 15:46:52.065204: train_loss -0.7474 
2025-07-11 15:46:52.067351: val_loss -0.7556 
2025-07-11 15:46:52.067546: Pseudo dice [0.9048] 
2025-07-11 15:46:52.067707: Epoch time: 141.02 s 
2025-07-11 15:46:52.067856: Yayy! New best EMA pseudo Dice: 0.8982 
2025-07-11 15:46:55.923444:  
2025-07-11 15:46:55.923671: Epoch 64 
2025-07-11 15:46:55.923784: Current learning rate: 0.00942 
2025-07-11 15:49:16.128616: train_loss -0.7385 
2025-07-11 15:49:16.130096: val_loss -0.786 
2025-07-11 15:49:16.130208: Pseudo dice [0.9097] 
2025-07-11 15:49:16.130364: Epoch time: 140.21 s 
2025-07-11 15:49:16.130449: Yayy! New best EMA pseudo Dice: 0.8993 
2025-07-11 15:49:19.737422:  
2025-07-11 15:49:19.738437: Epoch 65 
2025-07-11 15:49:19.738772: Current learning rate: 0.00941 
2025-07-11 15:51:43.724786: train_loss -0.7422 
2025-07-11 15:51:43.726111: val_loss -0.7453 
2025-07-11 15:51:43.726197: Pseudo dice [0.8861] 
2025-07-11 15:51:43.726293: Epoch time: 143.99 s 
2025-07-11 15:51:45.710808:  
2025-07-11 15:51:45.711669: Epoch 66 
2025-07-11 15:51:45.712003: Current learning rate: 0.0094 
2025-07-11 15:54:07.470145: train_loss -0.731 
2025-07-11 15:54:07.471482: val_loss -0.7508 
2025-07-11 15:54:07.471560: Pseudo dice [0.8996] 
2025-07-11 15:54:07.471636: Epoch time: 141.76 s 
2025-07-11 15:54:09.211413:  
2025-07-11 15:54:09.212265: Epoch 67 
2025-07-11 15:54:09.212637: Current learning rate: 0.00939 
2025-07-11 15:56:31.256131: train_loss -0.7463 
2025-07-11 15:56:31.257401: val_loss -0.7342 
2025-07-11 15:56:31.257588: Pseudo dice [0.9145] 
2025-07-11 15:56:31.257694: Epoch time: 142.05 s 
2025-07-11 15:56:31.257747: Yayy! New best EMA pseudo Dice: 0.8998 
2025-07-11 15:56:34.672062:  
2025-07-11 15:56:34.672760: Epoch 68 
2025-07-11 15:56:34.673002: Current learning rate: 0.00939 
2025-07-11 15:58:58.342221: train_loss -0.7415 
2025-07-11 15:58:58.343067: val_loss -0.7554 
2025-07-11 15:58:58.343131: Pseudo dice [0.8986] 
2025-07-11 15:58:58.343235: Epoch time: 143.67 s 
2025-07-11 15:58:59.836787:  
2025-07-11 15:58:59.837498: Epoch 69 
2025-07-11 15:58:59.837784: Current learning rate: 0.00938 
2025-07-11 16:01:22.834841: train_loss -0.7301 
2025-07-11 16:01:22.836212: val_loss -0.7525 
2025-07-11 16:01:22.836342: Pseudo dice [0.9046] 
2025-07-11 16:01:22.836451: Epoch time: 143.0 s 
2025-07-11 16:01:22.836527: Yayy! New best EMA pseudo Dice: 0.9002 
2025-07-11 16:01:26.260317:  
2025-07-11 16:01:26.261097: Epoch 70 
2025-07-11 16:01:26.261461: Current learning rate: 0.00937 
2025-07-11 16:03:48.435599: train_loss -0.7371 
2025-07-11 16:03:48.437819: val_loss -0.7414 
2025-07-11 16:03:48.438257: Pseudo dice [0.8982] 
2025-07-11 16:03:48.438630: Epoch time: 142.18 s 
2025-07-11 16:03:50.590434:  
2025-07-11 16:03:50.591390: Epoch 71 
2025-07-11 16:03:50.591846: Current learning rate: 0.00936 
2025-07-11 16:06:17.947129: train_loss -0.7364 
2025-07-11 16:06:17.948422: val_loss -0.755 
2025-07-11 16:06:17.948529: Pseudo dice [0.9054] 
2025-07-11 16:06:17.948626: Epoch time: 147.36 s 
2025-07-11 16:06:17.948681: Yayy! New best EMA pseudo Dice: 0.9005 
2025-07-11 16:06:21.028431:  
2025-07-11 16:06:21.029339: Epoch 72 
2025-07-11 16:06:21.029690: Current learning rate: 0.00935 
2025-07-11 16:08:42.977217: train_loss -0.7368 
2025-07-11 16:08:42.978481: val_loss -0.7428 
2025-07-11 16:08:42.978561: Pseudo dice [0.9093] 
2025-07-11 16:08:42.978656: Epoch time: 141.95 s 
2025-07-11 16:08:42.978710: Yayy! New best EMA pseudo Dice: 0.9014 
2025-07-11 16:08:46.307265:  
2025-07-11 16:08:46.307611: Epoch 73 
2025-07-11 16:08:46.307780: Current learning rate: 0.00934 
2025-07-11 16:11:09.547903: train_loss -0.7269 
2025-07-11 16:11:09.549706: val_loss -0.7356 
2025-07-11 16:11:09.549791: Pseudo dice [0.9067] 
2025-07-11 16:11:09.549879: Epoch time: 143.24 s 
2025-07-11 16:11:09.549929: Yayy! New best EMA pseudo Dice: 0.9019 
2025-07-11 16:11:12.815836:  
2025-07-11 16:11:12.816493: Epoch 74 
2025-07-11 16:11:12.816825: Current learning rate: 0.00933 
2025-07-11 16:13:32.918126: train_loss -0.7405 
2025-07-11 16:13:32.919120: val_loss -0.7649 
2025-07-11 16:13:32.919201: Pseudo dice [0.9121] 
2025-07-11 16:13:32.919296: Epoch time: 140.1 s 
2025-07-11 16:13:32.919338: Yayy! New best EMA pseudo Dice: 0.903 
2025-07-11 16:13:36.550262:  
2025-07-11 16:13:36.551102: Epoch 75 
2025-07-11 16:13:36.551567: Current learning rate: 0.00932 
2025-07-11 16:16:03.889914: train_loss -0.7475 
2025-07-11 16:16:03.891238: val_loss -0.7712 
2025-07-11 16:16:03.891378: Pseudo dice [0.9153] 
2025-07-11 16:16:03.891475: Epoch time: 147.34 s 
2025-07-11 16:16:03.891540: Yayy! New best EMA pseudo Dice: 0.9042 
2025-07-11 16:16:06.897950:  
2025-07-11 16:16:06.898344: Epoch 76 
2025-07-11 16:16:06.898474: Current learning rate: 0.00931 
2025-07-11 16:18:28.930318: train_loss -0.7488 
2025-07-11 16:18:28.931329: val_loss -0.7782 
2025-07-11 16:18:28.931418: Pseudo dice [0.9114] 
2025-07-11 16:18:28.931519: Epoch time: 142.03 s 
2025-07-11 16:18:28.931571: Yayy! New best EMA pseudo Dice: 0.9049 
2025-07-11 16:18:32.346291:  
2025-07-11 16:18:32.347028: Epoch 77 
2025-07-11 16:18:32.347397: Current learning rate: 0.0093 
2025-07-11 16:20:54.263709: train_loss -0.7422 
2025-07-11 16:20:54.264676: val_loss -0.7492 
2025-07-11 16:20:54.264758: Pseudo dice [0.9065] 
2025-07-11 16:20:54.264841: Epoch time: 141.92 s 
2025-07-11 16:20:54.264884: Yayy! New best EMA pseudo Dice: 0.9051 
2025-07-11 16:20:57.040396:  
2025-07-11 16:20:57.040740: Epoch 78 
2025-07-11 16:20:57.040887: Current learning rate: 0.0093 
2025-07-11 16:23:20.052339: train_loss -0.7616 
2025-07-11 16:23:20.053377: val_loss -0.7346 
2025-07-11 16:23:20.053449: Pseudo dice [0.9114] 
2025-07-11 16:23:20.053525: Epoch time: 143.01 s 
2025-07-11 16:23:20.053565: Yayy! New best EMA pseudo Dice: 0.9057 
2025-07-11 16:23:23.041063:  
2025-07-11 16:23:23.041363: Epoch 79 
2025-07-11 16:23:23.041528: Current learning rate: 0.00929 
2025-07-11 16:25:45.191741: train_loss -0.7431 
2025-07-11 16:25:45.192979: val_loss -0.7533 
2025-07-11 16:25:45.193078: Pseudo dice [0.9136] 
2025-07-11 16:25:45.193241: Epoch time: 142.15 s 
2025-07-11 16:25:45.193308: Yayy! New best EMA pseudo Dice: 0.9065 
2025-07-11 16:25:48.385121:  
2025-07-11 16:25:48.385998: Epoch 80 
2025-07-11 16:25:48.386282: Current learning rate: 0.00928 
2025-07-11 16:28:09.757587: train_loss -0.7542 
2025-07-11 16:28:09.758764: val_loss -0.7728 
2025-07-11 16:28:09.759029: Pseudo dice [0.9121] 
2025-07-11 16:28:09.759124: Epoch time: 141.37 s 
2025-07-11 16:28:09.759181: Yayy! New best EMA pseudo Dice: 0.907 
2025-07-11 16:28:13.349540:  
2025-07-11 16:28:13.350175: Epoch 81 
2025-07-11 16:28:13.350455: Current learning rate: 0.00927 
2025-07-11 16:30:36.671923: train_loss -0.7514 
2025-07-11 16:30:36.673389: val_loss -0.7513 
2025-07-11 16:30:36.673460: Pseudo dice [0.9153] 
2025-07-11 16:30:36.673538: Epoch time: 143.32 s 
2025-07-11 16:30:36.673582: Yayy! New best EMA pseudo Dice: 0.9079 
2025-07-11 16:30:40.639145:  
2025-07-11 16:30:40.639530: Epoch 82 
2025-07-11 16:30:40.639648: Current learning rate: 0.00926 
2025-07-11 16:33:03.755943: train_loss -0.7512 
2025-07-11 16:33:03.757447: val_loss -0.7666 
2025-07-11 16:33:03.757539: Pseudo dice [0.9101] 
2025-07-11 16:33:03.757625: Epoch time: 143.12 s 
2025-07-11 16:33:03.757679: Yayy! New best EMA pseudo Dice: 0.9081 
2025-07-11 16:33:06.338918:  
2025-07-11 16:33:06.339680: Epoch 83 
2025-07-11 16:33:06.340020: Current learning rate: 0.00925 
2025-07-11 16:35:27.499329: train_loss -0.7397 
2025-07-11 16:35:27.501766: val_loss -0.7848 
2025-07-11 16:35:27.502093: Pseudo dice [0.9105] 
2025-07-11 16:35:27.502338: Epoch time: 141.16 s 
2025-07-11 16:35:27.502452: Yayy! New best EMA pseudo Dice: 0.9083 
2025-07-11 16:35:30.530052:  
2025-07-11 16:35:30.530887: Epoch 84 
2025-07-11 16:35:30.531291: Current learning rate: 0.00924 
2025-07-11 16:37:56.037513: train_loss -0.7383 
2025-07-11 16:37:56.039058: val_loss -0.76 
2025-07-11 16:37:56.039190: Pseudo dice [0.9002] 
2025-07-11 16:37:56.039336: Epoch time: 145.51 s 
2025-07-11 16:37:57.958512:  
2025-07-11 16:37:57.959690: Epoch 85 
2025-07-11 16:37:57.960179: Current learning rate: 0.00923 
2025-07-11 16:40:21.958355: train_loss -0.7438 
2025-07-11 16:40:21.959474: val_loss -0.7495 
2025-07-11 16:40:21.959561: Pseudo dice [0.9032] 
2025-07-11 16:40:21.959644: Epoch time: 144.0 s 
2025-07-11 16:40:24.093153:  
2025-07-11 16:40:24.094433: Epoch 86 
2025-07-11 16:40:24.094877: Current learning rate: 0.00922 
2025-07-11 16:42:52.506192: train_loss -0.7499 
2025-07-11 16:42:52.507458: val_loss -0.7941 
2025-07-11 16:42:52.507531: Pseudo dice [0.9167] 
2025-07-11 16:42:52.507629: Epoch time: 148.42 s 
2025-07-11 16:42:53.980360:  
2025-07-11 16:42:53.981086: Epoch 87 
2025-07-11 16:42:53.981394: Current learning rate: 0.00921 
2025-07-11 16:45:12.999621: train_loss -0.7404 
2025-07-11 16:45:13.000597: val_loss -0.7244 
2025-07-11 16:45:13.000684: Pseudo dice [0.9011] 
2025-07-11 16:45:13.000782: Epoch time: 139.02 s 
2025-07-11 16:45:15.045423:  
2025-07-11 16:45:15.046652: Epoch 88 
2025-07-11 16:45:15.047212: Current learning rate: 0.0092 
2025-07-11 16:47:39.988226: train_loss -0.7479 
2025-07-11 16:47:39.989214: val_loss -0.7563 
2025-07-11 16:47:39.989294: Pseudo dice [0.906] 
2025-07-11 16:47:39.989372: Epoch time: 144.94 s 
2025-07-11 16:47:41.602723:  
2025-07-11 16:47:41.603946: Epoch 89 
2025-07-11 16:47:41.604273: Current learning rate: 0.0092 
2025-07-11 16:50:05.169870: train_loss -0.7542 
2025-07-11 16:50:05.170965: val_loss -0.7576 
2025-07-11 16:50:05.171062: Pseudo dice [0.9098] 
2025-07-11 16:50:05.171141: Epoch time: 143.57 s 
2025-07-11 16:50:07.023903:  
2025-07-11 16:50:07.024797: Epoch 90 
2025-07-11 16:50:07.025222: Current learning rate: 0.00919 
2025-07-11 16:52:29.517851: train_loss -0.7442 
2025-07-11 16:52:29.520041: val_loss -0.7828 
2025-07-11 16:52:29.520268: Pseudo dice [0.9189] 
2025-07-11 16:52:29.520489: Epoch time: 142.5 s 
2025-07-11 16:52:29.520704: Yayy! New best EMA pseudo Dice: 0.9086 
2025-07-11 16:52:32.498857:  
2025-07-11 16:52:32.499100: Epoch 91 
2025-07-11 16:52:32.499225: Current learning rate: 0.00918 
2025-07-11 16:54:53.783822: train_loss -0.7532 
2025-07-11 16:54:53.784896: val_loss -0.7382 
2025-07-11 16:54:53.785005: Pseudo dice [0.8997] 
2025-07-11 16:54:53.785087: Epoch time: 141.29 s 
2025-07-11 16:54:55.818548:  
2025-07-11 16:54:55.819954: Epoch 92 
2025-07-11 16:54:55.820411: Current learning rate: 0.00917 
2025-07-11 16:57:20.536750: train_loss -0.7224 
2025-07-11 16:57:20.537878: val_loss -0.7537 
2025-07-11 16:57:20.537962: Pseudo dice [0.8953] 
2025-07-11 16:57:20.538033: Epoch time: 144.72 s 
2025-07-11 16:57:21.997861:  
2025-07-11 16:57:21.998512: Epoch 93 
2025-07-11 16:57:21.998883: Current learning rate: 0.00916 
2025-07-11 16:59:46.501179: train_loss -0.7264 
2025-07-11 16:59:46.502761: val_loss -0.7418 
2025-07-11 16:59:46.503035: Pseudo dice [0.8981] 
2025-07-11 16:59:46.503259: Epoch time: 144.51 s 
2025-07-11 16:59:47.977030:  
2025-07-11 16:59:47.977776: Epoch 94 
2025-07-11 16:59:47.978099: Current learning rate: 0.00915 
2025-07-11 17:02:07.496356: train_loss -0.747 
2025-07-11 17:02:07.497432: val_loss -0.758 
2025-07-11 17:02:07.497504: Pseudo dice [0.9061] 
2025-07-11 17:02:07.497583: Epoch time: 139.52 s 
2025-07-11 17:02:09.439696:  
2025-07-11 17:02:09.440581: Epoch 95 
2025-07-11 17:02:09.441080: Current learning rate: 0.00914 
2025-07-11 17:04:33.274439: train_loss -0.7213 
2025-07-11 17:04:33.275687: val_loss -0.7351 
2025-07-11 17:04:33.275781: Pseudo dice [0.862] 
2025-07-11 17:04:33.275876: Epoch time: 143.84 s 
2025-07-11 17:04:35.193411:  
2025-07-11 17:04:35.194115: Epoch 96 
2025-07-11 17:04:35.194440: Current learning rate: 0.00913 
2025-07-11 17:07:02.786758: train_loss -0.7147 
2025-07-11 17:07:02.788101: val_loss -0.7128 
2025-07-11 17:07:02.788181: Pseudo dice [0.859] 
2025-07-11 17:07:02.788308: Epoch time: 147.6 s 
2025-07-11 17:07:04.174397:  
2025-07-11 17:07:04.175110: Epoch 97 
2025-07-11 17:07:04.175410: Current learning rate: 0.00912 
2025-07-11 17:09:25.672346: train_loss -0.7152 
2025-07-11 17:09:25.673460: val_loss -0.7455 
2025-07-11 17:09:25.673544: Pseudo dice [0.9016] 
2025-07-11 17:09:25.673637: Epoch time: 141.5 s 
2025-07-11 17:09:27.665901:  
2025-07-11 17:09:27.666961: Epoch 98 
2025-07-11 17:09:27.667484: Current learning rate: 0.00911 
2025-07-11 17:11:51.588661: train_loss -0.7322 
2025-07-11 17:11:51.589690: val_loss -0.7387 
2025-07-11 17:11:51.589771: Pseudo dice [0.885] 
2025-07-11 17:11:51.589849: Epoch time: 143.93 s 
2025-07-11 17:11:52.996530:  
2025-07-11 17:11:52.997108: Epoch 99 
2025-07-11 17:11:52.997373: Current learning rate: 0.0091 
2025-07-11 17:14:19.099074: train_loss -0.7231 
2025-07-11 17:14:19.100143: val_loss -0.7241 
2025-07-11 17:14:19.100231: Pseudo dice [0.8961] 
2025-07-11 17:14:19.100336: Epoch time: 146.1 s 
2025-07-11 17:14:21.370572:  
2025-07-11 17:14:21.370832: Epoch 100 
2025-07-11 17:14:21.370953: Current learning rate: 0.0091 
2025-07-11 17:16:43.325463: train_loss -0.7318 
2025-07-11 17:16:43.327930: val_loss -0.7397 
2025-07-11 17:16:43.328535: Pseudo dice [0.8931] 
2025-07-11 17:16:43.328825: Epoch time: 141.96 s 
2025-07-11 17:16:45.331007:  
2025-07-11 17:16:45.331884: Epoch 101 
2025-07-11 17:16:45.332268: Current learning rate: 0.00909 
2025-07-11 17:19:08.895518: train_loss -0.7263 
2025-07-11 17:19:08.896861: val_loss -0.7505 
2025-07-11 17:19:08.896955: Pseudo dice [0.9106] 
2025-07-11 17:19:08.897058: Epoch time: 143.57 s 
2025-07-11 17:19:14.094705:  
2025-07-11 17:19:14.094953: Epoch 102 
2025-07-11 17:19:14.095069: Current learning rate: 0.00908 
2025-07-11 17:21:39.266905: train_loss -0.7504 
2025-07-11 17:21:39.268164: val_loss -0.7441 
2025-07-11 17:21:39.268295: Pseudo dice [0.9184] 
2025-07-11 17:21:39.268413: Epoch time: 145.17 s 
2025-07-11 17:21:40.704173:  
2025-07-11 17:21:40.705034: Epoch 103 
2025-07-11 17:21:40.705364: Current learning rate: 0.00907 
2025-07-11 17:24:04.682026: train_loss -0.769 
2025-07-11 17:24:04.683594: val_loss -0.749 
2025-07-11 17:24:04.683809: Pseudo dice [0.9175] 
2025-07-11 17:24:04.684024: Epoch time: 143.98 s 
2025-07-11 17:24:06.580151:  
2025-07-11 17:24:06.581239: Epoch 104 
2025-07-11 17:24:06.581601: Current learning rate: 0.00906 
2025-07-11 17:26:27.708967: train_loss -0.7555 
2025-07-11 17:26:27.709985: val_loss -0.7642 
2025-07-11 17:26:27.710071: Pseudo dice [0.9165] 
2025-07-11 17:26:27.710194: Epoch time: 141.13 s 
2025-07-11 17:26:29.785941:  
2025-07-11 17:26:29.787094: Epoch 105 
2025-07-11 17:26:29.787519: Current learning rate: 0.00905 
2025-07-11 17:28:58.031961: train_loss -0.7576 
2025-07-11 17:28:58.032943: val_loss -0.756 
2025-07-11 17:28:58.033023: Pseudo dice [0.9057] 
2025-07-11 17:28:58.033118: Epoch time: 148.25 s 
2025-07-11 17:28:59.576426:  
2025-07-11 17:28:59.577323: Epoch 106 
2025-07-11 17:28:59.577639: Current learning rate: 0.00904 
2025-07-11 17:31:21.181243: train_loss -0.7364 
2025-07-11 17:31:21.182289: val_loss -0.7404 
2025-07-11 17:31:21.182365: Pseudo dice [0.9007] 
2025-07-11 17:31:21.182454: Epoch time: 141.61 s 
2025-07-11 17:31:23.207671:  
2025-07-11 17:31:23.209910: Epoch 107 
2025-07-11 17:31:23.210360: Current learning rate: 0.00903 
2025-07-11 17:33:51.147724: train_loss -0.7325 
2025-07-11 17:33:51.148940: val_loss -0.7313 
2025-07-11 17:33:51.149033: Pseudo dice [0.9051] 
2025-07-11 17:33:51.149146: Epoch time: 147.94 s 
2025-07-11 17:33:52.950031:  
2025-07-11 17:33:52.950823: Epoch 108 
2025-07-11 17:33:52.951202: Current learning rate: 0.00902 
2025-07-11 17:36:15.849539: train_loss -0.7217 
2025-07-11 17:36:15.851366: val_loss -0.768 
2025-07-11 17:36:15.851617: Pseudo dice [0.9094] 
2025-07-11 17:36:15.851822: Epoch time: 142.9 s 
2025-07-11 17:36:17.706276:  
2025-07-11 17:36:17.707404: Epoch 109 
2025-07-11 17:36:17.707785: Current learning rate: 0.00901 
2025-07-11 17:38:39.719519: train_loss -0.7454 
2025-07-11 17:38:39.720721: val_loss -0.7478 
2025-07-11 17:38:39.720869: Pseudo dice [0.8977] 
2025-07-11 17:38:39.721017: Epoch time: 142.01 s 
2025-07-11 17:38:41.481627:  
2025-07-11 17:38:41.482384: Epoch 110 
2025-07-11 17:38:41.482681: Current learning rate: 0.009 
2025-07-11 17:41:07.231609: train_loss -0.7506 
2025-07-11 17:41:07.233117: val_loss -0.7267 
2025-07-11 17:41:07.233199: Pseudo dice [0.9035] 
2025-07-11 17:41:07.233313: Epoch time: 145.75 s 
2025-07-11 17:41:09.134223:  
2025-07-11 17:41:09.135188: Epoch 111 
2025-07-11 17:41:09.135571: Current learning rate: 0.009 
2025-07-11 17:43:35.496539: train_loss -0.7272 
2025-07-11 17:43:35.499197: val_loss -0.7574 
2025-07-11 17:43:35.499473: Pseudo dice [0.9164] 
2025-07-11 17:43:35.499592: Epoch time: 146.36 s 
2025-07-11 17:43:37.196726:  
2025-07-11 17:43:37.197526: Epoch 112 
2025-07-11 17:43:37.197803: Current learning rate: 0.00899 
2025-07-11 17:45:57.715625: train_loss -0.7482 
2025-07-11 17:45:57.717272: val_loss -0.7353 
2025-07-11 17:45:57.717423: Pseudo dice [0.9015] 
2025-07-11 17:45:57.717587: Epoch time: 140.52 s 
2025-07-11 17:45:59.416920:  
2025-07-11 17:45:59.417835: Epoch 113 
2025-07-11 17:45:59.418254: Current learning rate: 0.00898 
2025-07-11 17:48:20.655010: train_loss -0.7646 
2025-07-11 17:48:20.656204: val_loss -0.7643 
2025-07-11 17:48:20.656325: Pseudo dice [0.9047] 
2025-07-11 17:48:20.656426: Epoch time: 141.24 s 
2025-07-11 17:48:22.646222:  
2025-07-11 17:48:22.647359: Epoch 114 
2025-07-11 17:48:22.647848: Current learning rate: 0.00897 
2025-07-11 17:50:46.262818: train_loss -0.7384 
2025-07-11 17:50:46.264019: val_loss -0.747 
2025-07-11 17:50:46.264137: Pseudo dice [0.8969] 
2025-07-11 17:50:46.264274: Epoch time: 143.62 s 
2025-07-11 17:50:47.979269:  
2025-07-11 17:50:47.980157: Epoch 115 
2025-07-11 17:50:47.980512: Current learning rate: 0.00896 
2025-07-11 17:53:11.147510: train_loss -0.7452 
2025-07-11 17:53:11.148504: val_loss -0.7402 
2025-07-11 17:53:11.148579: Pseudo dice [0.8865] 
2025-07-11 17:53:11.148672: Epoch time: 143.17 s 
2025-07-11 17:53:12.775684:  
2025-07-11 17:53:12.776529: Epoch 116 
2025-07-11 17:53:12.776851: Current learning rate: 0.00895 
2025-07-11 17:55:37.424917: train_loss -0.7473 
2025-07-11 17:55:37.426904: val_loss -0.7983 
2025-07-11 17:55:37.427229: Pseudo dice [0.93] 
2025-07-11 17:55:37.427489: Epoch time: 144.65 s 
2025-07-11 17:55:39.385314:  
2025-07-11 17:55:39.386113: Epoch 117 
2025-07-11 17:55:39.386510: Current learning rate: 0.00894 
2025-07-11 17:58:01.872676: train_loss -0.7468 
2025-07-11 17:58:01.874527: val_loss -0.7856 
2025-07-11 17:58:01.874841: Pseudo dice [0.9268] 
2025-07-11 17:58:01.875079: Epoch time: 142.49 s 
2025-07-11 17:58:03.443022:  
2025-07-11 17:58:03.443728: Epoch 118 
2025-07-11 17:58:03.444083: Current learning rate: 0.00893 
2025-07-11 18:00:27.775412: train_loss -0.7354 
2025-07-11 18:00:27.777722: val_loss -0.7944 
2025-07-11 18:00:27.777827: Pseudo dice [0.9237] 
2025-07-11 18:00:27.777934: Epoch time: 144.33 s 
2025-07-11 18:00:29.259151:  
2025-07-11 18:00:29.259777: Epoch 119 
2025-07-11 18:00:29.260042: Current learning rate: 0.00892 
2025-07-11 18:02:54.251872: train_loss -0.7498 
2025-07-11 18:02:54.253130: val_loss -0.7359 
2025-07-11 18:02:54.253219: Pseudo dice [0.8912] 
2025-07-11 18:02:54.253355: Epoch time: 144.99 s 
2025-07-11 18:02:55.985278:  
2025-07-11 18:02:55.986145: Epoch 120 
2025-07-11 18:02:55.986484: Current learning rate: 0.00891 
2025-07-11 18:05:22.754183: train_loss -0.7467 
2025-07-11 18:05:22.755201: val_loss -0.7749 
2025-07-11 18:05:22.755312: Pseudo dice [0.9189] 
2025-07-11 18:05:22.755410: Epoch time: 146.77 s 
2025-07-11 18:05:26.513480:  
2025-07-11 18:05:26.513820: Epoch 121 
2025-07-11 18:05:26.513969: Current learning rate: 0.0089 
2025-07-11 18:07:48.826855: train_loss -0.7485 
2025-07-11 18:07:48.828849: val_loss -0.7653 
2025-07-11 18:07:48.834936: Pseudo dice [0.9255] 
2025-07-11 18:07:48.835813: Epoch time: 142.31 s 
2025-07-11 18:07:48.835996: Yayy! New best EMA pseudo Dice: 0.9098 
2025-07-11 18:07:52.361619:  
2025-07-11 18:07:52.362442: Epoch 122 
2025-07-11 18:07:52.362765: Current learning rate: 0.00889 
2025-07-11 18:10:18.098859: train_loss -0.7547 
2025-07-11 18:10:18.100116: val_loss -0.7759 
2025-07-11 18:10:18.100275: Pseudo dice [0.9238] 
2025-07-11 18:10:18.100425: Epoch time: 145.74 s 
2025-07-11 18:10:18.100548: Yayy! New best EMA pseudo Dice: 0.9112 
2025-07-11 18:10:20.287566:  
2025-07-11 18:10:20.288091: Epoch 123 
2025-07-11 18:10:20.288260: Current learning rate: 0.00889 
2025-07-11 18:12:41.751036: train_loss -0.7412 
2025-07-11 18:12:41.751898: val_loss -0.7496 
2025-07-11 18:12:41.751984: Pseudo dice [0.9039] 
2025-07-11 18:12:41.752072: Epoch time: 141.46 s 
2025-07-11 18:12:43.516378:  
2025-07-11 18:12:43.517330: Epoch 124 
2025-07-11 18:12:43.517767: Current learning rate: 0.00888 
2025-07-11 18:15:01.475753: train_loss -0.7452 
2025-07-11 18:15:01.476964: val_loss -0.7476 
2025-07-11 18:15:01.477055: Pseudo dice [0.9121] 
2025-07-11 18:15:01.477149: Epoch time: 137.96 s 
2025-07-11 18:15:03.610043:  
2025-07-11 18:15:03.611138: Epoch 125 
2025-07-11 18:15:03.611526: Current learning rate: 0.00887 
2025-07-11 18:17:27.672586: train_loss -0.7387 
2025-07-11 18:17:27.673925: val_loss -0.753 
2025-07-11 18:17:27.674019: Pseudo dice [0.9081] 
2025-07-11 18:17:27.674139: Epoch time: 144.06 s 
2025-07-11 18:17:29.631858:  
2025-07-11 18:17:29.632962: Epoch 126 
2025-07-11 18:17:29.633376: Current learning rate: 0.00886 
2025-07-11 18:19:56.282385: train_loss -0.751 
2025-07-11 18:19:56.283411: val_loss -0.7939 
2025-07-11 18:19:56.283475: Pseudo dice [0.9184] 
2025-07-11 18:19:56.283603: Epoch time: 146.65 s 
2025-07-11 18:19:57.918084:  
2025-07-11 18:19:57.919158: Epoch 127 
2025-07-11 18:19:57.919538: Current learning rate: 0.00885 
2025-07-11 18:22:21.143739: train_loss -0.7513 
2025-07-11 18:22:21.144779: val_loss -0.7448 
2025-07-11 18:22:21.144869: Pseudo dice [0.9191] 
2025-07-11 18:22:21.144945: Epoch time: 143.23 s 
2025-07-11 18:22:21.145001: Yayy! New best EMA pseudo Dice: 0.912 
2025-07-11 18:22:24.114769:  
2025-07-11 18:22:24.115321: Epoch 128 
2025-07-11 18:22:24.115589: Current learning rate: 0.00884 
2025-07-11 18:24:43.419067: train_loss -0.7509 
2025-07-11 18:24:43.420766: val_loss -0.7815 
2025-07-11 18:24:43.420912: Pseudo dice [0.9172] 
2025-07-11 18:24:43.421068: Epoch time: 139.31 s 
2025-07-11 18:24:43.421136: Yayy! New best EMA pseudo Dice: 0.9125 
2025-07-11 18:24:46.781821:  
2025-07-11 18:24:46.782708: Epoch 129 
2025-07-11 18:24:46.783047: Current learning rate: 0.00883 
2025-07-11 18:27:07.876584: train_loss -0.7466 
2025-07-11 18:27:07.877798: val_loss -0.7386 
2025-07-11 18:27:07.877903: Pseudo dice [0.9171] 
2025-07-11 18:27:07.878026: Epoch time: 141.1 s 
2025-07-11 18:27:07.878086: Yayy! New best EMA pseudo Dice: 0.9129 
2025-07-11 18:27:11.053490:  
2025-07-11 18:27:11.053807: Epoch 130 
2025-07-11 18:27:11.053979: Current learning rate: 0.00882 
2025-07-11 18:29:34.498825: train_loss -0.7437 
2025-07-11 18:29:34.500504: val_loss -0.7645 
2025-07-11 18:29:34.500975: Pseudo dice [0.9212] 
2025-07-11 18:29:34.501267: Epoch time: 143.45 s 
2025-07-11 18:29:34.501463: Yayy! New best EMA pseudo Dice: 0.9138 
2025-07-11 18:29:37.427097:  
2025-07-11 18:29:37.427636: Epoch 131 
2025-07-11 18:29:37.427861: Current learning rate: 0.00881 
2025-07-11 18:31:58.456973: train_loss -0.7574 
2025-07-11 18:31:58.458397: val_loss -0.7748 
2025-07-11 18:31:58.458488: Pseudo dice [0.917] 
2025-07-11 18:31:58.458593: Epoch time: 141.03 s 
2025-07-11 18:31:58.458648: Yayy! New best EMA pseudo Dice: 0.9141 
2025-07-11 18:32:01.839630:  
2025-07-11 18:32:01.840520: Epoch 132 
2025-07-11 18:32:01.840920: Current learning rate: 0.0088 
2025-07-11 18:34:24.982170: train_loss -0.7461 
2025-07-11 18:34:24.984047: val_loss -0.7541 
2025-07-11 18:34:24.984711: Pseudo dice [0.926] 
2025-07-11 18:34:24.985541: Epoch time: 143.14 s 
2025-07-11 18:34:24.985911: Yayy! New best EMA pseudo Dice: 0.9153 
2025-07-11 18:34:28.406694:  
2025-07-11 18:34:28.407139: Epoch 133 
2025-07-11 18:34:28.407264: Current learning rate: 0.00879 
2025-07-11 18:36:51.119819: train_loss -0.7578 
2025-07-11 18:36:51.121073: val_loss -0.7799 
2025-07-11 18:36:51.121166: Pseudo dice [0.9131] 
2025-07-11 18:36:51.121277: Epoch time: 142.71 s 
2025-07-11 18:36:52.939586:  
2025-07-11 18:36:52.941956: Epoch 134 
2025-07-11 18:36:52.942577: Current learning rate: 0.00879 
2025-07-11 18:39:14.106146: train_loss -0.7568 
2025-07-11 18:39:14.107372: val_loss -0.7809 
2025-07-11 18:39:14.107505: Pseudo dice [0.9247] 
2025-07-11 18:39:14.107649: Epoch time: 141.17 s 
2025-07-11 18:39:14.107743: Yayy! New best EMA pseudo Dice: 0.916 
2025-07-11 18:39:16.965761:  
2025-07-11 18:39:16.966135: Epoch 135 
2025-07-11 18:39:16.966268: Current learning rate: 0.00878 
2025-07-11 18:41:34.406057: train_loss -0.7411 
2025-07-11 18:41:34.407540: val_loss -0.7881 
2025-07-11 18:41:34.407624: Pseudo dice [0.905] 
2025-07-11 18:41:34.407753: Epoch time: 137.44 s 
2025-07-11 18:41:36.340459:  
2025-07-11 18:41:36.341290: Epoch 136 
2025-07-11 18:41:36.341629: Current learning rate: 0.00877 
2025-07-11 18:44:00.556036: train_loss -0.7548 
2025-07-11 18:44:00.557792: val_loss -0.7775 
2025-07-11 18:44:00.558075: Pseudo dice [0.932] 
2025-07-11 18:44:00.558335: Epoch time: 144.22 s 
2025-07-11 18:44:00.558513: Yayy! New best EMA pseudo Dice: 0.9166 
2025-07-11 18:44:04.055773:  
2025-07-11 18:44:04.056677: Epoch 137 
2025-07-11 18:44:04.057031: Current learning rate: 0.00876 
2025-07-11 18:46:28.109972: train_loss -0.7498 
2025-07-11 18:46:28.111104: val_loss -0.7285 
2025-07-11 18:46:28.111178: Pseudo dice [0.8917] 
2025-07-11 18:46:28.111281: Epoch time: 144.06 s 
2025-07-11 18:46:29.633155:  
2025-07-11 18:46:29.633823: Epoch 138 
2025-07-11 18:46:29.634069: Current learning rate: 0.00875 
2025-07-11 18:48:50.978357: train_loss -0.7535 
2025-07-11 18:48:50.979935: val_loss -0.7731 
2025-07-11 18:48:50.980040: Pseudo dice [0.9104] 
2025-07-11 18:48:50.980156: Epoch time: 141.35 s 
2025-07-11 18:48:55.523786:  
2025-07-11 18:48:55.524024: Epoch 139 
2025-07-11 18:48:55.524131: Current learning rate: 0.00874 
2025-07-11 18:51:16.981331: train_loss -0.7595 
2025-07-11 18:51:16.982642: val_loss -0.7468 
2025-07-11 18:51:16.982818: Pseudo dice [0.8828] 
2025-07-11 18:51:16.982986: Epoch time: 141.46 s 
2025-07-11 18:51:18.906554:  
2025-07-11 18:51:18.907825: Epoch 140 
2025-07-11 18:51:18.908209: Current learning rate: 0.00873 
2025-07-11 18:53:45.198984: train_loss -0.7415 
2025-07-11 18:53:45.200512: val_loss -0.7669 
2025-07-11 18:53:45.200602: Pseudo dice [0.9128] 
2025-07-11 18:53:45.200725: Epoch time: 146.29 s 
2025-07-11 18:53:46.951776:  
2025-07-11 18:53:46.952730: Epoch 141 
2025-07-11 18:53:46.953096: Current learning rate: 0.00872 
2025-07-11 18:56:09.900976: train_loss -0.756 
2025-07-11 18:56:09.902703: val_loss -0.7593 
2025-07-11 18:56:09.902978: Pseudo dice [0.9195] 
2025-07-11 18:56:09.903221: Epoch time: 142.95 s 
2025-07-11 18:56:11.914721:  
2025-07-11 18:56:11.915821: Epoch 142 
2025-07-11 18:56:11.916193: Current learning rate: 0.00871 
2025-07-11 18:58:32.446100: train_loss -0.7563 
2025-07-11 18:58:32.447888: val_loss -0.7887 
2025-07-11 18:58:32.448266: Pseudo dice [0.9296] 
2025-07-11 18:58:32.448565: Epoch time: 140.53 s 
2025-07-11 18:58:34.416189:  
2025-07-11 18:58:34.417067: Epoch 143 
2025-07-11 18:58:34.417408: Current learning rate: 0.0087 
2025-07-11 19:00:58.193826: train_loss -0.7655 
2025-07-11 19:00:58.195214: val_loss -0.7794 
2025-07-11 19:00:58.195318: Pseudo dice [0.9067] 
2025-07-11 19:00:58.195421: Epoch time: 143.78 s 
2025-07-11 19:01:00.295675:  
2025-07-11 19:01:00.296862: Epoch 144 
2025-07-11 19:01:00.297296: Current learning rate: 0.00869 
2025-07-11 19:03:24.856025: train_loss -0.7586 
2025-07-11 19:03:24.856973: val_loss -0.7932 
2025-07-11 19:03:24.857060: Pseudo dice [0.9227] 
2025-07-11 19:03:24.857148: Epoch time: 144.56 s 
2025-07-11 19:03:26.765141:  
2025-07-11 19:03:26.766205: Epoch 145 
2025-07-11 19:03:26.766631: Current learning rate: 0.00868 
2025-07-11 19:05:52.208547: train_loss -0.7663 
2025-07-11 19:05:52.213616: val_loss -0.7809 
2025-07-11 19:05:52.214387: Pseudo dice [0.9152] 
2025-07-11 19:05:52.214975: Epoch time: 145.45 s 
2025-07-11 19:05:53.861031:  
2025-07-11 19:05:53.861728: Epoch 146 
2025-07-11 19:05:53.861954: Current learning rate: 0.00868 
2025-07-11 19:08:15.842352: train_loss -0.7552 
2025-07-11 19:08:15.843957: val_loss -0.789 
2025-07-11 19:08:15.844123: Pseudo dice [0.9267] 
2025-07-11 19:08:15.844702: Epoch time: 141.98 s 
2025-07-11 19:08:17.884699:  
2025-07-11 19:08:17.885701: Epoch 147 
2025-07-11 19:08:17.886107: Current learning rate: 0.00867 
2025-07-11 19:10:44.773892: train_loss -0.7635 
2025-07-11 19:10:44.774710: val_loss -0.7646 
2025-07-11 19:10:44.774791: Pseudo dice [0.9173] 
2025-07-11 19:10:44.774876: Epoch time: 146.89 s 
2025-07-11 19:10:46.315573:  
2025-07-11 19:10:46.316093: Epoch 148 
2025-07-11 19:10:46.316332: Current learning rate: 0.00866 
2025-07-11 19:13:11.662679: train_loss -0.7605 
2025-07-11 19:13:11.663683: val_loss -0.7901 
2025-07-11 19:13:11.663753: Pseudo dice [0.9258] 
2025-07-11 19:13:11.663848: Epoch time: 145.35 s 
2025-07-11 19:13:13.183473:  
2025-07-11 19:13:13.184346: Epoch 149 
2025-07-11 19:13:13.184670: Current learning rate: 0.00865 
2025-07-11 19:15:38.154684: train_loss -0.7433 
2025-07-11 19:15:38.156039: val_loss -0.7545 
2025-07-11 19:15:38.156151: Pseudo dice [0.9053] 
2025-07-11 19:15:38.156284: Epoch time: 144.97 s 
2025-07-11 19:15:41.647944:  
2025-07-11 19:15:41.648163: Epoch 150 
2025-07-11 19:15:41.648315: Current learning rate: 0.00864 
2025-07-11 19:18:04.126215: train_loss -0.7465 
2025-07-11 19:18:04.127558: val_loss -0.75 
2025-07-11 19:18:04.127689: Pseudo dice [0.8909] 
2025-07-11 19:18:04.127800: Epoch time: 142.48 s 
2025-07-11 19:18:05.959998:  
2025-07-11 19:18:05.960551: Epoch 151 
2025-07-11 19:18:05.960816: Current learning rate: 0.00863 
2025-07-11 19:20:29.349692: train_loss -0.7563 
2025-07-11 19:20:29.351001: val_loss -0.7753 
2025-07-11 19:20:29.351101: Pseudo dice [0.9143] 
2025-07-11 19:20:29.351216: Epoch time: 143.39 s 
2025-07-11 19:20:31.472619:  
2025-07-11 19:20:31.473526: Epoch 152 
2025-07-11 19:20:31.473942: Current learning rate: 0.00862 
2025-07-11 19:22:56.840966: train_loss -0.7298 
2025-07-11 19:22:56.842214: val_loss -0.7296 
2025-07-11 19:22:56.842316: Pseudo dice [0.8715] 
2025-07-11 19:22:56.842405: Epoch time: 145.37 s 
2025-07-11 19:22:58.549026:  
2025-07-11 19:22:58.549848: Epoch 153 
2025-07-11 19:22:58.550231: Current learning rate: 0.00861 
2025-07-11 19:25:21.863658: train_loss -0.7281 
2025-07-11 19:25:21.864996: val_loss -0.7237 
2025-07-11 19:25:21.865102: Pseudo dice [0.8892] 
2025-07-11 19:25:21.865194: Epoch time: 143.32 s 
2025-07-11 19:25:24.144275:  
2025-07-11 19:25:24.145488: Epoch 154 
2025-07-11 19:25:24.145995: Current learning rate: 0.0086 
2025-07-11 19:27:47.737751: train_loss -0.7321 
2025-07-11 19:27:47.739037: val_loss -0.742 
2025-07-11 19:27:47.739228: Pseudo dice [0.8998] 
2025-07-11 19:27:47.739412: Epoch time: 143.6 s 
2025-07-11 19:27:49.162208:  
2025-07-11 19:27:49.162895: Epoch 155 
2025-07-11 19:27:49.163178: Current learning rate: 0.00859 
2025-07-11 19:30:12.434865: train_loss -0.7407 
2025-07-11 19:30:12.435921: val_loss -0.7645 
2025-07-11 19:30:12.436012: Pseudo dice [0.914] 
2025-07-11 19:30:12.436103: Epoch time: 143.27 s 
2025-07-11 19:30:14.089097:  
2025-07-11 19:30:14.089774: Epoch 156 
2025-07-11 19:30:14.090053: Current learning rate: 0.00858 
2025-07-11 19:32:37.101006: train_loss -0.7196 
2025-07-11 19:32:37.102560: val_loss -0.7488 
2025-07-11 19:32:37.102705: Pseudo dice [0.8929] 
2025-07-11 19:32:37.102887: Epoch time: 143.01 s 
2025-07-11 19:32:42.225868:  
2025-07-11 19:32:42.226212: Epoch 157 
2025-07-11 19:32:42.226297: Current learning rate: 0.00858 
2025-07-11 19:35:05.616471: train_loss -0.7386 
2025-07-11 19:35:05.618217: val_loss -0.7481 
2025-07-11 19:35:05.618416: Pseudo dice [0.907] 
2025-07-11 19:35:05.618571: Epoch time: 143.39 s 
2025-07-11 19:35:07.445714:  
2025-07-11 19:35:07.447069: Epoch 158 
2025-07-11 19:35:07.447443: Current learning rate: 0.00857 
2025-07-11 19:37:33.806648: train_loss -0.7458 
2025-07-11 19:37:33.807900: val_loss -0.7633 
2025-07-11 19:37:33.808095: Pseudo dice [0.9119] 
2025-07-11 19:37:33.808346: Epoch time: 146.36 s 
2025-07-11 19:37:35.674450:  
2025-07-11 19:37:35.675620: Epoch 159 
2025-07-11 19:37:35.676003: Current learning rate: 0.00856 
2025-07-11 19:39:58.914560: train_loss -0.7567 
2025-07-11 19:39:58.916007: val_loss -0.792 
2025-07-11 19:39:58.916325: Pseudo dice [0.9131] 
2025-07-11 19:39:58.916579: Epoch time: 143.24 s 
2025-07-11 19:40:00.956857:  
2025-07-11 19:40:00.958022: Epoch 160 
2025-07-11 19:40:00.958400: Current learning rate: 0.00855 
2025-07-11 19:42:25.166168: train_loss -0.7659 
2025-07-11 19:42:25.167300: val_loss -0.7737 
2025-07-11 19:42:25.167409: Pseudo dice [0.9291] 
2025-07-11 19:42:25.167540: Epoch time: 144.21 s 
2025-07-11 19:42:26.596004:  
2025-07-11 19:42:26.596503: Epoch 161 
2025-07-11 19:42:26.596649: Current learning rate: 0.00854 
2025-07-11 19:44:53.493748: train_loss -0.7642 
2025-07-11 19:44:53.495154: val_loss -0.7617 
2025-07-11 19:44:53.495229: Pseudo dice [0.9217] 
2025-07-11 19:44:53.495301: Epoch time: 146.9 s 
2025-07-11 19:44:55.056424:  
2025-07-11 19:44:55.057060: Epoch 162 
2025-07-11 19:44:55.057323: Current learning rate: 0.00853 
2025-07-11 19:47:18.261849: train_loss -0.7697 
2025-07-11 19:47:18.263347: val_loss -0.7821 
2025-07-11 19:47:18.276583: Pseudo dice [0.932] 
2025-07-11 19:47:18.277492: Epoch time: 143.21 s 
2025-07-11 19:47:20.095852:  
2025-07-11 19:47:20.096871: Epoch 163 
2025-07-11 19:47:20.097342: Current learning rate: 0.00852 
2025-07-11 19:49:45.713416: train_loss -0.7568 
2025-07-11 19:49:45.713969: val_loss -0.7587 
2025-07-11 19:49:45.714058: Pseudo dice [0.9195] 
2025-07-11 19:49:45.714119: Epoch time: 145.62 s 
2025-07-11 19:49:47.033032:  
2025-07-11 19:49:47.033559: Epoch 164 
2025-07-11 19:49:47.033677: Current learning rate: 0.00851 
2025-07-11 19:52:07.298140: train_loss -0.7826 
2025-07-11 19:52:07.299705: val_loss -0.7694 
2025-07-11 19:52:07.299804: Pseudo dice [0.9323] 
2025-07-11 19:52:07.299909: Epoch time: 140.27 s 
2025-07-11 19:52:09.426115:  
2025-07-11 19:52:09.427449: Epoch 165 
2025-07-11 19:52:09.427966: Current learning rate: 0.0085 
2025-07-11 19:54:37.147753: train_loss -0.771 
2025-07-11 19:54:37.148768: val_loss -0.7912 
2025-07-11 19:54:37.148853: Pseudo dice [0.9292] 
2025-07-11 19:54:37.152540: Epoch time: 147.72 s 
2025-07-11 19:54:38.700587:  
2025-07-11 19:54:38.701428: Epoch 166 
2025-07-11 19:54:38.701734: Current learning rate: 0.00849 
2025-07-11 19:57:09.635824: train_loss -0.7542 
2025-07-11 19:57:09.636338: val_loss -0.7811 
2025-07-11 19:57:09.636391: Pseudo dice [0.9266] 
2025-07-11 19:57:09.636451: Epoch time: 150.94 s 
2025-07-11 19:57:09.636488: Yayy! New best EMA pseudo Dice: 0.9176 
2025-07-11 19:57:11.295347:  
2025-07-11 19:57:11.295846: Epoch 167 
2025-07-11 19:57:11.295959: Current learning rate: 0.00848 
2025-07-11 19:59:29.774549: train_loss -0.7611 
2025-07-11 19:59:29.776095: val_loss -0.769 
2025-07-11 19:59:29.776165: Pseudo dice [0.93] 
2025-07-11 19:59:29.776267: Epoch time: 138.48 s 
2025-07-11 19:59:29.776322: Yayy! New best EMA pseudo Dice: 0.9189 
2025-07-11 19:59:33.458079:  
2025-07-11 19:59:33.458992: Epoch 168 
2025-07-11 19:59:33.459335: Current learning rate: 0.00847 
2025-07-11 20:01:57.818822: train_loss -0.76 
2025-07-11 20:01:57.820102: val_loss -0.7775 
2025-07-11 20:01:57.820182: Pseudo dice [0.9288] 
2025-07-11 20:01:57.820286: Epoch time: 144.36 s 
2025-07-11 20:01:57.820338: Yayy! New best EMA pseudo Dice: 0.9199 
2025-07-11 20:02:00.952128:  
2025-07-11 20:02:00.952626: Epoch 169 
2025-07-11 20:02:00.952801: Current learning rate: 0.00847 
2025-07-11 20:04:25.836028: train_loss -0.7601 
2025-07-11 20:04:25.836961: val_loss -0.7725 
2025-07-11 20:04:25.837038: Pseudo dice [0.9252] 
2025-07-11 20:04:25.837137: Epoch time: 144.88 s 
2025-07-11 20:04:25.837182: Yayy! New best EMA pseudo Dice: 0.9204 
2025-07-11 20:04:28.710970:  
2025-07-11 20:04:28.711335: Epoch 170 
2025-07-11 20:04:28.711430: Current learning rate: 0.00846 
2025-07-11 20:06:51.860913: train_loss -0.7607 
2025-07-11 20:06:51.862429: val_loss -0.7595 
2025-07-11 20:06:51.862576: Pseudo dice [0.9134] 
2025-07-11 20:06:51.862683: Epoch time: 143.15 s 
2025-07-11 20:06:53.582458:  
2025-07-11 20:06:53.583115: Epoch 171 
2025-07-11 20:06:53.583398: Current learning rate: 0.00845 
2025-07-11 20:09:18.047773: train_loss -0.7545 
2025-07-11 20:09:18.049645: val_loss -0.7895 
2025-07-11 20:09:18.049920: Pseudo dice [0.9306] 
2025-07-11 20:09:18.050225: Epoch time: 144.47 s 
2025-07-11 20:09:18.050417: Yayy! New best EMA pseudo Dice: 0.9208 
2025-07-11 20:09:20.780048:  
2025-07-11 20:09:20.780462: Epoch 172 
2025-07-11 20:09:20.780565: Current learning rate: 0.00844 
2025-07-11 20:11:44.930997: train_loss -0.7468 
2025-07-11 20:11:44.932211: val_loss -0.7618 
2025-07-11 20:11:44.932337: Pseudo dice [0.9214] 
2025-07-11 20:11:44.932460: Epoch time: 144.15 s 
2025-07-11 20:11:44.932539: Yayy! New best EMA pseudo Dice: 0.9208 
2025-07-11 20:11:47.265998:  
2025-07-11 20:11:47.266349: Epoch 173 
2025-07-11 20:11:47.266506: Current learning rate: 0.00843 
2025-07-11 20:14:07.215998: train_loss -0.7603 
2025-07-11 20:14:07.217065: val_loss -0.7678 
2025-07-11 20:14:07.217157: Pseudo dice [0.9238] 
2025-07-11 20:14:07.217273: Epoch time: 139.95 s 
2025-07-11 20:14:07.217323: Yayy! New best EMA pseudo Dice: 0.9211 
2025-07-11 20:14:10.461907:  
2025-07-11 20:14:10.462539: Epoch 174 
2025-07-11 20:14:10.462788: Current learning rate: 0.00842 
2025-07-11 20:16:34.539605: train_loss -0.7518 
2025-07-11 20:16:34.540782: val_loss -0.7871 
2025-07-11 20:16:34.540871: Pseudo dice [0.9272] 
2025-07-11 20:16:34.540981: Epoch time: 144.08 s 
2025-07-11 20:16:34.541032: Yayy! New best EMA pseudo Dice: 0.9217 
2025-07-11 20:16:38.940415:  
2025-07-11 20:16:38.940800: Epoch 175 
2025-07-11 20:16:38.940907: Current learning rate: 0.00841 
2025-07-11 20:19:02.771210: train_loss -0.7674 
2025-07-11 20:19:02.778231: val_loss -0.7477 
2025-07-11 20:19:02.778523: Pseudo dice [0.9218] 
2025-07-11 20:19:02.778736: Epoch time: 143.83 s 
2025-07-11 20:19:02.778884: Yayy! New best EMA pseudo Dice: 0.9217 
2025-07-11 20:19:05.821739:  
2025-07-11 20:19:05.822125: Epoch 176 
2025-07-11 20:19:05.822233: Current learning rate: 0.0084 
2025-07-11 20:21:29.062337: train_loss -0.7646 
2025-07-11 20:21:29.064121: val_loss -0.7623 
2025-07-11 20:21:29.064412: Pseudo dice [0.9237] 
2025-07-11 20:21:29.064603: Epoch time: 143.24 s 
2025-07-11 20:21:29.064751: Yayy! New best EMA pseudo Dice: 0.9219 
2025-07-11 20:21:32.649179:  
2025-07-11 20:21:32.650009: Epoch 177 
2025-07-11 20:21:32.650293: Current learning rate: 0.00839 
2025-07-11 20:23:59.894631: train_loss -0.7649 
2025-07-11 20:23:59.896428: val_loss -0.7809 
2025-07-11 20:23:59.896551: Pseudo dice [0.9312] 
2025-07-11 20:23:59.896643: Epoch time: 147.25 s 
2025-07-11 20:23:59.896691: Yayy! New best EMA pseudo Dice: 0.9229 
2025-07-11 20:24:03.076244:  
2025-07-11 20:24:03.076771: Epoch 178 
2025-07-11 20:24:03.076875: Current learning rate: 0.00838 
2025-07-11 20:26:24.554969: train_loss -0.7672 
2025-07-11 20:26:24.556556: val_loss -0.7682 
2025-07-11 20:26:24.556669: Pseudo dice [0.9362] 
2025-07-11 20:26:24.556761: Epoch time: 141.48 s 
2025-07-11 20:26:24.556812: Yayy! New best EMA pseudo Dice: 0.9242 
2025-07-11 20:26:28.092641:  
2025-07-11 20:26:28.093578: Epoch 179 
2025-07-11 20:26:28.093881: Current learning rate: 0.00837 
2025-07-11 20:28:47.090636: train_loss -0.7657 
2025-07-11 20:28:47.092159: val_loss -0.778 
2025-07-11 20:28:47.092360: Pseudo dice [0.9298] 
2025-07-11 20:28:47.092531: Epoch time: 139.0 s 
2025-07-11 20:28:47.092652: Yayy! New best EMA pseudo Dice: 0.9248 
2025-07-11 20:28:50.911919:  
2025-07-11 20:28:50.913266: Epoch 180 
2025-07-11 20:28:50.913690: Current learning rate: 0.00836 
2025-07-11 20:31:12.036441: train_loss -0.7685 
2025-07-11 20:31:12.037587: val_loss -0.779 
2025-07-11 20:31:12.037694: Pseudo dice [0.9329] 
2025-07-11 20:31:12.037788: Epoch time: 141.13 s 
2025-07-11 20:31:12.037846: Yayy! New best EMA pseudo Dice: 0.9256 
2025-07-11 20:31:14.976552:  
2025-07-11 20:31:14.977019: Epoch 181 
2025-07-11 20:31:14.977160: Current learning rate: 0.00836 
2025-07-11 20:33:38.537463: train_loss -0.7595 
2025-07-11 20:33:38.538480: val_loss -0.7786 
2025-07-11 20:33:38.538552: Pseudo dice [0.9253] 
2025-07-11 20:33:38.538651: Epoch time: 143.56 s 
2025-07-11 20:33:40.369590:  
2025-07-11 20:33:40.370193: Epoch 182 
2025-07-11 20:33:40.370414: Current learning rate: 0.00835 
2025-07-11 20:36:01.816434: train_loss -0.7314 
2025-07-11 20:36:01.817439: val_loss -0.7658 
2025-07-11 20:36:01.817536: Pseudo dice [0.9125] 
2025-07-11 20:36:01.817652: Epoch time: 141.45 s 
2025-07-11 20:36:03.680170:  
2025-07-11 20:36:03.681079: Epoch 183 
2025-07-11 20:36:03.681480: Current learning rate: 0.00834 
2025-07-11 20:38:26.650943: train_loss -0.7551 
2025-07-11 20:38:26.651677: val_loss -0.8028 
2025-07-11 20:38:26.651742: Pseudo dice [0.928] 
2025-07-11 20:38:26.651875: Epoch time: 142.97 s 
2025-07-11 20:38:28.093229:  
2025-07-11 20:38:28.094051: Epoch 184 
2025-07-11 20:38:28.094380: Current learning rate: 0.00833 
2025-07-11 20:40:51.482806: train_loss -0.7645 
2025-07-11 20:40:51.484365: val_loss -0.7932 
2025-07-11 20:40:51.484599: Pseudo dice [0.9261] 
2025-07-11 20:40:51.484791: Epoch time: 143.39 s 
2025-07-11 20:40:53.271559:  
2025-07-11 20:40:53.272149: Epoch 185 
2025-07-11 20:40:53.272347: Current learning rate: 0.00832 
2025-07-11 20:43:14.157966: train_loss -0.7597 
2025-07-11 20:43:14.159606: val_loss -0.7603 
2025-07-11 20:43:14.159973: Pseudo dice [0.921] 
2025-07-11 20:43:14.160175: Epoch time: 140.89 s 
2025-07-11 20:43:16.199738:  
2025-07-11 20:43:16.200896: Epoch 186 
2025-07-11 20:43:16.201288: Current learning rate: 0.00831 
2025-07-11 20:45:38.623611: train_loss -0.7531 
2025-07-11 20:45:38.625679: val_loss -0.7797 
2025-07-11 20:45:38.626726: Pseudo dice [0.9222] 
2025-07-11 20:45:38.627503: Epoch time: 142.43 s 
2025-07-11 20:45:40.519617:  
2025-07-11 20:45:40.520558: Epoch 187 
2025-07-11 20:45:40.520902: Current learning rate: 0.0083 
2025-07-11 20:48:05.505748: train_loss -0.7675 
2025-07-11 20:48:05.507184: val_loss -0.7602 
2025-07-11 20:48:05.507622: Pseudo dice [0.9236] 
2025-07-11 20:48:05.508090: Epoch time: 144.99 s 
2025-07-11 20:48:07.428278:  
2025-07-11 20:48:07.429715: Epoch 188 
2025-07-11 20:48:07.430066: Current learning rate: 0.00829 
2025-07-11 20:50:33.954062: train_loss -0.7645 
2025-07-11 20:50:33.955686: val_loss -0.7654 
2025-07-11 20:50:33.955799: Pseudo dice [0.9309] 
2025-07-11 20:50:33.955880: Epoch time: 146.53 s 
2025-07-11 20:50:36.239396:  
2025-07-11 20:50:36.240540: Epoch 189 
2025-07-11 20:50:36.240984: Current learning rate: 0.00828 
2025-07-11 20:53:00.612499: train_loss -0.7609 
2025-07-11 20:53:00.614245: val_loss -0.781 
2025-07-11 20:53:00.614397: Pseudo dice [0.9363] 
2025-07-11 20:53:00.614534: Epoch time: 144.38 s 
2025-07-11 20:53:00.614596: Yayy! New best EMA pseudo Dice: 0.9259 
2025-07-11 20:53:03.825163:  
2025-07-11 20:53:03.825767: Epoch 190 
2025-07-11 20:53:03.826115: Current learning rate: 0.00827 
2025-07-11 20:55:24.710804: train_loss -0.761 
2025-07-11 20:55:24.715005: val_loss -0.76 
2025-07-11 20:55:24.715089: Pseudo dice [0.9179] 
2025-07-11 20:55:24.715196: Epoch time: 140.89 s 
2025-07-11 20:55:26.709537:  
2025-07-11 20:55:26.710291: Epoch 191 
2025-07-11 20:55:26.710622: Current learning rate: 0.00826 
2025-07-11 20:57:48.433478: train_loss -0.763 
2025-07-11 20:57:48.435221: val_loss -0.7801 
2025-07-11 20:57:48.435543: Pseudo dice [0.9284] 
2025-07-11 20:57:48.435772: Epoch time: 141.73 s 
2025-07-11 20:57:50.439836:  
2025-07-11 20:57:50.440870: Epoch 192 
2025-07-11 20:57:50.441384: Current learning rate: 0.00825 
2025-07-11 21:00:14.367497: train_loss -0.733 
2025-07-11 21:00:14.368527: val_loss -0.7779 
2025-07-11 21:00:14.368618: Pseudo dice [0.9212] 
2025-07-11 21:00:14.368717: Epoch time: 143.93 s 
2025-07-11 21:00:18.723055:  
2025-07-11 21:00:18.723537: Epoch 193 
2025-07-11 21:00:18.723637: Current learning rate: 0.00824 
2025-07-11 21:02:41.049912: train_loss -0.7435 
2025-07-11 21:02:41.050889: val_loss -0.7703 
2025-07-11 21:02:41.050969: Pseudo dice [0.9203] 
2025-07-11 21:02:41.051055: Epoch time: 142.33 s 
2025-07-11 21:02:43.036083:  
2025-07-11 21:02:43.037217: Epoch 194 
2025-07-11 21:02:43.037573: Current learning rate: 0.00824 
2025-07-11 21:05:10.774021: train_loss -0.746 
2025-07-11 21:05:10.775062: val_loss -0.7422 
2025-07-11 21:05:10.775132: Pseudo dice [0.9234] 
2025-07-11 21:05:10.775217: Epoch time: 147.74 s 
2025-07-11 21:05:12.319521:  
2025-07-11 21:05:12.320470: Epoch 195 
2025-07-11 21:05:12.320798: Current learning rate: 0.00823 
2025-07-11 21:07:35.485848: train_loss -0.7586 
2025-07-11 21:07:35.487038: val_loss -0.7572 
2025-07-11 21:07:35.487140: Pseudo dice [0.9213] 
2025-07-11 21:07:35.487239: Epoch time: 143.17 s 
2025-07-11 21:07:37.429393:  
2025-07-11 21:07:37.430684: Epoch 196 
2025-07-11 21:07:37.431060: Current learning rate: 0.00822 
2025-07-11 21:10:01.488851: train_loss -0.7513 
2025-07-11 21:10:01.489884: val_loss -0.7812 
2025-07-11 21:10:01.489966: Pseudo dice [0.9217] 
2025-07-11 21:10:01.490069: Epoch time: 144.06 s 
2025-07-11 21:10:03.141263:  
2025-07-11 21:10:03.142083: Epoch 197 
2025-07-11 21:10:03.142403: Current learning rate: 0.00821 
2025-07-11 21:12:22.716655: train_loss -0.7599 
2025-07-11 21:12:22.718679: val_loss -0.7687 
2025-07-11 21:12:22.719244: Pseudo dice [0.9252] 
2025-07-11 21:12:22.719521: Epoch time: 139.58 s 
2025-07-11 21:12:25.067997:  
2025-07-11 21:12:25.069254: Epoch 198 
2025-07-11 21:12:25.069678: Current learning rate: 0.0082 
2025-07-11 21:14:47.223801: train_loss -0.7571 
2025-07-11 21:14:47.232700: val_loss -0.7877 
2025-07-11 21:14:47.237694: Pseudo dice [0.9296] 
2025-07-11 21:14:47.242562: Epoch time: 142.16 s 
2025-07-11 21:14:49.406317:  
2025-07-11 21:14:49.407359: Epoch 199 
2025-07-11 21:14:49.407783: Current learning rate: 0.00819 
2025-07-11 21:17:12.326504: train_loss -0.746 
2025-07-11 21:17:12.327940: val_loss -0.8206 
2025-07-11 21:17:12.328035: Pseudo dice [0.9235] 
2025-07-11 21:17:12.328183: Epoch time: 142.92 s 
2025-07-11 21:17:15.008387:  
2025-07-11 21:17:15.008688: Epoch 200 
2025-07-11 21:17:15.008842: Current learning rate: 0.00818 
2025-07-11 21:19:41.840330: train_loss -0.7558 
2025-07-11 21:19:41.842059: val_loss -0.7819 
2025-07-11 21:19:41.842432: Pseudo dice [0.9158] 
2025-07-11 21:19:41.842621: Epoch time: 146.83 s 
2025-07-11 21:19:43.597996:  
2025-07-11 21:19:43.598821: Epoch 201 
2025-07-11 21:19:43.599142: Current learning rate: 0.00817 
2025-07-11 21:22:03.810135: train_loss -0.763 
2025-07-11 21:22:03.811623: val_loss -0.7547 
2025-07-11 21:22:03.811714: Pseudo dice [0.9259] 
2025-07-11 21:22:03.811799: Epoch time: 140.21 s 
2025-07-11 21:22:05.568090:  
2025-07-11 21:22:05.569194: Epoch 202 
2025-07-11 21:22:05.569593: Current learning rate: 0.00816 
2025-07-11 21:24:28.777102: train_loss -0.7698 
2025-07-11 21:24:28.778221: val_loss -0.7633 
2025-07-11 21:24:28.778333: Pseudo dice [0.924] 
2025-07-11 21:24:28.778459: Epoch time: 143.21 s 
2025-07-11 21:24:30.603782:  
2025-07-11 21:24:30.604379: Epoch 203 
2025-07-11 21:24:30.604674: Current learning rate: 0.00815 
2025-07-11 21:26:58.480569: train_loss -0.7744 
2025-07-11 21:26:58.482330: val_loss -0.7947 
2025-07-11 21:26:58.482679: Pseudo dice [0.9374] 
2025-07-11 21:26:58.482822: Epoch time: 147.88 s 
2025-07-11 21:27:00.012470:  
2025-07-11 21:27:00.013104: Epoch 204 
2025-07-11 21:27:00.013386: Current learning rate: 0.00814 
2025-07-11 21:29:22.949748: train_loss -0.7684 
2025-07-11 21:29:22.951368: val_loss -0.7724 
2025-07-11 21:29:22.951536: Pseudo dice [0.9345] 
2025-07-11 21:29:22.951693: Epoch time: 142.94 s 
2025-07-11 21:29:22.951787: Yayy! New best EMA pseudo Dice: 0.9261 
2025-07-11 21:29:26.091561:  
2025-07-11 21:29:26.092219: Epoch 205 
2025-07-11 21:29:26.092594: Current learning rate: 0.00813 
2025-07-11 21:31:49.068106: train_loss -0.7735 
2025-07-11 21:31:49.069776: val_loss -0.7704 
2025-07-11 21:31:49.070014: Pseudo dice [0.9354] 
2025-07-11 21:31:49.070210: Epoch time: 142.98 s 
2025-07-11 21:31:49.070385: Yayy! New best EMA pseudo Dice: 0.927 
2025-07-11 21:31:51.814174:  
2025-07-11 21:31:51.814879: Epoch 206 
2025-07-11 21:31:51.815090: Current learning rate: 0.00813 
2025-07-11 21:34:16.060540: train_loss -0.7576 
2025-07-11 21:34:16.062211: val_loss -0.8087 
2025-07-11 21:34:16.062404: Pseudo dice [0.939] 
2025-07-11 21:34:16.062500: Epoch time: 144.25 s 
2025-07-11 21:34:16.062554: Yayy! New best EMA pseudo Dice: 0.9282 
2025-07-11 21:34:18.476349:  
2025-07-11 21:34:18.476876: Epoch 207 
2025-07-11 21:34:18.477060: Current learning rate: 0.00812 
2025-07-11 21:36:42.790216: train_loss -0.7719 
2025-07-11 21:36:42.791203: val_loss -0.7584 
2025-07-11 21:36:42.791288: Pseudo dice [0.9378] 
2025-07-11 21:36:42.791371: Epoch time: 144.31 s 
2025-07-11 21:36:42.791406: Yayy! New best EMA pseudo Dice: 0.9292 
2025-07-11 21:36:44.987583:  
2025-07-11 21:36:44.987977: Epoch 208 
2025-07-11 21:36:44.988080: Current learning rate: 0.00811 
2025-07-11 21:39:02.879723: train_loss -0.7611 
2025-07-11 21:39:02.880944: val_loss -0.7709 
2025-07-11 21:39:02.881036: Pseudo dice [0.9349] 
2025-07-11 21:39:02.881147: Epoch time: 137.89 s 
2025-07-11 21:39:02.881214: Yayy! New best EMA pseudo Dice: 0.9298 
2025-07-11 21:39:06.039636:  
2025-07-11 21:39:06.040364: Epoch 209 
2025-07-11 21:39:06.040658: Current learning rate: 0.0081 
2025-07-11 21:41:30.984344: train_loss -0.7685 
2025-07-11 21:41:30.985379: val_loss -0.7769 
2025-07-11 21:41:30.985442: Pseudo dice [0.9296] 
2025-07-11 21:41:30.985528: Epoch time: 144.95 s 
2025-07-11 21:41:35.154655:  
2025-07-11 21:41:35.155106: Epoch 210 
2025-07-11 21:41:35.155227: Current learning rate: 0.00809 
2025-07-11 21:43:57.858949: train_loss -0.7653 
2025-07-11 21:43:57.860491: val_loss -0.7769 
2025-07-11 21:43:57.860595: Pseudo dice [0.9177] 
2025-07-11 21:43:57.860721: Epoch time: 142.7 s 
2025-07-11 21:43:59.877640:  
2025-07-11 21:43:59.879147: Epoch 211 
2025-07-11 21:43:59.879541: Current learning rate: 0.00808 
2025-07-11 21:46:27.628097: train_loss -0.7607 
2025-07-11 21:46:27.629156: val_loss -0.7729 
2025-07-11 21:46:27.629238: Pseudo dice [0.9207] 
2025-07-11 21:46:27.629368: Epoch time: 147.75 s 
2025-07-11 21:46:29.014509:  
2025-07-11 21:46:29.015023: Epoch 212 
2025-07-11 21:46:29.015146: Current learning rate: 0.00807 
2025-07-11 21:48:54.446406: train_loss -0.7601 
2025-07-11 21:48:54.447834: val_loss -0.7975 
2025-07-11 21:48:54.447950: Pseudo dice [0.9234] 
2025-07-11 21:48:54.448059: Epoch time: 145.43 s 
2025-07-11 21:48:56.025206:  
2025-07-11 21:48:56.026362: Epoch 213 
2025-07-11 21:48:56.026743: Current learning rate: 0.00806 
2025-07-11 21:51:19.368609: train_loss -0.7549 
2025-07-11 21:51:19.370190: val_loss -0.7894 
2025-07-11 21:51:19.370643: Pseudo dice [0.9376] 
2025-07-11 21:51:19.370812: Epoch time: 143.35 s 
2025-07-11 21:51:21.324394:  
2025-07-11 21:51:21.325440: Epoch 214 
2025-07-11 21:51:21.325698: Current learning rate: 0.00805 
2025-07-11 21:53:45.943859: train_loss -0.78 
2025-07-11 21:53:45.944936: val_loss -0.7706 
2025-07-11 21:53:45.945016: Pseudo dice [0.9353] 
2025-07-11 21:53:45.945111: Epoch time: 144.62 s 
2025-07-11 21:53:47.444214:  
2025-07-11 21:53:47.444728: Epoch 215 
2025-07-11 21:53:47.444913: Current learning rate: 0.00804 
2025-07-11 21:56:07.370303: train_loss -0.7699 
2025-07-11 21:56:07.371476: val_loss -0.7772 
2025-07-11 21:56:07.371603: Pseudo dice [0.9352] 
2025-07-11 21:56:07.371713: Epoch time: 139.93 s 
2025-07-11 21:56:09.469060:  
2025-07-11 21:56:09.470438: Epoch 216 
2025-07-11 21:56:09.470979: Current learning rate: 0.00803 
2025-07-11 21:58:29.937975: train_loss -0.7558 
2025-07-11 21:58:29.939007: val_loss -0.7961 
2025-07-11 21:58:29.939089: Pseudo dice [0.9291] 
2025-07-11 21:58:29.939176: Epoch time: 140.47 s 
2025-07-11 21:58:31.765685:  
2025-07-11 21:58:31.766738: Epoch 217 
2025-07-11 21:58:31.767137: Current learning rate: 0.00802 
2025-07-11 22:00:55.458963: train_loss -0.7692 
2025-07-11 22:00:55.460117: val_loss -0.7644 
2025-07-11 22:00:55.460192: Pseudo dice [0.9256] 
2025-07-11 22:00:55.460302: Epoch time: 143.7 s 
2025-07-11 22:00:57.353091:  
2025-07-11 22:00:57.354189: Epoch 218 
2025-07-11 22:00:57.354566: Current learning rate: 0.00801 
2025-07-11 22:03:20.157160: train_loss -0.7597 
2025-07-11 22:03:20.158952: val_loss -0.7738 
2025-07-11 22:03:20.159188: Pseudo dice [0.9079] 
2025-07-11 22:03:20.159371: Epoch time: 142.81 s 
2025-07-11 22:03:22.110457:  
2025-07-11 22:03:22.111447: Epoch 219 
2025-07-11 22:03:22.111829: Current learning rate: 0.00801 
2025-07-11 22:05:44.108798: train_loss -0.744 
2025-07-11 22:05:44.110576: val_loss -0.7671 
2025-07-11 22:05:44.110675: Pseudo dice [0.9234] 
2025-07-11 22:05:44.110764: Epoch time: 142.0 s 
2025-07-11 22:05:46.072030:  
2025-07-11 22:05:46.073248: Epoch 220 
2025-07-11 22:05:46.073726: Current learning rate: 0.008 
2025-07-11 22:08:13.034801: train_loss -0.7724 
2025-07-11 22:08:13.036914: val_loss -0.801 
2025-07-11 22:08:13.039141: Pseudo dice [0.9372] 
2025-07-11 22:08:13.039582: Epoch time: 146.97 s 
2025-07-11 22:08:14.680320:  
2025-07-11 22:08:14.681153: Epoch 221 
2025-07-11 22:08:14.681445: Current learning rate: 0.00799 
2025-07-11 22:10:36.346638: train_loss -0.7674 
2025-07-11 22:10:36.348277: val_loss -0.7754 
2025-07-11 22:10:36.348384: Pseudo dice [0.9303] 
2025-07-11 22:10:36.348501: Epoch time: 141.67 s 
2025-07-11 22:10:38.197958:  
2025-07-11 22:10:38.198918: Epoch 222 
2025-07-11 22:10:38.199278: Current learning rate: 0.00798 
2025-07-11 22:13:04.803145: train_loss -0.7627 
2025-07-11 22:13:04.804591: val_loss -0.7856 
2025-07-11 22:13:04.804815: Pseudo dice [0.9164] 
2025-07-11 22:13:04.805019: Epoch time: 146.61 s 
2025-07-11 22:13:06.198488:  
2025-07-11 22:13:06.199178: Epoch 223 
2025-07-11 22:13:06.199512: Current learning rate: 0.00797 
2025-07-11 22:15:31.651088: train_loss -0.767 
2025-07-11 22:15:31.652431: val_loss -0.8 
2025-07-11 22:15:31.652607: Pseudo dice [0.9235] 
2025-07-11 22:15:31.652766: Epoch time: 145.45 s 
2025-07-11 22:15:33.262274:  
2025-07-11 22:15:33.263005: Epoch 224 
2025-07-11 22:15:33.263313: Current learning rate: 0.00796 
2025-07-11 22:17:50.259660: train_loss -0.7753 
2025-07-11 22:17:50.260715: val_loss -0.7864 
2025-07-11 22:17:50.260784: Pseudo dice [0.9202] 
2025-07-11 22:17:50.260873: Epoch time: 137.0 s 
2025-07-11 22:17:52.235321:  
2025-07-11 22:17:52.236490: Epoch 225 
2025-07-11 22:17:52.236955: Current learning rate: 0.00795 
2025-07-11 22:20:19.983904: train_loss -0.7675 
2025-07-11 22:20:19.984831: val_loss -0.7746 
2025-07-11 22:20:19.984895: Pseudo dice [0.9191] 
2025-07-11 22:20:19.984999: Epoch time: 147.75 s 
2025-07-11 22:20:21.255133:  
2025-07-11 22:20:21.255453: Epoch 226 
2025-07-11 22:20:21.255574: Current learning rate: 0.00794 
2025-07-11 22:22:44.982398: train_loss -0.76 
2025-07-11 22:22:44.983542: val_loss -0.7724 
2025-07-11 22:22:44.983631: Pseudo dice [0.931] 
2025-07-11 22:22:44.983722: Epoch time: 143.73 s 
2025-07-11 22:22:46.731755:  
2025-07-11 22:22:46.732618: Epoch 227 
2025-07-11 22:22:46.733062: Current learning rate: 0.00793 
2025-07-11 22:25:09.416348: train_loss -0.7685 
2025-07-11 22:25:09.417773: val_loss -0.7861 
2025-07-11 22:25:09.417856: Pseudo dice [0.9323] 
2025-07-11 22:25:09.417956: Epoch time: 142.68 s 
2025-07-11 22:25:11.466765:  
2025-07-11 22:25:11.467712: Epoch 228 
2025-07-11 22:25:11.468118: Current learning rate: 0.00792 
2025-07-11 22:27:33.618367: train_loss -0.773 
2025-07-11 22:27:33.619891: val_loss -0.7754 
2025-07-11 22:27:33.620111: Pseudo dice [0.9279] 
2025-07-11 22:27:33.620265: Epoch time: 142.15 s 
2025-07-11 22:27:35.477008:  
2025-07-11 22:27:35.477841: Epoch 229 
2025-07-11 22:27:35.478226: Current learning rate: 0.00791 
2025-07-11 22:29:57.372757: train_loss -0.7706 
2025-07-11 22:29:57.373836: val_loss -0.7838 
2025-07-11 22:29:57.373930: Pseudo dice [0.9361] 
2025-07-11 22:29:57.374075: Epoch time: 141.9 s 
2025-07-11 22:30:01.855705:  
2025-07-11 22:30:01.856127: Epoch 230 
2025-07-11 22:30:01.856239: Current learning rate: 0.0079 
2025-07-11 22:32:20.268869: train_loss -0.7634 
2025-07-11 22:32:20.270272: val_loss -0.7906 
2025-07-11 22:32:20.270351: Pseudo dice [0.9363] 
2025-07-11 22:32:20.270439: Epoch time: 138.41 s 
2025-07-11 22:32:22.067954:  
2025-07-11 22:32:22.069144: Epoch 231 
2025-07-11 22:32:22.069597: Current learning rate: 0.00789 
2025-07-11 22:34:49.295346: train_loss -0.7603 
2025-07-11 22:34:49.297115: val_loss -0.8179 
2025-07-11 22:34:49.297390: Pseudo dice [0.9428] 
2025-07-11 22:34:49.297621: Epoch time: 147.23 s 
2025-07-11 22:34:49.297819: Yayy! New best EMA pseudo Dice: 0.9298 
2025-07-11 22:34:52.993069:  
2025-07-11 22:34:52.994248: Epoch 232 
2025-07-11 22:34:52.994601: Current learning rate: 0.00789 
2025-07-11 22:37:19.674328: train_loss -0.7794 
2025-07-11 22:37:19.675508: val_loss -0.778 
2025-07-11 22:37:19.675593: Pseudo dice [0.9468] 
2025-07-11 22:37:19.675749: Epoch time: 146.68 s 
2025-07-11 22:37:19.675822: Yayy! New best EMA pseudo Dice: 0.9315 
2025-07-11 22:37:22.966943:  
2025-07-11 22:37:22.967483: Epoch 233 
2025-07-11 22:37:22.967664: Current learning rate: 0.00788 
2025-07-11 22:39:44.099371: train_loss -0.766 
2025-07-11 22:39:44.100316: val_loss -0.7932 
2025-07-11 22:39:44.100388: Pseudo dice [0.942] 
2025-07-11 22:39:44.100492: Epoch time: 141.13 s 
2025-07-11 22:39:44.100544: Yayy! New best EMA pseudo Dice: 0.9326 
2025-07-11 22:39:46.978483:  
2025-07-11 22:39:46.979383: Epoch 234 
2025-07-11 22:39:46.979701: Current learning rate: 0.00787 
2025-07-11 22:42:13.714830: train_loss -0.7742 
2025-07-11 22:42:13.715931: val_loss -0.7918 
2025-07-11 22:42:13.716038: Pseudo dice [0.9215] 
2025-07-11 22:42:13.716221: Epoch time: 146.74 s 
2025-07-11 22:42:15.373302:  
2025-07-11 22:42:15.374413: Epoch 235 
2025-07-11 22:42:15.374786: Current learning rate: 0.00786 
2025-07-11 22:44:41.013093: train_loss -0.7494 
2025-07-11 22:44:41.014667: val_loss -0.7881 
2025-07-11 22:44:41.014807: Pseudo dice [0.9219] 
2025-07-11 22:44:41.014907: Epoch time: 145.64 s 
2025-07-11 22:44:42.901254:  
2025-07-11 22:44:42.902231: Epoch 236 
2025-07-11 22:44:42.902671: Current learning rate: 0.00785 
2025-07-11 22:47:05.470315: train_loss -0.7521 
2025-07-11 22:47:05.471630: val_loss -0.7781 
2025-07-11 22:47:05.471835: Pseudo dice [0.9337] 
2025-07-11 22:47:05.471995: Epoch time: 142.57 s 
2025-07-11 22:47:07.452402:  
2025-07-11 22:47:07.453463: Epoch 237 
2025-07-11 22:47:07.453822: Current learning rate: 0.00784 
2025-07-11 22:49:35.611653: train_loss -0.7649 
2025-07-11 22:49:35.612422: val_loss -0.7866 
2025-07-11 22:49:35.612489: Pseudo dice [0.9432] 
2025-07-11 22:49:35.612558: Epoch time: 148.16 s 
2025-07-11 22:49:37.012740:  
2025-07-11 22:49:37.013352: Epoch 238 
2025-07-11 22:49:37.013548: Current learning rate: 0.00783 
2025-07-11 22:51:58.718904: train_loss -0.7653 
2025-07-11 22:51:58.720067: val_loss -0.8067 
2025-07-11 22:51:58.720165: Pseudo dice [0.944] 
2025-07-11 22:51:58.720317: Epoch time: 141.71 s 
2025-07-11 22:51:58.720393: Yayy! New best EMA pseudo Dice: 0.9333 
2025-07-11 22:52:01.658092:  
2025-07-11 22:52:01.658774: Epoch 239 
2025-07-11 22:52:01.659029: Current learning rate: 0.00782 
2025-07-11 22:54:24.730869: train_loss -0.7691 
2025-07-11 22:54:24.733725: val_loss -0.8038 
2025-07-11 22:54:24.734110: Pseudo dice [0.9432] 
2025-07-11 22:54:24.734385: Epoch time: 143.07 s 
2025-07-11 22:54:24.734519: Yayy! New best EMA pseudo Dice: 0.9343 
2025-07-11 22:54:27.910531:  
2025-07-11 22:54:27.911015: Epoch 240 
2025-07-11 22:54:27.911118: Current learning rate: 0.00781 
2025-07-11 22:56:49.064939: train_loss -0.7646 
2025-07-11 22:56:49.066157: val_loss -0.8072 
2025-07-11 22:56:49.066235: Pseudo dice [0.9462] 
2025-07-11 22:56:49.066355: Epoch time: 141.16 s 
2025-07-11 22:56:49.066449: Yayy! New best EMA pseudo Dice: 0.9355 
2025-07-11 22:56:52.190292:  
2025-07-11 22:56:52.190853: Epoch 241 
2025-07-11 22:56:52.191072: Current learning rate: 0.0078 
2025-07-11 22:59:11.206417: train_loss -0.7693 
2025-07-11 22:59:11.207973: val_loss -0.7935 
2025-07-11 22:59:11.208401: Pseudo dice [0.9173] 
2025-07-11 22:59:11.208636: Epoch time: 139.02 s 
2025-07-11 22:59:12.967377:  
2025-07-11 22:59:12.967901: Epoch 242 
2025-07-11 22:59:12.968135: Current learning rate: 0.00779 
2025-07-11 23:01:38.525147: train_loss -0.7662 
2025-07-11 23:01:38.526033: val_loss -0.7611 
2025-07-11 23:01:38.526142: Pseudo dice [0.9284] 
2025-07-11 23:01:38.526241: Epoch time: 145.56 s 
2025-07-11 23:01:39.902124:  
2025-07-11 23:01:39.902738: Epoch 243 
2025-07-11 23:01:39.902987: Current learning rate: 0.00778 
2025-07-11 23:04:03.184119: train_loss -0.7525 
2025-07-11 23:04:03.185634: val_loss -0.736 
2025-07-11 23:04:03.185905: Pseudo dice [0.9344] 
2025-07-11 23:04:03.186032: Epoch time: 143.28 s 
2025-07-11 23:04:04.766915:  
2025-07-11 23:04:04.767681: Epoch 244 
2025-07-11 23:04:04.768057: Current learning rate: 0.00777 
2025-07-11 23:06:32.835909: train_loss -0.7715 
2025-07-11 23:06:32.837215: val_loss -0.8024 
2025-07-11 23:06:32.837321: Pseudo dice [0.9427] 
2025-07-11 23:06:32.837429: Epoch time: 148.07 s 
2025-07-11 23:06:34.382512:  
2025-07-11 23:06:34.383006: Epoch 245 
2025-07-11 23:06:34.383160: Current learning rate: 0.00777 
2025-07-11 23:08:54.630548: train_loss -0.7769 
2025-07-11 23:08:54.637867: val_loss -0.7887 
2025-07-11 23:08:54.638532: Pseudo dice [0.9421] 
2025-07-11 23:08:54.638664: Epoch time: 140.25 s 
2025-07-11 23:08:56.539122:  
2025-07-11 23:08:56.540363: Epoch 246 
2025-07-11 23:08:56.540804: Current learning rate: 0.00776 
2025-07-11 23:11:20.510339: train_loss -0.775 
2025-07-11 23:11:20.511619: val_loss -0.779 
2025-07-11 23:11:20.511710: Pseudo dice [0.9312] 
2025-07-11 23:11:20.511831: Epoch time: 143.97 s 
2025-07-11 23:11:22.403927:  
2025-07-11 23:11:22.405518: Epoch 247 
2025-07-11 23:11:22.405964: Current learning rate: 0.00775 
2025-07-11 23:13:45.334058: train_loss -0.7741 
2025-07-11 23:13:45.336120: val_loss -0.7792 
2025-07-11 23:13:45.336461: Pseudo dice [0.9447] 
2025-07-11 23:13:45.336784: Epoch time: 142.93 s 
2025-07-11 23:13:45.337572: Yayy! New best EMA pseudo Dice: 0.9356 
2025-07-11 23:13:48.882900:  
2025-07-11 23:13:48.883536: Epoch 248 
2025-07-11 23:13:48.883883: Current learning rate: 0.00774 
2025-07-11 23:16:14.591579: train_loss -0.7792 
2025-07-11 23:16:14.592324: val_loss -0.7958 
2025-07-11 23:16:14.592432: Pseudo dice [0.9383] 
2025-07-11 23:16:14.592511: Epoch time: 145.71 s 
2025-07-11 23:16:14.592561: Yayy! New best EMA pseudo Dice: 0.9359 
2025-07-11 23:16:17.456998:  
2025-07-11 23:16:17.457479: Epoch 249 
2025-07-11 23:16:17.457616: Current learning rate: 0.00773 
2025-07-11 23:18:38.986505: train_loss -0.7685 
2025-07-11 23:18:38.987792: val_loss -0.7963 
2025-07-11 23:18:38.987887: Pseudo dice [0.9461] 
2025-07-11 23:18:38.987993: Epoch time: 141.53 s 
2025-07-11 23:18:40.882761: Yayy! New best EMA pseudo Dice: 0.9369 
2025-07-11 23:18:43.728350:  
2025-07-11 23:18:43.729018: Epoch 250 
2025-07-11 23:18:43.729284: Current learning rate: 0.00772 
2025-07-11 23:21:03.920489: train_loss -0.768 
2025-07-11 23:21:03.922672: val_loss -0.7756 
2025-07-11 23:21:03.922927: Pseudo dice [0.9267] 
2025-07-11 23:21:03.923089: Epoch time: 140.19 s 
2025-07-11 23:21:05.924349:  
2025-07-11 23:21:05.925753: Epoch 251 
2025-07-11 23:21:05.926171: Current learning rate: 0.00771 
2025-07-11 23:23:28.318372: train_loss -0.777 
2025-07-11 23:23:28.319370: val_loss -0.785 
2025-07-11 23:23:28.319439: Pseudo dice [0.9463] 
2025-07-11 23:23:28.319540: Epoch time: 142.4 s 
2025-07-11 23:23:28.319594: Yayy! New best EMA pseudo Dice: 0.9369 
2025-07-11 23:23:30.816326:  
2025-07-11 23:23:30.817028: Epoch 252 
2025-07-11 23:23:30.817232: Current learning rate: 0.0077 
2025-07-11 23:25:52.817936: train_loss -0.7773 
2025-07-11 23:25:52.818951: val_loss -0.7922 
2025-07-11 23:25:52.819031: Pseudo dice [0.9468] 
2025-07-11 23:25:52.819114: Epoch time: 142.0 s 
2025-07-11 23:25:52.819175: Yayy! New best EMA pseudo Dice: 0.9379 
2025-07-11 23:25:56.393346:  
2025-07-11 23:25:56.394470: Epoch 253 
2025-07-11 23:25:56.394885: Current learning rate: 0.00769 
2025-07-11 23:28:17.404137: train_loss -0.7689 
2025-07-11 23:28:17.406029: val_loss -0.7868 
2025-07-11 23:28:17.406393: Pseudo dice [0.9441] 
2025-07-11 23:28:17.406574: Epoch time: 141.01 s 
2025-07-11 23:28:17.406676: Yayy! New best EMA pseudo Dice: 0.9385 
2025-07-11 23:28:20.636472:  
2025-07-11 23:28:20.637091: Epoch 254 
2025-07-11 23:28:20.637274: Current learning rate: 0.00768 
2025-07-11 23:30:40.369758: train_loss -0.7716 
2025-07-11 23:30:40.372143: val_loss -0.7729 
2025-07-11 23:30:40.372784: Pseudo dice [0.947] 
2025-07-11 23:30:40.373186: Epoch time: 139.73 s 
2025-07-11 23:30:40.373272: Yayy! New best EMA pseudo Dice: 0.9394 
2025-07-11 23:30:43.888795:  
2025-07-11 23:30:43.889825: Epoch 255 
2025-07-11 23:30:43.890136: Current learning rate: 0.00767 
2025-07-11 23:33:05.679374: train_loss -0.778 
2025-07-11 23:33:05.680397: val_loss -0.8079 
2025-07-11 23:33:05.680465: Pseudo dice [0.9484] 
2025-07-11 23:33:05.680545: Epoch time: 141.79 s 
2025-07-11 23:33:05.680585: Yayy! New best EMA pseudo Dice: 0.9403 
2025-07-11 23:33:08.338926:  
2025-07-11 23:33:08.339528: Epoch 256 
2025-07-11 23:33:08.339767: Current learning rate: 0.00766 
2025-07-11 23:35:31.926603: train_loss -0.767 
2025-07-11 23:35:31.927524: val_loss -0.8143 
2025-07-11 23:35:31.927594: Pseudo dice [0.9451] 
2025-07-11 23:35:31.927670: Epoch time: 143.59 s 
2025-07-11 23:35:31.927705: Yayy! New best EMA pseudo Dice: 0.9408 
2025-07-11 23:35:34.349455:  
2025-07-11 23:35:34.349905: Epoch 257 
2025-07-11 23:35:34.350000: Current learning rate: 0.00765 
2025-07-11 23:37:54.865039: train_loss -0.776 
2025-07-11 23:37:54.866256: val_loss -0.7831 
2025-07-11 23:37:54.866358: Pseudo dice [0.9439] 
2025-07-11 23:37:54.866456: Epoch time: 140.52 s 
2025-07-11 23:37:54.866511: Yayy! New best EMA pseudo Dice: 0.9411 
2025-07-11 23:37:58.219919:  
2025-07-11 23:37:58.220778: Epoch 258 
2025-07-11 23:37:58.221063: Current learning rate: 0.00764 
2025-07-11 23:40:22.011904: train_loss -0.7792 
2025-07-11 23:40:22.013355: val_loss -0.826 
2025-07-11 23:40:22.013528: Pseudo dice [0.9474] 
2025-07-11 23:40:22.013695: Epoch time: 143.79 s 
2025-07-11 23:40:22.013775: Yayy! New best EMA pseudo Dice: 0.9417 
2025-07-11 23:40:25.605969:  
2025-07-11 23:40:25.606837: Epoch 259 
2025-07-11 23:40:25.607257: Current learning rate: 0.00764 
2025-07-11 23:42:50.425519: train_loss -0.7636 
2025-07-11 23:42:50.426154: val_loss -0.7838 
2025-07-11 23:42:50.426213: Pseudo dice [0.9474] 
2025-07-11 23:42:50.426287: Epoch time: 144.82 s 
2025-07-11 23:42:50.426328: Yayy! New best EMA pseudo Dice: 0.9423 
2025-07-11 23:42:52.743976:  
2025-07-11 23:42:52.744392: Epoch 260 
2025-07-11 23:42:52.744504: Current learning rate: 0.00763 
2025-07-11 23:45:15.581897: train_loss -0.7432 
2025-07-11 23:45:15.583392: val_loss -0.7635 
2025-07-11 23:45:15.583467: Pseudo dice [0.8818] 
2025-07-11 23:45:15.583584: Epoch time: 142.84 s 
2025-07-11 23:45:17.388778:  
2025-07-11 23:45:17.389689: Epoch 261 
2025-07-11 23:45:17.390034: Current learning rate: 0.00762 
2025-07-11 23:47:37.019914: train_loss -0.7575 
2025-07-11 23:47:37.020994: val_loss -0.7667 
2025-07-11 23:47:37.021072: Pseudo dice [0.9257] 
2025-07-11 23:47:37.021170: Epoch time: 139.63 s 
2025-07-11 23:47:39.074116:  
2025-07-11 23:47:39.075141: Epoch 262 
2025-07-11 23:47:39.075554: Current learning rate: 0.00761 
2025-07-11 23:50:00.468886: train_loss -0.7619 
2025-07-11 23:50:00.470637: val_loss -0.7823 
2025-07-11 23:50:00.470732: Pseudo dice [0.9361] 
2025-07-11 23:50:00.470815: Epoch time: 141.4 s 
2025-07-11 23:50:02.748876:  
2025-07-11 23:50:02.749629: Epoch 263 
2025-07-11 23:50:02.749979: Current learning rate: 0.0076 
2025-07-11 23:52:29.666022: train_loss -0.7669 
2025-07-11 23:52:29.667162: val_loss -0.7971 
2025-07-11 23:52:29.667240: Pseudo dice [0.9464] 
2025-07-11 23:52:29.667353: Epoch time: 146.92 s 
2025-07-11 23:52:31.122413:  
2025-07-11 23:52:31.123016: Epoch 264 
2025-07-11 23:52:31.123398: Current learning rate: 0.00759 
2025-07-11 23:54:54.779982: train_loss -0.7492 
2025-07-11 23:54:54.781286: val_loss -0.7606 
2025-07-11 23:54:54.781387: Pseudo dice [0.9304] 
2025-07-11 23:54:54.781500: Epoch time: 143.66 s 
2025-07-11 23:54:56.519623:  
2025-07-11 23:54:56.520441: Epoch 265 
2025-07-11 23:54:56.520781: Current learning rate: 0.00758 
2025-07-11 23:57:19.084062: train_loss -0.7517 
2025-07-11 23:57:19.085081: val_loss -0.7967 
2025-07-11 23:57:19.085164: Pseudo dice [0.9347] 
2025-07-11 23:57:19.085566: Epoch time: 142.57 s 
2025-07-11 23:57:21.134229:  
2025-07-11 23:57:21.135259: Epoch 266 
2025-07-11 23:57:21.135727: Current learning rate: 0.00757 
2025-07-11 23:59:40.819538: train_loss -0.7721 
2025-07-11 23:59:40.820708: val_loss -0.7673 
2025-07-11 23:59:40.820782: Pseudo dice [0.9374] 
2025-07-11 23:59:40.820880: Epoch time: 139.69 s 
2025-07-11 23:59:42.576103:  
2025-07-11 23:59:42.576675: Epoch 267 
2025-07-11 23:59:42.576989: Current learning rate: 0.00756 
2025-07-12 00:02:03.645623: train_loss -0.7677 
2025-07-12 00:02:03.647267: val_loss -0.8165 
2025-07-12 00:02:03.647874: Pseudo dice [0.9427] 
2025-07-12 00:02:03.648215: Epoch time: 141.07 s 
2025-07-12 00:02:10.711159:  
2025-07-12 00:02:10.711609: Epoch 268 
2025-07-12 00:02:10.711738: Current learning rate: 0.00755 
2025-07-12 00:04:31.250733: train_loss -0.7816 
2025-07-12 00:04:31.252116: val_loss -0.7833 
2025-07-12 00:04:31.252185: Pseudo dice [0.9332] 
2025-07-12 00:04:31.252273: Epoch time: 140.54 s 
2025-07-12 00:04:33.085763:  
2025-07-12 00:04:33.086962: Epoch 269 
2025-07-12 00:04:33.087336: Current learning rate: 0.00754 
2025-07-12 00:06:56.688724: train_loss -0.7659 
2025-07-12 00:06:56.689927: val_loss -0.761 
2025-07-12 00:06:56.690009: Pseudo dice [0.9412] 
2025-07-12 00:06:56.690106: Epoch time: 143.6 s 
2025-07-12 00:06:58.659158:  
2025-07-12 00:06:58.660321: Epoch 270 
2025-07-12 00:06:58.660730: Current learning rate: 0.00753 
2025-07-12 00:09:25.551310: train_loss -0.748 
2025-07-12 00:09:25.552600: val_loss -0.7818 
2025-07-12 00:09:25.552716: Pseudo dice [0.9392] 
2025-07-12 00:09:25.552842: Epoch time: 146.89 s 
2025-07-12 00:09:27.212848:  
2025-07-12 00:09:27.213439: Epoch 271 
2025-07-12 00:09:27.213642: Current learning rate: 0.00752 
2025-07-12 00:11:49.782316: train_loss -0.7734 
2025-07-12 00:11:49.783366: val_loss -0.7632 
2025-07-12 00:11:49.783444: Pseudo dice [0.9308] 
2025-07-12 00:11:49.783631: Epoch time: 142.57 s 
2025-07-12 00:11:51.536321:  
2025-07-12 00:11:51.537081: Epoch 272 
2025-07-12 00:11:51.537467: Current learning rate: 0.00751 
2025-07-12 00:14:17.979800: train_loss -0.7587 
2025-07-12 00:14:17.980886: val_loss -0.7616 
2025-07-12 00:14:17.980957: Pseudo dice [0.9315] 
2025-07-12 00:14:17.981055: Epoch time: 146.44 s 
2025-07-12 00:14:19.564496:  
2025-07-12 00:14:19.565309: Epoch 273 
2025-07-12 00:14:19.565573: Current learning rate: 0.00751 
2025-07-12 00:16:43.617044: train_loss -0.7653 
2025-07-12 00:16:43.617972: val_loss -0.7932 
2025-07-12 00:16:43.618042: Pseudo dice [0.9356] 
2025-07-12 00:16:43.618124: Epoch time: 144.05 s 
2025-07-12 00:16:45.279624:  
2025-07-12 00:16:45.280601: Epoch 274 
2025-07-12 00:16:45.280947: Current learning rate: 0.0075 
2025-07-12 00:19:10.728641: train_loss -0.7691 
2025-07-12 00:19:10.729904: val_loss -0.7894 
2025-07-12 00:19:10.729986: Pseudo dice [0.9473] 
2025-07-12 00:19:10.730095: Epoch time: 145.45 s 
2025-07-12 00:19:12.508019:  
2025-07-12 00:19:12.508822: Epoch 275 
2025-07-12 00:19:12.509099: Current learning rate: 0.00749 
2025-07-12 00:21:34.608414: train_loss -0.7729 
2025-07-12 00:21:34.609882: val_loss -0.7847 
2025-07-12 00:21:34.610047: Pseudo dice [0.951] 
2025-07-12 00:21:34.610198: Epoch time: 142.1 s 
2025-07-12 00:21:36.589789:  
2025-07-12 00:21:36.590828: Epoch 276 
2025-07-12 00:21:36.591232: Current learning rate: 0.00748 
2025-07-12 00:24:06.747264: train_loss -0.7604 
2025-07-12 00:24:06.749548: val_loss -0.7735 
2025-07-12 00:24:06.749662: Pseudo dice [0.933] 
2025-07-12 00:24:06.749874: Epoch time: 150.16 s 
2025-07-12 00:24:08.617176:  
2025-07-12 00:24:08.618411: Epoch 277 
2025-07-12 00:24:08.618805: Current learning rate: 0.00747 
2025-07-12 00:26:26.907694: train_loss -0.7841 
2025-07-12 00:26:26.911129: val_loss -0.7737 
2025-07-12 00:26:26.911578: Pseudo dice [0.95] 
2025-07-12 00:26:26.911845: Epoch time: 138.29 s 
2025-07-12 00:26:29.025876:  
2025-07-12 00:26:29.026571: Epoch 278 
2025-07-12 00:26:29.026833: Current learning rate: 0.00746 
2025-07-12 00:28:51.456724: train_loss -0.7706 
2025-07-12 00:28:51.457934: val_loss -0.7691 
2025-07-12 00:28:51.458168: Pseudo dice [0.9413] 
2025-07-12 00:28:51.458339: Epoch time: 142.43 s 
2025-07-12 00:28:53.393896:  
2025-07-12 00:28:53.394953: Epoch 279 
2025-07-12 00:28:53.395305: Current learning rate: 0.00745 
2025-07-12 00:31:16.541932: train_loss -0.7574 
2025-07-12 00:31:16.543028: val_loss -0.7829 
2025-07-12 00:31:16.543131: Pseudo dice [0.9255] 
2025-07-12 00:31:16.543243: Epoch time: 143.15 s 
2025-07-12 00:31:18.078111:  
2025-07-12 00:31:18.078835: Epoch 280 
2025-07-12 00:31:18.079123: Current learning rate: 0.00744 
2025-07-12 00:33:42.161468: train_loss -0.7599 
2025-07-12 00:33:42.162708: val_loss -0.8072 
2025-07-12 00:33:42.162885: Pseudo dice [0.9381] 
2025-07-12 00:33:42.163022: Epoch time: 144.08 s 
2025-07-12 00:33:44.297693:  
2025-07-12 00:33:44.298878: Epoch 281 
2025-07-12 00:33:44.299354: Current learning rate: 0.00743 
2025-07-12 00:36:11.883241: train_loss -0.7763 
2025-07-12 00:36:11.884316: val_loss -0.8007 
2025-07-12 00:36:11.884387: Pseudo dice [0.9486] 
2025-07-12 00:36:11.884463: Epoch time: 147.59 s 
2025-07-12 00:36:13.190248:  
2025-07-12 00:36:13.190685: Epoch 282 
2025-07-12 00:36:13.190797: Current learning rate: 0.00742 
2025-07-12 00:38:38.769971: train_loss -0.7742 
2025-07-12 00:38:38.771317: val_loss -0.7506 
2025-07-12 00:38:38.771405: Pseudo dice [0.9322] 
2025-07-12 00:38:38.771519: Epoch time: 145.58 s 
2025-07-12 00:38:40.301872:  
2025-07-12 00:38:40.302522: Epoch 283 
2025-07-12 00:38:40.302851: Current learning rate: 0.00741 
2025-07-12 00:41:04.398746: train_loss -0.7582 
2025-07-12 00:41:04.400070: val_loss -0.7651 
2025-07-12 00:41:04.400183: Pseudo dice [0.9295] 
2025-07-12 00:41:04.400329: Epoch time: 144.1 s 
2025-07-12 00:41:05.970758:  
2025-07-12 00:41:05.971283: Epoch 284 
2025-07-12 00:41:05.971524: Current learning rate: 0.0074 
2025-07-12 00:43:32.213737: train_loss -0.7557 
2025-07-12 00:43:32.215946: val_loss -0.7533 
2025-07-12 00:43:32.216174: Pseudo dice [0.9028] 
2025-07-12 00:43:32.216275: Epoch time: 146.24 s 
2025-07-12 00:43:33.869191:  
2025-07-12 00:43:33.869847: Epoch 285 
2025-07-12 00:43:33.870137: Current learning rate: 0.00739 
2025-07-12 00:45:53.509481: train_loss -0.7497 
2025-07-12 00:45:53.510874: val_loss -0.7555 
2025-07-12 00:45:53.511019: Pseudo dice [0.9071] 
2025-07-12 00:45:53.511180: Epoch time: 139.64 s 
2025-07-12 00:45:55.462652:  
2025-07-12 00:45:55.463659: Epoch 286 
2025-07-12 00:45:55.464027: Current learning rate: 0.00738 
2025-07-12 00:48:21.686815: train_loss -0.7181 
2025-07-12 00:48:21.688150: val_loss -0.7708 
2025-07-12 00:48:21.688282: Pseudo dice [0.9228] 
2025-07-12 00:48:21.688385: Epoch time: 146.23 s 
2025-07-12 00:48:27.423559:  
2025-07-12 00:48:27.423997: Epoch 287 
2025-07-12 00:48:27.424109: Current learning rate: 0.00738 
2025-07-12 00:50:49.771008: train_loss -0.7394 
2025-07-12 00:50:49.773109: val_loss -0.7796 
2025-07-12 00:50:49.773342: Pseudo dice [0.9285] 
2025-07-12 00:50:49.773531: Epoch time: 142.35 s 
2025-07-12 00:50:51.860439:  
2025-07-12 00:50:51.861968: Epoch 288 
2025-07-12 00:50:51.862412: Current learning rate: 0.00737 
2025-07-12 00:53:14.633131: train_loss -0.7689 
2025-07-12 00:53:14.634146: val_loss -0.8194 
2025-07-12 00:53:14.634216: Pseudo dice [0.937] 
2025-07-12 00:53:14.634319: Epoch time: 142.78 s 
2025-07-12 00:53:16.434791:  
2025-07-12 00:53:16.436003: Epoch 289 
2025-07-12 00:53:16.436448: Current learning rate: 0.00736 
2025-07-12 00:55:39.393547: train_loss -0.7671 
2025-07-12 00:55:39.394434: val_loss -0.7896 
2025-07-12 00:55:39.394522: Pseudo dice [0.9244] 
2025-07-12 00:55:39.394607: Epoch time: 142.96 s 
2025-07-12 00:55:41.001129:  
2025-07-12 00:55:41.001698: Epoch 290 
2025-07-12 00:55:41.001857: Current learning rate: 0.00735 
2025-07-12 00:58:04.334990: train_loss -0.764 
2025-07-12 00:58:04.336020: val_loss -0.767 
2025-07-12 00:58:04.336090: Pseudo dice [0.9433] 
2025-07-12 00:58:04.336165: Epoch time: 143.33 s 
2025-07-12 00:58:06.251221:  
2025-07-12 00:58:06.252316: Epoch 291 
2025-07-12 00:58:06.252651: Current learning rate: 0.00734 
2025-07-12 01:00:29.798911: train_loss -0.7665 
2025-07-12 01:00:29.800010: val_loss -0.7957 
2025-07-12 01:00:29.800130: Pseudo dice [0.9327] 
2025-07-12 01:00:29.800228: Epoch time: 143.55 s 
2025-07-12 01:00:31.992631:  
2025-07-12 01:00:31.993959: Epoch 292 
2025-07-12 01:00:31.994383: Current learning rate: 0.00733 
2025-07-12 01:02:57.635756: train_loss -0.7726 
2025-07-12 01:02:57.638087: val_loss -0.7906 
2025-07-12 01:02:57.638338: Pseudo dice [0.939] 
2025-07-12 01:02:57.638512: Epoch time: 145.65 s 
2025-07-12 01:02:59.529830:  
2025-07-12 01:02:59.530961: Epoch 293 
2025-07-12 01:02:59.531296: Current learning rate: 0.00732 
2025-07-12 01:05:22.517268: train_loss -0.7611 
2025-07-12 01:05:22.518986: val_loss -0.8178 
2025-07-12 01:05:22.519421: Pseudo dice [0.9459] 
2025-07-12 01:05:22.519674: Epoch time: 142.99 s 
2025-07-12 01:05:24.518552:  
2025-07-12 01:05:24.519970: Epoch 294 
2025-07-12 01:05:24.520472: Current learning rate: 0.00731 
2025-07-12 01:07:50.601331: train_loss -0.7697 
2025-07-12 01:07:50.602448: val_loss -0.7945 
2025-07-12 01:07:50.602568: Pseudo dice [0.9435] 
2025-07-12 01:07:50.602690: Epoch time: 146.08 s 
2025-07-12 01:07:52.292587:  
2025-07-12 01:07:52.295098: Epoch 295 
2025-07-12 01:07:52.295918: Current learning rate: 0.0073 
2025-07-12 01:10:16.798249: train_loss -0.7616 
2025-07-12 01:10:16.799261: val_loss -0.8043 
2025-07-12 01:10:16.799441: Pseudo dice [0.9392] 
2025-07-12 01:10:16.799528: Epoch time: 144.51 s 
2025-07-12 01:10:18.444120:  
2025-07-12 01:10:18.445140: Epoch 296 
2025-07-12 01:10:18.445484: Current learning rate: 0.00729 
2025-07-12 01:12:42.796323: train_loss -0.7807 
2025-07-12 01:12:42.798656: val_loss -0.8098 
2025-07-12 01:12:42.798805: Pseudo dice [0.9343] 
2025-07-12 01:12:42.798901: Epoch time: 144.35 s 
2025-07-12 01:12:44.378155:  
2025-07-12 01:12:44.378856: Epoch 297 
2025-07-12 01:12:44.379127: Current learning rate: 0.00728 
2025-07-12 01:15:04.488516: train_loss -0.7634 
2025-07-12 01:15:04.490813: val_loss -0.7862 
2025-07-12 01:15:04.491162: Pseudo dice [0.9322] 
2025-07-12 01:15:04.491447: Epoch time: 140.11 s 
2025-07-12 01:15:06.793597:  
2025-07-12 01:15:06.794704: Epoch 298 
2025-07-12 01:15:06.795152: Current learning rate: 0.00727 
2025-07-12 01:17:32.802058: train_loss -0.775 
2025-07-12 01:17:32.803221: val_loss -0.7904 
2025-07-12 01:17:32.803313: Pseudo dice [0.9362] 
2025-07-12 01:17:32.803422: Epoch time: 146.01 s 
2025-07-12 01:17:34.571676:  
2025-07-12 01:17:34.572562: Epoch 299 
2025-07-12 01:17:34.572880: Current learning rate: 0.00726 
2025-07-12 01:19:58.581019: train_loss -0.7722 
2025-07-12 01:19:58.582335: val_loss -0.7947 
2025-07-12 01:19:58.582424: Pseudo dice [0.9369] 
2025-07-12 01:19:58.582522: Epoch time: 144.01 s 
2025-07-12 01:20:01.960266:  
2025-07-12 01:20:01.960808: Epoch 300 
2025-07-12 01:20:01.961067: Current learning rate: 0.00725 
2025-07-12 01:22:20.337478: train_loss -0.7706 
2025-07-12 01:22:20.338651: val_loss -0.7886 
2025-07-12 01:22:20.338789: Pseudo dice [0.9377] 
2025-07-12 01:22:20.338916: Epoch time: 138.38 s 
2025-07-12 01:22:22.604900:  
2025-07-12 01:22:22.605652: Epoch 301 
2025-07-12 01:22:22.606045: Current learning rate: 0.00724 
2025-07-12 01:24:49.546793: train_loss -0.7672 
2025-07-12 01:24:49.548266: val_loss -0.7855 
2025-07-12 01:24:49.548431: Pseudo dice [0.9388] 
2025-07-12 01:24:49.548589: Epoch time: 146.94 s 
2025-07-12 01:24:51.246381:  
2025-07-12 01:24:51.247142: Epoch 302 
2025-07-12 01:24:51.247490: Current learning rate: 0.00724 
2025-07-12 01:27:11.678773: train_loss -0.774 
2025-07-12 01:27:11.680063: val_loss -0.8205 
2025-07-12 01:27:11.680145: Pseudo dice [0.9494] 
2025-07-12 01:27:11.680488: Epoch time: 140.43 s 
2025-07-12 01:27:13.686090:  
2025-07-12 01:27:13.686951: Epoch 303 
2025-07-12 01:27:13.687333: Current learning rate: 0.00723 
2025-07-12 01:29:38.360457: train_loss -0.7736 
2025-07-12 01:29:38.362269: val_loss -0.7658 
2025-07-12 01:29:38.362596: Pseudo dice [0.941] 
2025-07-12 01:29:38.362919: Epoch time: 144.68 s 
2025-07-12 01:29:39.974129:  
2025-07-12 01:29:39.974663: Epoch 304 
2025-07-12 01:29:39.974922: Current learning rate: 0.00722 
2025-07-12 01:32:03.188461: train_loss -0.7755 
2025-07-12 01:32:03.190336: val_loss -0.7711 
2025-07-12 01:32:03.190750: Pseudo dice [0.9553] 
2025-07-12 01:32:03.190957: Epoch time: 143.22 s 
2025-07-12 01:32:07.651488:  
2025-07-12 01:32:07.651883: Epoch 305 
2025-07-12 01:32:07.652016: Current learning rate: 0.00721 
2025-07-12 01:34:29.016141: train_loss -0.7709 
2025-07-12 01:34:29.017521: val_loss -0.7711 
2025-07-12 01:34:29.017624: Pseudo dice [0.9391] 
2025-07-12 01:34:29.017726: Epoch time: 141.37 s 
2025-07-12 01:34:30.861655:  
2025-07-12 01:34:30.862547: Epoch 306 
2025-07-12 01:34:30.862923: Current learning rate: 0.0072 
2025-07-12 01:36:55.228991: train_loss -0.7714 
2025-07-12 01:36:55.230145: val_loss -0.7884 
2025-07-12 01:36:55.230230: Pseudo dice [0.9423] 
2025-07-12 01:36:55.230428: Epoch time: 144.37 s 
2025-07-12 01:36:57.448948:  
2025-07-12 01:36:57.449898: Epoch 307 
2025-07-12 01:36:57.450176: Current learning rate: 0.00719 
2025-07-12 01:39:21.412682: train_loss -0.7655 
2025-07-12 01:39:21.413918: val_loss -0.7956 
2025-07-12 01:39:21.414011: Pseudo dice [0.9474] 
2025-07-12 01:39:21.414090: Epoch time: 143.97 s 
2025-07-12 01:39:22.972551:  
2025-07-12 01:39:22.972998: Epoch 308 
2025-07-12 01:39:22.973230: Current learning rate: 0.00718 
2025-07-12 01:41:44.481039: train_loss -0.7744 
2025-07-12 01:41:44.482504: val_loss -0.8033 
2025-07-12 01:41:44.482595: Pseudo dice [0.9427] 
2025-07-12 01:41:44.482703: Epoch time: 141.51 s 
2025-07-12 01:41:46.216437:  
2025-07-12 01:41:46.217733: Epoch 309 
2025-07-12 01:41:46.218139: Current learning rate: 0.00717 
2025-07-12 01:44:12.194501: train_loss -0.7788 
2025-07-12 01:44:12.195881: val_loss -0.7774 
2025-07-12 01:44:12.195968: Pseudo dice [0.9444] 
2025-07-12 01:44:12.196074: Epoch time: 145.98 s 
2025-07-12 01:44:13.876988:  
2025-07-12 01:44:13.878145: Epoch 310 
2025-07-12 01:44:13.878452: Current learning rate: 0.00716 
2025-07-12 01:46:36.891877: train_loss -0.7797 
2025-07-12 01:46:36.893336: val_loss -0.7829 
2025-07-12 01:46:36.893429: Pseudo dice [0.9413] 
2025-07-12 01:46:36.893545: Epoch time: 143.02 s 
2025-07-12 01:46:38.550567:  
2025-07-12 01:46:38.551535: Epoch 311 
2025-07-12 01:46:38.551924: Current learning rate: 0.00715 
2025-07-12 01:49:03.013275: train_loss -0.7653 
2025-07-12 01:49:03.015749: val_loss -0.8118 
2025-07-12 01:49:03.015846: Pseudo dice [0.946] 
2025-07-12 01:49:03.015986: Epoch time: 144.46 s 
2025-07-12 01:49:04.789013:  
2025-07-12 01:49:04.790080: Epoch 312 
2025-07-12 01:49:04.790670: Current learning rate: 0.00714 
2025-07-12 01:51:27.451851: train_loss -0.7802 
2025-07-12 01:51:27.453082: val_loss -0.8164 
2025-07-12 01:51:27.453277: Pseudo dice [0.9495] 
2025-07-12 01:51:27.453401: Epoch time: 142.66 s 
2025-07-12 01:51:27.453456: Yayy! New best EMA pseudo Dice: 0.9423 
2025-07-12 01:51:30.743133:  
2025-07-12 01:51:30.743496: Epoch 313 
2025-07-12 01:51:30.743690: Current learning rate: 0.00713 
2025-07-12 01:53:50.328525: train_loss -0.7859 
2025-07-12 01:53:50.329849: val_loss -0.808 
2025-07-12 01:53:50.329973: Pseudo dice [0.9422] 
2025-07-12 01:53:50.330112: Epoch time: 139.59 s 
2025-07-12 01:53:52.086008:  
2025-07-12 01:53:52.087393: Epoch 314 
2025-07-12 01:53:52.087980: Current learning rate: 0.00712 
2025-07-12 01:56:16.914322: train_loss -0.7631 
2025-07-12 01:56:16.915489: val_loss -0.8035 
2025-07-12 01:56:16.915604: Pseudo dice [0.9388] 
2025-07-12 01:56:16.915720: Epoch time: 144.83 s 
2025-07-12 01:56:18.813663:  
2025-07-12 01:56:18.814655: Epoch 315 
2025-07-12 01:56:18.815101: Current learning rate: 0.00711 
2025-07-12 01:58:46.264991: train_loss -0.7759 
2025-07-12 01:58:46.266227: val_loss -0.8032 
2025-07-12 01:58:46.266367: Pseudo dice [0.9384] 
2025-07-12 01:58:46.266503: Epoch time: 147.45 s 
2025-07-12 01:58:47.944924:  
2025-07-12 01:58:47.945445: Epoch 316 
2025-07-12 01:58:47.945687: Current learning rate: 0.0071 
2025-07-12 02:01:11.869678: train_loss -0.7806 
2025-07-12 02:01:11.871314: val_loss -0.7843 
2025-07-12 02:01:11.871589: Pseudo dice [0.9475] 
2025-07-12 02:01:11.871835: Epoch time: 143.93 s 
2025-07-12 02:01:13.849672:  
2025-07-12 02:01:13.850561: Epoch 317 
2025-07-12 02:01:13.850916: Current learning rate: 0.0071 
2025-07-12 02:03:36.035679: train_loss -0.778 
2025-07-12 02:03:36.036969: val_loss -0.8225 
2025-07-12 02:03:36.037062: Pseudo dice [0.9577] 
2025-07-12 02:03:36.037169: Epoch time: 142.19 s 
2025-07-12 02:03:36.037221: Yayy! New best EMA pseudo Dice: 0.9437 
2025-07-12 02:03:38.933727:  
2025-07-12 02:03:38.934128: Epoch 318 
2025-07-12 02:03:38.934232: Current learning rate: 0.00709 
2025-07-12 02:05:58.569598: train_loss -0.7843 
2025-07-12 02:05:58.570924: val_loss -0.7797 
2025-07-12 02:05:58.571043: Pseudo dice [0.9532] 
2025-07-12 02:05:58.571187: Epoch time: 139.64 s 
2025-07-12 02:05:58.571259: Yayy! New best EMA pseudo Dice: 0.9447 
2025-07-12 02:06:02.385758:  
2025-07-12 02:06:02.386515: Epoch 319 
2025-07-12 02:06:02.386865: Current learning rate: 0.00708 
2025-07-12 02:08:23.919192: train_loss -0.7695 
2025-07-12 02:08:23.920601: val_loss -0.7903 
2025-07-12 02:08:23.920747: Pseudo dice [0.9499] 
2025-07-12 02:08:23.920858: Epoch time: 141.54 s 
2025-07-12 02:08:23.920944: Yayy! New best EMA pseudo Dice: 0.9452 
2025-07-12 02:08:27.091959:  
2025-07-12 02:08:27.092508: Epoch 320 
2025-07-12 02:08:27.092764: Current learning rate: 0.00707 
2025-07-12 02:10:45.772222: train_loss -0.7698 
2025-07-12 02:10:45.773529: val_loss -0.8259 
2025-07-12 02:10:45.773676: Pseudo dice [0.952] 
2025-07-12 02:10:45.773812: Epoch time: 138.68 s 
2025-07-12 02:10:45.773899: Yayy! New best EMA pseudo Dice: 0.9459 
2025-07-12 02:10:48.867226:  
2025-07-12 02:10:48.867979: Epoch 321 
2025-07-12 02:10:48.868334: Current learning rate: 0.00706 
2025-07-12 02:13:08.625242: train_loss -0.7897 
2025-07-12 02:13:08.626722: val_loss -0.799 
2025-07-12 02:13:08.626791: Pseudo dice [0.9537] 
2025-07-12 02:13:08.626855: Epoch time: 139.76 s 
2025-07-12 02:13:08.626892: Yayy! New best EMA pseudo Dice: 0.9467 
2025-07-12 02:13:11.025644:  
2025-07-12 02:13:11.026035: Epoch 322 
2025-07-12 02:13:11.026133: Current learning rate: 0.00705 
2025-07-12 02:15:30.691285: train_loss -0.778 
2025-07-12 02:15:30.692414: val_loss -0.7947 
2025-07-12 02:15:30.692498: Pseudo dice [0.9562] 
2025-07-12 02:15:30.692587: Epoch time: 139.67 s 
2025-07-12 02:15:30.692632: Yayy! New best EMA pseudo Dice: 0.9476 
2025-07-12 02:15:34.079871:  
2025-07-12 02:15:34.080564: Epoch 323 
2025-07-12 02:15:34.080846: Current learning rate: 0.00704 
2025-07-12 02:17:58.705148: train_loss -0.7791 
2025-07-12 02:17:58.706504: val_loss -0.7989 
2025-07-12 02:17:58.706685: Pseudo dice [0.9479] 
2025-07-12 02:17:58.706823: Epoch time: 144.63 s 
2025-07-12 02:17:58.706925: Yayy! New best EMA pseudo Dice: 0.9477 
2025-07-12 02:18:03.307067:  
2025-07-12 02:18:03.307490: Epoch 324 
2025-07-12 02:18:03.307605: Current learning rate: 0.00703 
2025-07-12 02:20:26.622025: train_loss -0.7577 
2025-07-12 02:20:26.623820: val_loss -0.7705 
2025-07-12 02:20:26.624231: Pseudo dice [0.9479] 
2025-07-12 02:20:26.624574: Epoch time: 143.32 s 
2025-07-12 02:20:26.625061: Yayy! New best EMA pseudo Dice: 0.9477 
2025-07-12 02:20:28.928062:  
2025-07-12 02:20:28.928406: Epoch 325 
2025-07-12 02:20:28.928528: Current learning rate: 0.00702 
2025-07-12 02:22:49.841880: train_loss -0.7808 
2025-07-12 02:22:49.843045: val_loss -0.8162 
2025-07-12 02:22:49.843128: Pseudo dice [0.9478] 
2025-07-12 02:22:49.843211: Epoch time: 140.91 s 
2025-07-12 02:22:49.843265: Yayy! New best EMA pseudo Dice: 0.9477 
2025-07-12 02:22:52.605734:  
2025-07-12 02:22:52.606334: Epoch 326 
2025-07-12 02:22:52.606548: Current learning rate: 0.00701 
2025-07-12 02:25:15.323340: train_loss -0.7727 
2025-07-12 02:25:15.324302: val_loss -0.7903 
2025-07-12 02:25:15.324379: Pseudo dice [0.9188] 
2025-07-12 02:25:15.324467: Epoch time: 142.72 s 
2025-07-12 02:25:17.091675:  
2025-07-12 02:25:17.092736: Epoch 327 
2025-07-12 02:25:17.093091: Current learning rate: 0.007 
2025-07-12 02:27:40.602272: train_loss -0.7601 
2025-07-12 02:27:40.603852: val_loss -0.7949 
2025-07-12 02:27:40.603945: Pseudo dice [0.9515] 
2025-07-12 02:27:40.604051: Epoch time: 143.51 s 
2025-07-12 02:27:42.665845:  
2025-07-12 02:27:42.667431: Epoch 328 
2025-07-12 02:27:42.667909: Current learning rate: 0.00699 
2025-07-12 02:30:09.048749: train_loss -0.7736 
2025-07-12 02:30:09.049693: val_loss -0.7938 
2025-07-12 02:30:09.049779: Pseudo dice [0.956] 
2025-07-12 02:30:09.049867: Epoch time: 146.39 s 
2025-07-12 02:30:10.665397:  
2025-07-12 02:30:10.666495: Epoch 329 
2025-07-12 02:30:10.666836: Current learning rate: 0.00698 
2025-07-12 02:32:34.028794: train_loss -0.7744 
2025-07-12 02:32:34.029900: val_loss -0.806 
2025-07-12 02:32:34.029959: Pseudo dice [0.9497] 
2025-07-12 02:32:34.030047: Epoch time: 143.37 s 
2025-07-12 02:32:35.540197:  
2025-07-12 02:32:35.540679: Epoch 330 
2025-07-12 02:32:35.540918: Current learning rate: 0.00697 
2025-07-12 02:34:57.850523: train_loss -0.771 
2025-07-12 02:34:57.851828: val_loss -0.7686 
2025-07-12 02:34:57.851913: Pseudo dice [0.9378] 
2025-07-12 02:34:57.852006: Epoch time: 142.31 s 
2025-07-12 02:34:59.753159:  
2025-07-12 02:34:59.754380: Epoch 331 
2025-07-12 02:34:59.754692: Current learning rate: 0.00696 
2025-07-12 02:37:28.705395: train_loss -0.7759 
2025-07-12 02:37:28.706989: val_loss -0.7753 
2025-07-12 02:37:28.707669: Pseudo dice [0.9403] 
2025-07-12 02:37:28.708072: Epoch time: 148.95 s 
2025-07-12 02:37:30.502181:  
2025-07-12 02:37:30.503093: Epoch 332 
2025-07-12 02:37:30.503433: Current learning rate: 0.00696 
2025-07-12 02:39:52.804091: train_loss -0.7786 
2025-07-12 02:39:52.805655: val_loss -0.7979 
2025-07-12 02:39:52.805740: Pseudo dice [0.9557] 
2025-07-12 02:39:52.805846: Epoch time: 142.3 s 
2025-07-12 02:39:54.843478:  
2025-07-12 02:39:54.844447: Epoch 333 
2025-07-12 02:39:54.844879: Current learning rate: 0.00695 
2025-07-12 02:42:19.006768: train_loss -0.7803 
2025-07-12 02:42:19.008276: val_loss -0.7841 
2025-07-12 02:42:19.008383: Pseudo dice [0.9556] 
2025-07-12 02:42:19.008488: Epoch time: 144.17 s 
2025-07-12 02:42:20.923923:  
2025-07-12 02:42:20.925137: Epoch 334 
2025-07-12 02:42:20.925554: Current learning rate: 0.00694 
2025-07-12 02:44:43.791734: train_loss -0.7851 
2025-07-12 02:44:43.794195: val_loss -0.8107 
2025-07-12 02:44:43.794955: Pseudo dice [0.951] 
2025-07-12 02:44:43.795397: Epoch time: 142.87 s 
2025-07-12 02:44:45.739972:  
2025-07-12 02:44:45.740957: Epoch 335 
2025-07-12 02:44:45.741343: Current learning rate: 0.00693 
2025-07-12 02:47:10.291899: train_loss -0.7897 
2025-07-12 02:47:10.293017: val_loss -0.7755 
2025-07-12 02:47:10.293138: Pseudo dice [0.9537] 
2025-07-12 02:47:10.293261: Epoch time: 144.55 s 
2025-07-12 02:47:10.293334: Yayy! New best EMA pseudo Dice: 0.9483 
2025-07-12 02:47:13.772676:  
2025-07-12 02:47:13.773494: Epoch 336 
2025-07-12 02:47:13.773788: Current learning rate: 0.00692 
2025-07-12 02:49:35.585908: train_loss -0.7916 
2025-07-12 02:49:35.586734: val_loss -0.7737 
2025-07-12 02:49:35.586797: Pseudo dice [0.9436] 
2025-07-12 02:49:35.586880: Epoch time: 141.82 s 
2025-07-12 02:49:37.185263:  
2025-07-12 02:49:37.185955: Epoch 337 
2025-07-12 02:49:37.186215: Current learning rate: 0.00691 
2025-07-12 02:51:57.840632: train_loss -0.7759 
2025-07-12 02:51:57.842018: val_loss -0.8279 
2025-07-12 02:51:57.842102: Pseudo dice [0.9547] 
2025-07-12 02:51:57.842241: Epoch time: 140.66 s 
2025-07-12 02:51:57.842307: Yayy! New best EMA pseudo Dice: 0.9485 
2025-07-12 02:52:01.142699:  
2025-07-12 02:52:01.143371: Epoch 338 
2025-07-12 02:52:01.143696: Current learning rate: 0.0069 
2025-07-12 02:54:22.420030: train_loss -0.7843 
2025-07-12 02:54:22.421284: val_loss -0.807 
2025-07-12 02:54:22.421361: Pseudo dice [0.9481] 
2025-07-12 02:54:22.421444: Epoch time: 141.28 s 
2025-07-12 02:54:24.435762:  
2025-07-12 02:54:24.437155: Epoch 339 
2025-07-12 02:54:24.437543: Current learning rate: 0.00689 
2025-07-12 02:56:49.526475: train_loss -0.7787 
2025-07-12 02:56:49.527309: val_loss -0.8041 
2025-07-12 02:56:49.527379: Pseudo dice [0.9514] 
2025-07-12 02:56:49.527473: Epoch time: 145.09 s 
2025-07-12 02:56:49.527528: Yayy! New best EMA pseudo Dice: 0.9488 
2025-07-12 02:56:51.709063:  
2025-07-12 02:56:51.709470: Epoch 340 
2025-07-12 02:56:51.709573: Current learning rate: 0.00688 
2025-07-12 02:59:13.853638: train_loss -0.7929 
2025-07-12 02:59:13.854976: val_loss -0.7872 
2025-07-12 02:59:13.855056: Pseudo dice [0.9573] 
2025-07-12 02:59:13.855163: Epoch time: 142.15 s 
2025-07-12 02:59:13.855219: Yayy! New best EMA pseudo Dice: 0.9496 
2025-07-12 02:59:17.559093:  
2025-07-12 02:59:17.559835: Epoch 341 
2025-07-12 02:59:17.560211: Current learning rate: 0.00687 
2025-07-12 03:01:37.899075: train_loss -0.7936 
2025-07-12 03:01:37.900530: val_loss -0.7824 
2025-07-12 03:01:37.900613: Pseudo dice [0.9452] 
2025-07-12 03:01:37.900705: Epoch time: 140.34 s 
2025-07-12 03:01:43.695119:  
2025-07-12 03:01:43.695523: Epoch 342 
2025-07-12 03:01:43.695639: Current learning rate: 0.00686 
2025-07-12 03:04:02.082288: train_loss -0.7845 
2025-07-12 03:04:02.096510: val_loss -0.7559 
2025-07-12 03:04:02.097236: Pseudo dice [0.9537] 
2025-07-12 03:04:02.097389: Epoch time: 138.39 s 
2025-07-12 03:04:02.097463: Yayy! New best EMA pseudo Dice: 0.9496 
2025-07-12 03:04:05.452449:  
2025-07-12 03:04:05.453188: Epoch 343 
2025-07-12 03:04:05.453476: Current learning rate: 0.00685 
2025-07-12 03:06:25.536479: train_loss -0.7621 
2025-07-12 03:06:25.537927: val_loss -0.8054 
2025-07-12 03:06:25.538022: Pseudo dice [0.9525] 
2025-07-12 03:06:25.538110: Epoch time: 140.09 s 
2025-07-12 03:06:25.538166: Yayy! New best EMA pseudo Dice: 0.9499 
2025-07-12 03:06:29.159234:  
2025-07-12 03:06:29.160327: Epoch 344 
2025-07-12 03:06:29.160693: Current learning rate: 0.00684 
2025-07-12 03:08:56.975452: train_loss -0.7865 
2025-07-12 03:08:56.977371: val_loss -0.8091 
2025-07-12 03:08:56.977798: Pseudo dice [0.9529] 
2025-07-12 03:08:56.978316: Epoch time: 147.82 s 
2025-07-12 03:08:56.978527: Yayy! New best EMA pseudo Dice: 0.9502 
2025-07-12 03:09:00.016456:  
2025-07-12 03:09:00.016895: Epoch 345 
2025-07-12 03:09:00.017083: Current learning rate: 0.00683 
2025-07-12 03:11:20.954863: train_loss -0.772 
2025-07-12 03:11:20.955916: val_loss -0.8048 
2025-07-12 03:11:20.955999: Pseudo dice [0.946] 
2025-07-12 03:11:20.956085: Epoch time: 140.94 s 
2025-07-12 03:11:22.754637:  
2025-07-12 03:11:22.755774: Epoch 346 
2025-07-12 03:11:22.756114: Current learning rate: 0.00682 
2025-07-12 03:13:46.181139: train_loss -0.7762 
2025-07-12 03:13:46.182805: val_loss -0.7682 
2025-07-12 03:13:46.183126: Pseudo dice [0.9168] 
2025-07-12 03:13:46.183340: Epoch time: 143.43 s 
2025-07-12 03:13:48.355423:  
2025-07-12 03:13:48.356757: Epoch 347 
2025-07-12 03:13:48.357174: Current learning rate: 0.00681 
2025-07-12 03:16:11.100415: train_loss -0.7696 
2025-07-12 03:16:11.101583: val_loss -0.7668 
2025-07-12 03:16:11.101706: Pseudo dice [0.9382] 
2025-07-12 03:16:11.101814: Epoch time: 142.75 s 
2025-07-12 03:16:13.493587:  
2025-07-12 03:16:13.495222: Epoch 348 
2025-07-12 03:16:13.495786: Current learning rate: 0.0068 
2025-07-12 03:18:40.797726: train_loss -0.7749 
2025-07-12 03:18:40.799229: val_loss -0.7969 
2025-07-12 03:18:40.799500: Pseudo dice [0.9443] 
2025-07-12 03:18:40.799693: Epoch time: 147.31 s 
2025-07-12 03:18:42.303874:  
2025-07-12 03:18:42.304827: Epoch 349 
2025-07-12 03:18:42.305085: Current learning rate: 0.0068 
2025-07-12 03:21:00.820018: train_loss -0.7829 
2025-07-12 03:21:00.821747: val_loss -0.8119 
2025-07-12 03:21:00.822090: Pseudo dice [0.9553] 
2025-07-12 03:21:00.822379: Epoch time: 138.52 s 
2025-07-12 03:21:04.119109:  
2025-07-12 03:21:04.119954: Epoch 350 
2025-07-12 03:21:04.120256: Current learning rate: 0.00679 
2025-07-12 03:23:24.701452: train_loss -0.7847 
2025-07-12 03:23:24.702567: val_loss -0.8268 
2025-07-12 03:23:24.702647: Pseudo dice [0.9531] 
2025-07-12 03:23:24.702754: Epoch time: 140.58 s 
2025-07-12 03:23:26.914016:  
2025-07-12 03:23:26.914998: Epoch 351 
2025-07-12 03:23:26.915402: Current learning rate: 0.00678 
2025-07-12 03:25:53.962382: train_loss -0.7917 
2025-07-12 03:25:53.963506: val_loss -0.8106 
2025-07-12 03:25:53.963675: Pseudo dice [0.9584] 
2025-07-12 03:25:53.963818: Epoch time: 147.05 s 
2025-07-12 03:25:55.418318:  
2025-07-12 03:25:55.418740: Epoch 352 
2025-07-12 03:25:55.418895: Current learning rate: 0.00677 
2025-07-12 03:28:15.665910: train_loss -0.782 
2025-07-12 03:28:15.667176: val_loss -0.8188 
2025-07-12 03:28:15.667280: Pseudo dice [0.9543] 
2025-07-12 03:28:15.667381: Epoch time: 140.25 s 
2025-07-12 03:28:17.699151:  
2025-07-12 03:28:17.700271: Epoch 353 
2025-07-12 03:28:17.700727: Current learning rate: 0.00676 
2025-07-12 03:30:41.685996: train_loss -0.7885 
2025-07-12 03:30:41.686824: val_loss -0.8156 
2025-07-12 03:30:41.686898: Pseudo dice [0.9535] 
2025-07-12 03:30:41.686989: Epoch time: 143.99 s 
2025-07-12 03:30:43.271540:  
2025-07-12 03:30:43.272265: Epoch 354 
2025-07-12 03:30:43.272564: Current learning rate: 0.00675 
2025-07-12 03:33:04.958392: train_loss -0.791 
2025-07-12 03:33:04.959877: val_loss -0.8126 
2025-07-12 03:33:04.960062: Pseudo dice [0.954] 
2025-07-12 03:33:04.960235: Epoch time: 141.69 s 
2025-07-12 03:33:07.087219:  
2025-07-12 03:33:07.088154: Epoch 355 
2025-07-12 03:33:07.088609: Current learning rate: 0.00674 
2025-07-12 03:35:32.759628: train_loss -0.7786 
2025-07-12 03:35:32.760233: val_loss -0.7733 
2025-07-12 03:35:32.760306: Pseudo dice [0.9383] 
2025-07-12 03:35:32.760376: Epoch time: 145.67 s 
2025-07-12 03:35:34.071998:  
2025-07-12 03:35:34.072362: Epoch 356 
2025-07-12 03:35:34.072475: Current learning rate: 0.00673 
2025-07-12 03:37:57.574710: train_loss -0.7738 
2025-07-12 03:37:57.575853: val_loss -0.7861 
2025-07-12 03:37:57.575935: Pseudo dice [0.9526] 
2025-07-12 03:37:57.576039: Epoch time: 143.5 s 
2025-07-12 03:37:59.265601:  
2025-07-12 03:37:59.266286: Epoch 357 
2025-07-12 03:37:59.266567: Current learning rate: 0.00672 
2025-07-12 03:40:24.432093: train_loss -0.7797 
2025-07-12 03:40:24.433666: val_loss -0.7866 
2025-07-12 03:40:24.433828: Pseudo dice [0.9543] 
2025-07-12 03:40:24.434005: Epoch time: 145.17 s 
2025-07-12 03:40:26.084664:  
2025-07-12 03:40:26.085377: Epoch 358 
2025-07-12 03:40:26.085704: Current learning rate: 0.00671 
2025-07-12 03:42:52.356107: train_loss -0.7877 
2025-07-12 03:42:52.357429: val_loss -0.7961 
2025-07-12 03:42:52.357512: Pseudo dice [0.9394] 
2025-07-12 03:42:52.357613: Epoch time: 146.27 s 
2025-07-12 03:42:54.396588:  
2025-07-12 03:42:54.397256: Epoch 359 
2025-07-12 03:42:54.397490: Current learning rate: 0.0067 
2025-07-12 03:45:17.759695: train_loss -0.7713 
2025-07-12 03:45:17.760919: val_loss -0.7975 
2025-07-12 03:45:17.761043: Pseudo dice [0.9427] 
2025-07-12 03:45:17.761186: Epoch time: 143.36 s 
2025-07-12 03:45:19.222249:  
2025-07-12 03:45:19.222925: Epoch 360 
2025-07-12 03:45:19.223258: Current learning rate: 0.00669 
2025-07-12 03:47:42.182699: train_loss -0.7922 
2025-07-12 03:47:42.185056: val_loss -0.7933 
2025-07-12 03:47:42.185397: Pseudo dice [0.951] 
2025-07-12 03:47:42.185516: Epoch time: 142.96 s 
2025-07-12 03:47:47.057516:  
2025-07-12 03:47:47.057893: Epoch 361 
2025-07-12 03:47:47.057969: Current learning rate: 0.00668 
2025-07-12 03:50:10.594105: train_loss -0.7959 
2025-07-12 03:50:10.595658: val_loss -0.7757 
2025-07-12 03:50:10.595860: Pseudo dice [0.9465] 
2025-07-12 03:50:10.596022: Epoch time: 143.54 s 
2025-07-12 03:50:12.747290:  
2025-07-12 03:50:12.748438: Epoch 362 
2025-07-12 03:50:12.748810: Current learning rate: 0.00667 
2025-07-12 03:52:42.170881: train_loss -0.7692 
2025-07-12 03:52:42.172264: val_loss -0.7898 
2025-07-12 03:52:42.172394: Pseudo dice [0.953] 
2025-07-12 03:52:42.172549: Epoch time: 149.43 s 
2025-07-12 03:52:43.909206:  
2025-07-12 03:52:43.910548: Epoch 363 
2025-07-12 03:52:43.910951: Current learning rate: 0.00666 
2025-07-12 03:55:11.180786: train_loss -0.7707 
2025-07-12 03:55:11.182339: val_loss -0.7791 
2025-07-12 03:55:11.182608: Pseudo dice [0.9457] 
2025-07-12 03:55:11.182842: Epoch time: 147.27 s 
2025-07-12 03:55:12.915858:  
2025-07-12 03:55:12.916639: Epoch 364 
2025-07-12 03:55:12.916922: Current learning rate: 0.00665 
2025-07-12 03:57:34.268013: train_loss -0.7615 
2025-07-12 03:57:34.269013: val_loss -0.7821 
2025-07-12 03:57:34.269122: Pseudo dice [0.9398] 
2025-07-12 03:57:34.269219: Epoch time: 141.35 s 
2025-07-12 03:57:36.128344:  
2025-07-12 03:57:36.129496: Epoch 365 
2025-07-12 03:57:36.129882: Current learning rate: 0.00665 
2025-07-12 03:59:57.274583: train_loss -0.7759 
2025-07-12 03:59:57.275735: val_loss -0.7925 
2025-07-12 03:59:57.275828: Pseudo dice [0.9521] 
2025-07-12 03:59:57.275926: Epoch time: 141.15 s 
2025-07-12 03:59:59.222195:  
2025-07-12 03:59:59.223274: Epoch 366 
2025-07-12 03:59:59.223590: Current learning rate: 0.00664 
2025-07-12 04:02:23.198670: train_loss -0.7683 
2025-07-12 04:02:23.200150: val_loss -0.7975 
2025-07-12 04:02:23.200262: Pseudo dice [0.9538] 
2025-07-12 04:02:23.200353: Epoch time: 143.98 s 
2025-07-12 04:02:24.947047:  
2025-07-12 04:02:24.947886: Epoch 367 
2025-07-12 04:02:24.948337: Current learning rate: 0.00663 
2025-07-12 04:04:47.119997: train_loss -0.7868 
2025-07-12 04:04:47.121640: val_loss -0.7836 
2025-07-12 04:04:47.121928: Pseudo dice [0.9424] 
2025-07-12 04:04:47.122089: Epoch time: 142.17 s 
2025-07-12 04:04:48.769182:  
2025-07-12 04:04:48.770007: Epoch 368 
2025-07-12 04:04:48.770290: Current learning rate: 0.00662 
2025-07-12 04:07:11.275675: train_loss -0.7831 
2025-07-12 04:07:11.276698: val_loss -0.8178 
2025-07-12 04:07:11.276773: Pseudo dice [0.9504] 
2025-07-12 04:07:11.276916: Epoch time: 142.51 s 
2025-07-12 04:07:12.923663:  
2025-07-12 04:07:12.924676: Epoch 369 
2025-07-12 04:07:12.924995: Current learning rate: 0.00661 
2025-07-12 04:09:33.725332: train_loss -0.7758 
2025-07-12 04:09:33.729516: val_loss -0.7798 
2025-07-12 04:09:33.729729: Pseudo dice [0.9446] 
2025-07-12 04:09:33.729878: Epoch time: 140.8 s 
2025-07-12 04:09:35.441815:  
2025-07-12 04:09:35.442570: Epoch 370 
2025-07-12 04:09:35.442891: Current learning rate: 0.0066 
2025-07-12 04:12:00.740278: train_loss -0.7813 
2025-07-12 04:12:00.741861: val_loss -0.7828 
2025-07-12 04:12:00.743187: Pseudo dice [0.9584] 
2025-07-12 04:12:00.743309: Epoch time: 145.3 s 
2025-07-12 04:12:02.616421:  
2025-07-12 04:12:02.617400: Epoch 371 
2025-07-12 04:12:02.617799: Current learning rate: 0.00659 
2025-07-12 04:14:28.060600: train_loss -0.7688 
2025-07-12 04:14:28.061760: val_loss -0.7905 
2025-07-12 04:14:28.061848: Pseudo dice [0.944] 
2025-07-12 04:14:28.061963: Epoch time: 145.45 s 
2025-07-12 04:14:30.197318:  
2025-07-12 04:14:30.198651: Epoch 372 
2025-07-12 04:14:30.199262: Current learning rate: 0.00658 
2025-07-12 04:16:59.587682: train_loss -0.7663 
2025-07-12 04:16:59.588647: val_loss -0.7862 
2025-07-12 04:16:59.588735: Pseudo dice [0.9503] 
2025-07-12 04:16:59.588814: Epoch time: 149.39 s 
2025-07-12 04:17:01.076078:  
2025-07-12 04:17:01.076912: Epoch 373 
2025-07-12 04:17:01.077267: Current learning rate: 0.00657 
2025-07-12 04:19:23.354235: train_loss -0.7839 
2025-07-12 04:19:23.355728: val_loss -0.7773 
2025-07-12 04:19:23.355954: Pseudo dice [0.9468] 
2025-07-12 04:19:23.356158: Epoch time: 142.28 s 
2025-07-12 04:19:25.330781:  
2025-07-12 04:19:25.332036: Epoch 374 
2025-07-12 04:19:25.332520: Current learning rate: 0.00656 
2025-07-12 04:21:47.850619: train_loss -0.7795 
2025-07-12 04:21:47.852382: val_loss -0.8204 
2025-07-12 04:21:47.852823: Pseudo dice [0.9558] 
2025-07-12 04:21:47.853279: Epoch time: 142.52 s 
2025-07-12 04:21:49.721279:  
2025-07-12 04:21:49.722147: Epoch 375 
2025-07-12 04:21:49.722502: Current learning rate: 0.00655 
2025-07-12 04:24:14.729395: train_loss -0.7821 
2025-07-12 04:24:14.730192: val_loss -0.7901 
2025-07-12 04:24:14.730266: Pseudo dice [0.9564] 
2025-07-12 04:24:14.730335: Epoch time: 145.01 s 
2025-07-12 04:24:16.192132:  
2025-07-12 04:24:16.192539: Epoch 376 
2025-07-12 04:24:16.192666: Current learning rate: 0.00654 
2025-07-12 04:26:37.789890: train_loss -0.7861 
2025-07-12 04:26:37.791334: val_loss -0.8147 
2025-07-12 04:26:37.791519: Pseudo dice [0.9587] 
2025-07-12 04:26:37.791694: Epoch time: 141.6 s 
2025-07-12 04:26:37.791807: Yayy! New best EMA pseudo Dice: 0.9507 
2025-07-12 04:26:41.052180:  
2025-07-12 04:26:41.052598: Epoch 377 
2025-07-12 04:26:41.052853: Current learning rate: 0.00653 
2025-07-12 04:29:02.820492: train_loss -0.7774 
2025-07-12 04:29:02.821227: val_loss -0.8273 
2025-07-12 04:29:02.821327: Pseudo dice [0.9566] 
2025-07-12 04:29:02.821419: Epoch time: 141.77 s 
2025-07-12 04:29:02.821472: Yayy! New best EMA pseudo Dice: 0.9513 
2025-07-12 04:29:05.822038:  
2025-07-12 04:29:05.822451: Epoch 378 
2025-07-12 04:29:05.822545: Current learning rate: 0.00652 
2025-07-12 04:31:28.825539: train_loss -0.7864 
2025-07-12 04:31:28.826670: val_loss -0.8057 
2025-07-12 04:31:28.826778: Pseudo dice [0.9452] 
2025-07-12 04:31:28.826876: Epoch time: 143.0 s 
2025-07-12 04:31:30.634497:  
2025-07-12 04:31:30.635562: Epoch 379 
2025-07-12 04:31:30.635949: Current learning rate: 0.00651 
2025-07-12 04:33:59.929838: train_loss -0.785 
2025-07-12 04:33:59.930956: val_loss -0.7769 
2025-07-12 04:33:59.931029: Pseudo dice [0.9558] 
2025-07-12 04:33:59.931209: Epoch time: 149.3 s 
2025-07-12 04:34:02.745258:  
2025-07-12 04:34:02.745630: Epoch 380 
2025-07-12 04:34:02.745700: Current learning rate: 0.0065 
2025-07-12 04:36:25.234399: train_loss -0.7827 
2025-07-12 04:36:25.236623: val_loss -0.773 
2025-07-12 04:36:25.236836: Pseudo dice [0.9444] 
2025-07-12 04:36:25.236938: Epoch time: 142.49 s 
2025-07-12 04:36:27.141486:  
2025-07-12 04:36:27.142384: Epoch 381 
2025-07-12 04:36:27.142841: Current learning rate: 0.00649 
2025-07-12 04:38:51.971321: train_loss -0.7734 
2025-07-12 04:38:51.972501: val_loss -0.8046 
2025-07-12 04:38:51.972666: Pseudo dice [0.9568] 
2025-07-12 04:38:51.972813: Epoch time: 144.83 s 
2025-07-12 04:38:53.571032:  
2025-07-12 04:38:53.571828: Epoch 382 
2025-07-12 04:38:53.572033: Current learning rate: 0.00648 
2025-07-12 04:41:19.197957: train_loss -0.7882 
2025-07-12 04:41:19.199165: val_loss -0.8105 
2025-07-12 04:41:19.199240: Pseudo dice [0.9618] 
2025-07-12 04:41:19.199356: Epoch time: 145.63 s 
2025-07-12 04:41:19.199411: Yayy! New best EMA pseudo Dice: 0.9522 
2025-07-12 04:41:22.679792:  
2025-07-12 04:41:22.680769: Epoch 383 
2025-07-12 04:41:22.681091: Current learning rate: 0.00648 
2025-07-12 04:43:45.628884: train_loss -0.7774 
2025-07-12 04:43:45.630761: val_loss -0.7967 
2025-07-12 04:43:45.630860: Pseudo dice [0.9604] 
2025-07-12 04:43:45.630965: Epoch time: 142.95 s 
2025-07-12 04:43:45.631019: Yayy! New best EMA pseudo Dice: 0.953 
2025-07-12 04:43:48.970159:  
2025-07-12 04:43:48.971018: Epoch 384 
2025-07-12 04:43:48.971256: Current learning rate: 0.00647 
2025-07-12 04:46:12.991862: train_loss -0.7925 
2025-07-12 04:46:12.993127: val_loss -0.8167 
2025-07-12 04:46:12.993199: Pseudo dice [0.9553] 
2025-07-12 04:46:12.993329: Epoch time: 144.02 s 
2025-07-12 04:46:12.993389: Yayy! New best EMA pseudo Dice: 0.9533 
2025-07-12 04:46:16.045755:  
2025-07-12 04:46:16.046240: Epoch 385 
2025-07-12 04:46:16.046484: Current learning rate: 0.00646 
2025-07-12 04:48:37.870699: train_loss -0.7828 
2025-07-12 04:48:37.872319: val_loss -0.7728 
2025-07-12 04:48:37.872556: Pseudo dice [0.9598] 
2025-07-12 04:48:37.872842: Epoch time: 141.83 s 
2025-07-12 04:48:37.873013: Yayy! New best EMA pseudo Dice: 0.9539 
2025-07-12 04:48:41.473457:  
2025-07-12 04:48:41.474376: Epoch 386 
2025-07-12 04:48:41.474816: Current learning rate: 0.00645 
2025-07-12 04:51:05.421948: train_loss -0.7752 
2025-07-12 04:51:05.422997: val_loss -0.8213 
2025-07-12 04:51:05.423079: Pseudo dice [0.9624] 
2025-07-12 04:51:05.423179: Epoch time: 143.95 s 
2025-07-12 04:51:05.423278: Yayy! New best EMA pseudo Dice: 0.9548 
2025-07-12 04:51:08.865377:  
2025-07-12 04:51:08.866372: Epoch 387 
2025-07-12 04:51:08.866693: Current learning rate: 0.00644 
2025-07-12 04:53:32.677646: train_loss -0.7911 
2025-07-12 04:53:32.678657: val_loss -0.7817 
2025-07-12 04:53:32.678733: Pseudo dice [0.96] 
2025-07-12 04:53:32.678815: Epoch time: 143.81 s 
2025-07-12 04:53:32.678859: Yayy! New best EMA pseudo Dice: 0.9553 
2025-07-12 04:53:34.954926:  
2025-07-12 04:53:34.955384: Epoch 388 
2025-07-12 04:53:34.955556: Current learning rate: 0.00643 
2025-07-12 04:56:00.719557: train_loss -0.7873 
2025-07-12 04:56:00.721333: val_loss -0.8063 
2025-07-12 04:56:00.721598: Pseudo dice [0.9596] 
2025-07-12 04:56:00.721859: Epoch time: 145.77 s 
2025-07-12 04:56:00.722023: Yayy! New best EMA pseudo Dice: 0.9557 
2025-07-12 04:56:03.679737:  
2025-07-12 04:56:03.680177: Epoch 389 
2025-07-12 04:56:03.680313: Current learning rate: 0.00642 
2025-07-12 04:58:23.774309: train_loss -0.7836 
2025-07-12 04:58:23.775664: val_loss -0.803 
2025-07-12 04:58:23.775757: Pseudo dice [0.9605] 
2025-07-12 04:58:23.775863: Epoch time: 140.1 s 
2025-07-12 04:58:23.775929: Yayy! New best EMA pseudo Dice: 0.9562 
2025-07-12 04:58:27.416861:  
2025-07-12 04:58:27.417744: Epoch 390 
2025-07-12 04:58:27.418066: Current learning rate: 0.00641 
2025-07-12 05:00:47.255147: train_loss -0.7828 
2025-07-12 05:00:47.256358: val_loss -0.7818 
2025-07-12 05:00:47.256479: Pseudo dice [0.9511] 
2025-07-12 05:00:47.256571: Epoch time: 139.84 s 
2025-07-12 05:00:49.169198:  
2025-07-12 05:00:49.170155: Epoch 391 
2025-07-12 05:00:49.170538: Current learning rate: 0.0064 
2025-07-12 05:03:13.074292: train_loss -0.7806 
2025-07-12 05:03:13.075852: val_loss -0.8212 
2025-07-12 05:03:13.075942: Pseudo dice [0.9426] 
2025-07-12 05:03:13.076051: Epoch time: 143.91 s 
2025-07-12 05:03:15.135736:  
2025-07-12 05:03:15.136887: Epoch 392 
2025-07-12 05:03:15.137401: Current learning rate: 0.00639 
2025-07-12 05:05:39.300837: train_loss -0.779 
2025-07-12 05:05:39.301790: val_loss -0.8041 
2025-07-12 05:05:39.301863: Pseudo dice [0.9581] 
2025-07-12 05:05:39.301964: Epoch time: 144.17 s 
2025-07-12 05:05:40.889987:  
2025-07-12 05:05:40.890729: Epoch 393 
2025-07-12 05:05:40.891136: Current learning rate: 0.00638 
2025-07-12 05:08:04.396975: train_loss -0.7741 
2025-07-12 05:08:04.398207: val_loss -0.7959 
2025-07-12 05:08:04.398409: Pseudo dice [0.9579] 
2025-07-12 05:08:04.398556: Epoch time: 143.51 s 
2025-07-12 05:08:06.143986:  
2025-07-12 05:08:06.144564: Epoch 394 
2025-07-12 05:08:06.144804: Current learning rate: 0.00637 
2025-07-12 05:10:30.375409: train_loss -0.7907 
2025-07-12 05:10:30.376599: val_loss -0.8066 
2025-07-12 05:10:30.389892: Pseudo dice [0.9532] 
2025-07-12 05:10:30.390661: Epoch time: 144.23 s 
2025-07-12 05:10:32.246945:  
2025-07-12 05:10:32.247666: Epoch 395 
2025-07-12 05:10:32.248010: Current learning rate: 0.00636 
2025-07-12 05:12:51.737513: train_loss -0.7879 
2025-07-12 05:12:51.738667: val_loss -0.8281 
2025-07-12 05:12:51.738753: Pseudo dice [0.9598] 
2025-07-12 05:12:51.738870: Epoch time: 139.49 s 
2025-07-12 05:12:53.769922:  
2025-07-12 05:12:53.770943: Epoch 396 
2025-07-12 05:12:53.771327: Current learning rate: 0.00635 
2025-07-12 05:15:18.423753: train_loss -0.7797 
2025-07-12 05:15:18.424651: val_loss -0.7709 
2025-07-12 05:15:18.424726: Pseudo dice [0.9595] 
2025-07-12 05:15:18.424815: Epoch time: 144.66 s 
2025-07-12 05:15:23.449020:  
2025-07-12 05:15:23.449476: Epoch 397 
2025-07-12 05:15:23.449661: Current learning rate: 0.00634 
2025-07-12 05:17:42.796795: train_loss -0.79 
2025-07-12 05:17:42.798272: val_loss -0.7902 
2025-07-12 05:17:42.798347: Pseudo dice [0.9542] 
2025-07-12 05:17:42.798437: Epoch time: 139.35 s 
2025-07-12 05:17:44.403225:  
2025-07-12 05:17:44.404374: Epoch 398 
2025-07-12 05:17:44.404728: Current learning rate: 0.00633 
2025-07-12 05:20:07.007065: train_loss -0.7873 
2025-07-12 05:20:07.008024: val_loss -0.7911 
2025-07-12 05:20:07.008101: Pseudo dice [0.956] 
2025-07-12 05:20:07.008192: Epoch time: 142.61 s 
2025-07-12 05:20:08.596165:  
2025-07-12 05:20:08.597217: Epoch 399 
2025-07-12 05:20:08.597526: Current learning rate: 0.00632 
2025-07-12 05:22:31.463459: train_loss -0.7739 
2025-07-12 05:22:31.465017: val_loss -0.8035 
2025-07-12 05:22:31.465209: Pseudo dice [0.9265] 
2025-07-12 05:22:31.465378: Epoch time: 142.87 s 
2025-07-12 05:22:35.296930:  
2025-07-12 05:22:35.297755: Epoch 400 
2025-07-12 05:22:35.298229: Current learning rate: 0.00631 
2025-07-12 05:24:59.761930: train_loss -0.7624 
2025-07-12 05:24:59.763494: val_loss -0.7983 
2025-07-12 05:24:59.763739: Pseudo dice [0.9537] 
2025-07-12 05:24:59.763923: Epoch time: 144.47 s 
2025-07-12 05:25:01.557976:  
2025-07-12 05:25:01.559232: Epoch 401 
2025-07-12 05:25:01.559659: Current learning rate: 0.0063 
2025-07-12 05:27:27.172295: train_loss -0.7743 
2025-07-12 05:27:27.173488: val_loss -0.8152 
2025-07-12 05:27:27.173609: Pseudo dice [0.9524] 
2025-07-12 05:27:27.173723: Epoch time: 145.62 s 
2025-07-12 05:27:29.024806:  
2025-07-12 05:27:29.026031: Epoch 402 
2025-07-12 05:27:29.026399: Current learning rate: 0.0063 
2025-07-12 05:29:52.281698: train_loss -0.7936 
2025-07-12 05:29:52.282880: val_loss -0.7958 
2025-07-12 05:29:52.282957: Pseudo dice [0.9566] 
2025-07-12 05:29:52.283055: Epoch time: 143.26 s 
2025-07-12 05:29:53.922013:  
2025-07-12 05:29:53.922991: Epoch 403 
2025-07-12 05:29:53.923386: Current learning rate: 0.00629 
2025-07-12 05:32:17.016317: train_loss -0.7731 
2025-07-12 05:32:17.017400: val_loss -0.7968 
2025-07-12 05:32:17.017475: Pseudo dice [0.9323] 
2025-07-12 05:32:17.017590: Epoch time: 143.1 s 
2025-07-12 05:32:18.952175:  
2025-07-12 05:32:18.953248: Epoch 404 
2025-07-12 05:32:18.953600: Current learning rate: 0.00628 
2025-07-12 05:34:44.945424: train_loss -0.7744 
2025-07-12 05:34:44.947648: val_loss -0.8231 
2025-07-12 05:34:44.948298: Pseudo dice [0.9429] 
2025-07-12 05:34:44.948576: Epoch time: 146.0 s 
2025-07-12 05:34:47.017291:  
2025-07-12 05:34:47.018411: Epoch 405 
2025-07-12 05:34:47.018793: Current learning rate: 0.00627 
2025-07-12 05:37:12.327551: train_loss -0.7757 
2025-07-12 05:37:12.328829: val_loss -0.7947 
2025-07-12 05:37:12.328935: Pseudo dice [0.9521] 
2025-07-12 05:37:12.329052: Epoch time: 145.31 s 
2025-07-12 05:37:14.350433:  
2025-07-12 05:37:14.351292: Epoch 406 
2025-07-12 05:37:14.351695: Current learning rate: 0.00626 
2025-07-12 05:39:40.714755: train_loss -0.7843 
2025-07-12 05:39:40.716190: val_loss -0.7976 
2025-07-12 05:39:40.716368: Pseudo dice [0.9563] 
2025-07-12 05:39:40.716538: Epoch time: 146.37 s 
2025-07-12 05:39:42.446035:  
2025-07-12 05:39:42.447061: Epoch 407 
2025-07-12 05:39:42.447446: Current learning rate: 0.00625 
2025-07-12 05:42:04.198278: train_loss -0.7899 
2025-07-12 05:42:04.199250: val_loss -0.7915 
2025-07-12 05:42:04.199323: Pseudo dice [0.9551] 
2025-07-12 05:42:04.199433: Epoch time: 141.75 s 
2025-07-12 05:42:06.116014:  
2025-07-12 05:42:06.116863: Epoch 408 
2025-07-12 05:42:06.117200: Current learning rate: 0.00624 
2025-07-12 05:44:29.878371: train_loss -0.7891 
2025-07-12 05:44:29.879283: val_loss -0.7757 
2025-07-12 05:44:29.879355: Pseudo dice [0.9588] 
2025-07-12 05:44:29.879438: Epoch time: 143.76 s 
2025-07-12 05:44:32.055681:  
2025-07-12 05:44:32.056781: Epoch 409 
2025-07-12 05:44:32.057245: Current learning rate: 0.00623 
2025-07-12 05:46:56.247652: train_loss -0.7816 
2025-07-12 05:46:56.248986: val_loss -0.8015 
2025-07-12 05:46:56.249089: Pseudo dice [0.9479] 
2025-07-12 05:46:56.249188: Epoch time: 144.19 s 
2025-07-12 05:46:58.180349:  
2025-07-12 05:46:58.181381: Epoch 410 
2025-07-12 05:46:58.181798: Current learning rate: 0.00622 
2025-07-12 05:49:23.157039: train_loss -0.7773 
2025-07-12 05:49:23.158219: val_loss -0.789 
2025-07-12 05:49:23.158301: Pseudo dice [0.944] 
2025-07-12 05:49:23.158394: Epoch time: 144.98 s 
2025-07-12 05:49:24.996917:  
2025-07-12 05:49:24.997921: Epoch 411 
2025-07-12 05:49:24.998344: Current learning rate: 0.00621 
2025-07-12 05:51:53.268605: train_loss -0.7747 
2025-07-12 05:51:53.269917: val_loss -0.789 
2025-07-12 05:51:53.270005: Pseudo dice [0.9522] 
2025-07-12 05:51:53.270091: Epoch time: 148.27 s 
2025-07-12 05:51:55.265988:  
2025-07-12 05:51:55.267000: Epoch 412 
2025-07-12 05:51:55.267454: Current learning rate: 0.0062 
2025-07-12 05:54:18.222184: train_loss -0.7878 
2025-07-12 05:54:18.223363: val_loss -0.8015 
2025-07-12 05:54:18.223437: Pseudo dice [0.9569] 
2025-07-12 05:54:18.223511: Epoch time: 142.96 s 
2025-07-12 05:54:19.700006:  
2025-07-12 05:54:19.700685: Epoch 413 
2025-07-12 05:54:19.701030: Current learning rate: 0.00619 
2025-07-12 05:56:45.124675: train_loss -0.7946 
2025-07-12 05:56:45.125646: val_loss -0.7985 
2025-07-12 05:56:45.125727: Pseudo dice [0.9607] 
2025-07-12 05:56:45.125809: Epoch time: 145.43 s 
2025-07-12 05:56:46.487405:  
2025-07-12 05:56:46.488210: Epoch 414 
2025-07-12 05:56:46.488485: Current learning rate: 0.00618 
2025-07-12 05:59:07.899537: train_loss -0.7785 
2025-07-12 05:59:07.901137: val_loss -0.7728 
2025-07-12 05:59:07.901334: Pseudo dice [0.9244] 
2025-07-12 05:59:07.901459: Epoch time: 141.41 s 
2025-07-12 05:59:09.429842:  
2025-07-12 05:59:09.430355: Epoch 415 
2025-07-12 05:59:09.430589: Current learning rate: 0.00617 
2025-07-12 06:01:33.211068: train_loss -0.7465 
2025-07-12 06:01:33.213166: val_loss -0.7932 
2025-07-12 06:01:33.213427: Pseudo dice [0.931] 
2025-07-12 06:01:33.213575: Epoch time: 143.78 s 
2025-07-12 06:01:38.373971:  
2025-07-12 06:01:38.374412: Epoch 416 
2025-07-12 06:01:38.374521: Current learning rate: 0.00616 
2025-07-12 06:04:00.095291: train_loss -0.7799 
2025-07-12 06:04:00.096493: val_loss -0.802 
2025-07-12 06:04:00.096610: Pseudo dice [0.9468] 
2025-07-12 06:04:00.096741: Epoch time: 141.72 s 
2025-07-12 06:04:01.763129:  
2025-07-12 06:04:01.764404: Epoch 417 
2025-07-12 06:04:01.764740: Current learning rate: 0.00615 
2025-07-12 06:06:28.485989: train_loss -0.7789 
2025-07-12 06:06:28.487190: val_loss -0.7949 
2025-07-12 06:06:28.487284: Pseudo dice [0.9444] 
2025-07-12 06:06:28.487401: Epoch time: 146.72 s 
2025-07-12 06:06:30.234246:  
2025-07-12 06:06:30.235168: Epoch 418 
2025-07-12 06:06:30.235435: Current learning rate: 0.00614 
2025-07-12 06:08:51.924901: train_loss -0.7619 
2025-07-12 06:08:51.926053: val_loss -0.7573 
2025-07-12 06:08:51.926203: Pseudo dice [0.9251] 
2025-07-12 06:08:51.926341: Epoch time: 141.69 s 
2025-07-12 06:08:53.969793:  
2025-07-12 06:08:53.970863: Epoch 419 
2025-07-12 06:08:53.971225: Current learning rate: 0.00613 
2025-07-12 06:11:18.703023: train_loss -0.78 
2025-07-12 06:11:18.704049: val_loss -0.7793 
2025-07-12 06:11:18.704130: Pseudo dice [0.945] 
2025-07-12 06:11:18.704218: Epoch time: 144.74 s 
2025-07-12 06:11:20.266992:  
2025-07-12 06:11:20.267820: Epoch 420 
2025-07-12 06:11:20.268049: Current learning rate: 0.00612 
2025-07-12 06:13:42.358480: train_loss -0.7796 
2025-07-12 06:13:42.360129: val_loss -0.7841 
2025-07-12 06:13:42.360394: Pseudo dice [0.95] 
2025-07-12 06:13:42.360573: Epoch time: 142.09 s 
2025-07-12 06:13:44.327358:  
2025-07-12 06:13:44.328537: Epoch 421 
2025-07-12 06:13:44.329153: Current learning rate: 0.00612 
2025-07-12 06:16:06.483062: train_loss -0.7719 
2025-07-12 06:16:06.484598: val_loss -0.786 
2025-07-12 06:16:06.484917: Pseudo dice [0.9524] 
2025-07-12 06:16:06.485112: Epoch time: 142.16 s 
2025-07-12 06:16:08.074290:  
2025-07-12 06:16:08.074839: Epoch 422 
2025-07-12 06:16:08.075011: Current learning rate: 0.00611 
2025-07-12 06:18:33.531613: train_loss -0.7665 
2025-07-12 06:18:33.532938: val_loss -0.7955 
2025-07-12 06:18:33.533097: Pseudo dice [0.9323] 
2025-07-12 06:18:33.533215: Epoch time: 145.46 s 
2025-07-12 06:18:35.390689:  
2025-07-12 06:18:35.391945: Epoch 423 
2025-07-12 06:18:35.392236: Current learning rate: 0.0061 
2025-07-12 06:20:57.661930: train_loss -0.7697 
2025-07-12 06:20:57.663161: val_loss -0.7837 
2025-07-12 06:20:57.663235: Pseudo dice [0.9511] 
2025-07-12 06:20:57.663337: Epoch time: 142.27 s 
2025-07-12 06:20:59.570273:  
2025-07-12 06:20:59.571373: Epoch 424 
2025-07-12 06:20:59.571853: Current learning rate: 0.00609 
2025-07-12 06:23:22.092309: train_loss -0.7574 
2025-07-12 06:23:22.093342: val_loss -0.8071 
2025-07-12 06:23:22.093415: Pseudo dice [0.9504] 
2025-07-12 06:23:22.093496: Epoch time: 142.52 s 
2025-07-12 06:23:23.977150:  
2025-07-12 06:23:23.978676: Epoch 425 
2025-07-12 06:23:23.979183: Current learning rate: 0.00608 
2025-07-12 06:25:47.412735: train_loss -0.7907 
2025-07-12 06:25:47.413841: val_loss -0.7919 
2025-07-12 06:25:47.413914: Pseudo dice [0.9479] 
2025-07-12 06:25:47.414015: Epoch time: 143.44 s 
2025-07-12 06:25:49.071832:  
2025-07-12 06:25:49.072877: Epoch 426 
2025-07-12 06:25:49.073247: Current learning rate: 0.00607 
2025-07-12 06:28:10.433425: train_loss -0.7781 
2025-07-12 06:28:10.434927: val_loss -0.8007 
2025-07-12 06:28:10.435020: Pseudo dice [0.9492] 
2025-07-12 06:28:10.435098: Epoch time: 141.36 s 
2025-07-12 06:28:12.174765:  
2025-07-12 06:28:12.175603: Epoch 427 
2025-07-12 06:28:12.175946: Current learning rate: 0.00606 
2025-07-12 06:30:34.826623: train_loss -0.7579 
2025-07-12 06:30:34.827508: val_loss -0.7866 
2025-07-12 06:30:34.827581: Pseudo dice [0.9296] 
2025-07-12 06:30:34.827675: Epoch time: 142.65 s 
2025-07-12 06:30:36.358243:  
2025-07-12 06:30:36.358974: Epoch 428 
2025-07-12 06:30:36.359248: Current learning rate: 0.00605 
2025-07-12 06:33:05.634224: train_loss -0.7556 
2025-07-12 06:33:05.635425: val_loss -0.7866 
2025-07-12 06:33:05.635537: Pseudo dice [0.9374] 
2025-07-12 06:33:05.635633: Epoch time: 149.28 s 
2025-07-12 06:33:07.271878:  
2025-07-12 06:33:07.272568: Epoch 429 
2025-07-12 06:33:07.272801: Current learning rate: 0.00604 
2025-07-12 06:35:29.521388: train_loss -0.7599 
2025-07-12 06:35:29.522295: val_loss -0.7801 
2025-07-12 06:35:29.522437: Pseudo dice [0.9467] 
2025-07-12 06:35:29.522519: Epoch time: 142.25 s 
2025-07-12 06:35:31.286638:  
2025-07-12 06:35:31.287280: Epoch 430 
2025-07-12 06:35:31.287588: Current learning rate: 0.00603 
2025-07-12 06:37:53.598116: train_loss -0.7876 
2025-07-12 06:37:53.599152: val_loss -0.8247 
2025-07-12 06:37:53.599215: Pseudo dice [0.9592] 
2025-07-12 06:37:53.599300: Epoch time: 142.31 s 
2025-07-12 06:37:55.190616:  
2025-07-12 06:37:55.191328: Epoch 431 
2025-07-12 06:37:55.191610: Current learning rate: 0.00602 
2025-07-12 06:40:19.382939: train_loss -0.7894 
2025-07-12 06:40:19.384694: val_loss -0.7746 
2025-07-12 06:40:19.384847: Pseudo dice [0.9538] 
2025-07-12 06:40:19.384965: Epoch time: 144.19 s 
2025-07-12 06:40:21.174689:  
2025-07-12 06:40:21.175502: Epoch 432 
2025-07-12 06:40:21.175768: Current learning rate: 0.00601 
2025-07-12 06:42:48.960277: train_loss -0.7945 
2025-07-12 06:42:48.961391: val_loss -0.8136 
2025-07-12 06:42:48.961484: Pseudo dice [0.9555] 
2025-07-12 06:42:48.961586: Epoch time: 147.79 s 
2025-07-12 06:42:50.404069:  
2025-07-12 06:42:50.404519: Epoch 433 
2025-07-12 06:42:50.404761: Current learning rate: 0.006 
2025-07-12 06:45:15.256016: train_loss -0.778 
2025-07-12 06:45:15.257161: val_loss -0.8002 
2025-07-12 06:45:15.257307: Pseudo dice [0.9548] 
2025-07-12 06:45:15.257391: Epoch time: 144.85 s 
2025-07-12 06:45:17.016270:  
2025-07-12 06:45:17.017087: Epoch 434 
2025-07-12 06:45:17.017349: Current learning rate: 0.00599 
2025-07-12 06:47:42.525429: train_loss -0.7857 
2025-07-12 06:47:42.527367: val_loss -0.8003 
2025-07-12 06:47:42.527728: Pseudo dice [0.9569] 
2025-07-12 06:47:42.528015: Epoch time: 145.51 s 
2025-07-12 06:47:44.545676:  
2025-07-12 06:47:44.546524: Epoch 435 
2025-07-12 06:47:44.546886: Current learning rate: 0.00598 
2025-07-12 06:50:07.586232: train_loss -0.7951 
2025-07-12 06:50:07.587210: val_loss -0.7906 
2025-07-12 06:50:07.587302: Pseudo dice [0.963] 
2025-07-12 06:50:07.587401: Epoch time: 143.04 s 
2025-07-12 06:50:12.021452:  
2025-07-12 06:50:12.021844: Epoch 436 
2025-07-12 06:50:12.021920: Current learning rate: 0.00597 
2025-07-12 06:52:32.640018: train_loss -0.7974 
2025-07-12 06:52:32.641068: val_loss -0.8141 
2025-07-12 06:52:32.641134: Pseudo dice [0.9543] 
2025-07-12 06:52:32.641221: Epoch time: 140.62 s 
2025-07-12 06:52:34.381009:  
2025-07-12 06:52:34.382337: Epoch 437 
2025-07-12 06:52:34.382805: Current learning rate: 0.00596 
2025-07-12 06:54:57.652881: train_loss -0.7849 
2025-07-12 06:54:57.654697: val_loss -0.8028 
2025-07-12 06:54:57.654805: Pseudo dice [0.9525] 
2025-07-12 06:54:57.654921: Epoch time: 143.27 s 
2025-07-12 06:54:59.543800:  
2025-07-12 06:54:59.544971: Epoch 438 
2025-07-12 06:54:59.545333: Current learning rate: 0.00595 
2025-07-12 06:57:24.367108: train_loss -0.7817 
2025-07-12 06:57:24.369012: val_loss -0.8111 
2025-07-12 06:57:24.369365: Pseudo dice [0.958] 
2025-07-12 06:57:24.369629: Epoch time: 144.83 s 
2025-07-12 06:57:26.330411:  
2025-07-12 06:57:26.331244: Epoch 439 
2025-07-12 06:57:26.331597: Current learning rate: 0.00594 
2025-07-12 06:59:49.106892: train_loss -0.7761 
2025-07-12 06:59:49.108310: val_loss -0.7817 
2025-07-12 06:59:49.108514: Pseudo dice [0.948] 
2025-07-12 06:59:49.108646: Epoch time: 142.78 s 
2025-07-12 06:59:50.757903:  
2025-07-12 06:59:50.758702: Epoch 440 
2025-07-12 06:59:50.759056: Current learning rate: 0.00593 
2025-07-12 07:02:13.864039: train_loss -0.7677 
2025-07-12 07:02:13.865712: val_loss -0.7929 
2025-07-12 07:02:13.865952: Pseudo dice [0.9573] 
2025-07-12 07:02:13.866125: Epoch time: 143.11 s 
2025-07-12 07:02:15.519319:  
2025-07-12 07:02:15.520246: Epoch 441 
2025-07-12 07:02:15.520514: Current learning rate: 0.00592 
2025-07-12 07:04:41.526668: train_loss -0.801 
2025-07-12 07:04:41.528105: val_loss -0.8046 
2025-07-12 07:04:41.528205: Pseudo dice [0.9545] 
2025-07-12 07:04:41.528367: Epoch time: 146.01 s 
2025-07-12 07:04:43.323817:  
2025-07-12 07:04:43.324895: Epoch 442 
2025-07-12 07:04:43.325314: Current learning rate: 0.00592 
2025-07-12 07:07:12.314920: train_loss -0.7767 
2025-07-12 07:07:12.316176: val_loss -0.7688 
2025-07-12 07:07:12.316282: Pseudo dice [0.9297] 
2025-07-12 07:07:12.316391: Epoch time: 148.99 s 
2025-07-12 07:07:13.909184:  
2025-07-12 07:07:13.910187: Epoch 443 
2025-07-12 07:07:13.910522: Current learning rate: 0.00591 
2025-07-12 07:09:33.976148: train_loss -0.7881 
2025-07-12 07:09:33.977471: val_loss -0.7529 
2025-07-12 07:09:33.977567: Pseudo dice [0.9504] 
2025-07-12 07:09:33.977680: Epoch time: 140.07 s 
2025-07-12 07:09:35.942784:  
2025-07-12 07:09:35.944124: Epoch 444 
2025-07-12 07:09:35.944563: Current learning rate: 0.0059 
2025-07-12 07:11:59.742078: train_loss -0.7948 
2025-07-12 07:11:59.745238: val_loss -0.7999 
2025-07-12 07:11:59.746548: Pseudo dice [0.9525] 
2025-07-12 07:11:59.746961: Epoch time: 143.8 s 
2025-07-12 07:12:01.930291:  
2025-07-12 07:12:01.931313: Epoch 445 
2025-07-12 07:12:01.931718: Current learning rate: 0.00589 
2025-07-12 07:14:27.760687: train_loss -0.7744 
2025-07-12 07:14:27.765172: val_loss -0.7753 
2025-07-12 07:14:27.765658: Pseudo dice [0.9464] 
2025-07-12 07:14:27.765772: Epoch time: 145.83 s 
2025-07-12 07:14:29.925333:  
2025-07-12 07:14:29.926515: Epoch 446 
2025-07-12 07:14:29.926981: Current learning rate: 0.00588 
2025-07-12 07:16:54.456922: train_loss -0.7926 
2025-07-12 07:16:54.457993: val_loss -0.8091 
2025-07-12 07:16:54.458095: Pseudo dice [0.9603] 
2025-07-12 07:16:54.458201: Epoch time: 144.53 s 
2025-07-12 07:16:56.454200:  
2025-07-12 07:16:56.455140: Epoch 447 
2025-07-12 07:16:56.455463: Current learning rate: 0.00587 
2025-07-12 07:19:20.460507: train_loss -0.805 
2025-07-12 07:19:20.462154: val_loss -0.8085 
2025-07-12 07:19:20.462420: Pseudo dice [0.9585] 
2025-07-12 07:19:20.462614: Epoch time: 144.01 s 
2025-07-12 07:19:22.225869:  
2025-07-12 07:19:22.226589: Epoch 448 
2025-07-12 07:19:22.226884: Current learning rate: 0.00586 
2025-07-12 07:21:45.136872: train_loss -0.7881 
2025-07-12 07:21:45.138082: val_loss -0.7958 
2025-07-12 07:21:45.138164: Pseudo dice [0.9568] 
2025-07-12 07:21:45.138299: Epoch time: 142.91 s 
2025-07-12 07:21:46.657694:  
2025-07-12 07:21:46.658360: Epoch 449 
2025-07-12 07:21:46.658542: Current learning rate: 0.00585 
2025-07-12 07:24:09.131988: train_loss -0.8004 
2025-07-12 07:24:09.133524: val_loss -0.8235 
2025-07-12 07:24:09.133599: Pseudo dice [0.9606] 
2025-07-12 07:24:09.133683: Epoch time: 142.48 s 
2025-07-12 07:24:12.207568:  
2025-07-12 07:24:12.208245: Epoch 450 
2025-07-12 07:24:12.208541: Current learning rate: 0.00584 
2025-07-12 07:26:34.192766: train_loss -0.7762 
2025-07-12 07:26:34.193972: val_loss -0.7874 
2025-07-12 07:26:34.194077: Pseudo dice [0.9608] 
2025-07-12 07:26:34.194183: Epoch time: 141.99 s 
2025-07-12 07:26:36.043244:  
2025-07-12 07:26:36.044063: Epoch 451 
2025-07-12 07:26:36.044417: Current learning rate: 0.00583 
2025-07-12 07:28:59.505093: train_loss -0.7824 
2025-07-12 07:28:59.506443: val_loss -0.7854 
2025-07-12 07:28:59.506540: Pseudo dice [0.9529] 
2025-07-12 07:28:59.506644: Epoch time: 143.46 s 
2025-07-12 07:29:01.616364:  
2025-07-12 07:29:01.617357: Epoch 452 
2025-07-12 07:29:01.617793: Current learning rate: 0.00582 
2025-07-12 07:31:22.213855: train_loss -0.8039 
2025-07-12 07:31:22.217112: val_loss -0.8172 
2025-07-12 07:31:22.217797: Pseudo dice [0.9621] 
2025-07-12 07:31:22.218014: Epoch time: 140.6 s 
2025-07-12 07:31:24.263145:  
2025-07-12 07:31:24.264305: Epoch 453 
2025-07-12 07:31:24.264783: Current learning rate: 0.00581 
2025-07-12 07:33:47.477003: train_loss -0.7781 
2025-07-12 07:33:47.478616: val_loss -0.7941 
2025-07-12 07:33:47.478698: Pseudo dice [0.9626] 
2025-07-12 07:33:47.478802: Epoch time: 143.22 s 
2025-07-12 07:33:49.119171:  
2025-07-12 07:33:49.119862: Epoch 454 
2025-07-12 07:33:49.120176: Current learning rate: 0.0058 
2025-07-12 07:36:11.575372: train_loss -0.7958 
2025-07-12 07:36:11.576697: val_loss -0.7869 
2025-07-12 07:36:11.576791: Pseudo dice [0.9628] 
2025-07-12 07:36:11.576902: Epoch time: 142.46 s 
2025-07-12 07:36:13.513709:  
2025-07-12 07:36:13.514658: Epoch 455 
2025-07-12 07:36:13.515145: Current learning rate: 0.00579 
2025-07-12 07:38:38.318874: train_loss -0.7869 
2025-07-12 07:38:38.319973: val_loss -0.7977 
2025-07-12 07:38:38.333065: Pseudo dice [0.9484] 
2025-07-12 07:38:38.333721: Epoch time: 144.81 s 
2025-07-12 07:38:42.456276:  
2025-07-12 07:38:42.456671: Epoch 456 
2025-07-12 07:38:42.456782: Current learning rate: 0.00578 
2025-07-12 07:41:03.548215: train_loss -0.7858 
2025-07-12 07:41:03.549702: val_loss -0.7726 
2025-07-12 07:41:03.549920: Pseudo dice [0.9227] 
2025-07-12 07:41:03.550128: Epoch time: 141.09 s 
2025-07-12 07:41:05.484545:  
2025-07-12 07:41:05.485642: Epoch 457 
2025-07-12 07:41:05.485996: Current learning rate: 0.00577 
2025-07-12 07:43:29.820114: train_loss -0.7655 
2025-07-12 07:43:29.821988: val_loss -0.8003 
2025-07-12 07:43:29.822276: Pseudo dice [0.9581] 
2025-07-12 07:43:29.822572: Epoch time: 144.34 s 
2025-07-12 07:43:31.768222:  
2025-07-12 07:43:31.769400: Epoch 458 
2025-07-12 07:43:31.769806: Current learning rate: 0.00576 
2025-07-12 07:45:58.905763: train_loss -0.787 
2025-07-12 07:45:58.909062: val_loss -0.8225 
2025-07-12 07:45:58.909902: Pseudo dice [0.9612] 
2025-07-12 07:45:58.910228: Epoch time: 147.14 s 
2025-07-12 07:46:00.838453:  
2025-07-12 07:46:00.839925: Epoch 459 
2025-07-12 07:46:00.840415: Current learning rate: 0.00575 
2025-07-12 07:48:28.672091: train_loss -0.8063 
2025-07-12 07:48:28.673575: val_loss -0.8 
2025-07-12 07:48:28.673670: Pseudo dice [0.9597] 
2025-07-12 07:48:28.673816: Epoch time: 147.84 s 
2025-07-12 07:48:30.304030:  
2025-07-12 07:48:30.305002: Epoch 460 
2025-07-12 07:48:30.305393: Current learning rate: 0.00574 
2025-07-12 07:50:56.589966: train_loss -0.7814 
2025-07-12 07:50:56.591228: val_loss -0.8044 
2025-07-12 07:50:56.591432: Pseudo dice [0.9603] 
2025-07-12 07:50:56.591591: Epoch time: 146.29 s 
2025-07-12 07:50:58.182454:  
2025-07-12 07:50:58.183311: Epoch 461 
2025-07-12 07:50:58.183571: Current learning rate: 0.00573 
2025-07-12 07:53:22.887079: train_loss -0.7803 
2025-07-12 07:53:22.888511: val_loss -0.8096 
2025-07-12 07:53:22.888794: Pseudo dice [0.9605] 
2025-07-12 07:53:22.889034: Epoch time: 144.71 s 
2025-07-12 07:53:24.588476:  
2025-07-12 07:53:24.589280: Epoch 462 
2025-07-12 07:53:24.589586: Current learning rate: 0.00572 
2025-07-12 07:55:49.036916: train_loss -0.7864 
2025-07-12 07:55:49.038175: val_loss -0.7908 
2025-07-12 07:55:49.038274: Pseudo dice [0.9534] 
2025-07-12 07:55:49.038391: Epoch time: 144.45 s 
2025-07-12 07:55:50.586874:  
2025-07-12 07:55:50.587753: Epoch 463 
2025-07-12 07:55:50.588130: Current learning rate: 0.00571 
2025-07-12 07:58:17.181233: train_loss -0.7728 
2025-07-12 07:58:17.183525: val_loss -0.7934 
2025-07-12 07:58:17.184477: Pseudo dice [0.9501] 
2025-07-12 07:58:17.185138: Epoch time: 146.6 s 
2025-07-12 07:58:18.796496:  
2025-07-12 07:58:18.797142: Epoch 464 
2025-07-12 07:58:18.797370: Current learning rate: 0.0057 
2025-07-12 08:00:41.187024: train_loss -0.7715 
2025-07-12 08:00:41.188183: val_loss -0.8195 
2025-07-12 08:00:41.188271: Pseudo dice [0.96] 
2025-07-12 08:00:41.188374: Epoch time: 142.39 s 
2025-07-12 08:00:43.087153:  
2025-07-12 08:00:43.088173: Epoch 465 
2025-07-12 08:00:43.088511: Current learning rate: 0.0057 
2025-07-12 08:03:07.160752: train_loss -0.7727 
2025-07-12 08:03:07.162070: val_loss -0.8063 
2025-07-12 08:03:07.162144: Pseudo dice [0.9617] 
2025-07-12 08:03:07.162273: Epoch time: 144.08 s 
2025-07-12 08:03:09.113297:  
2025-07-12 08:03:09.114225: Epoch 466 
2025-07-12 08:03:09.114577: Current learning rate: 0.00569 
2025-07-12 08:05:32.209516: train_loss -0.776 
2025-07-12 08:05:32.210726: val_loss -0.7431 
2025-07-12 08:05:32.210814: Pseudo dice [0.9137] 
2025-07-12 08:05:32.210915: Epoch time: 143.1 s 
2025-07-12 08:05:34.215398:  
2025-07-12 08:05:34.216611: Epoch 467 
2025-07-12 08:05:34.217086: Current learning rate: 0.00568 
2025-07-12 08:07:59.561749: train_loss -0.7629 
2025-07-12 08:07:59.565102: val_loss -0.7948 
2025-07-12 08:07:59.565819: Pseudo dice [0.9468] 
2025-07-12 08:07:59.566212: Epoch time: 145.35 s 
2025-07-12 08:08:01.370874:  
2025-07-12 08:08:01.371822: Epoch 468 
2025-07-12 08:08:01.372235: Current learning rate: 0.00567 
2025-07-12 08:10:25.356985: train_loss -0.7622 
2025-07-12 08:10:25.358381: val_loss -0.7881 
2025-07-12 08:10:25.358570: Pseudo dice [0.9383] 
2025-07-12 08:10:25.358736: Epoch time: 143.99 s 
2025-07-12 08:10:27.289766:  
2025-07-12 08:10:27.291146: Epoch 469 
2025-07-12 08:10:27.291758: Current learning rate: 0.00566 
2025-07-12 08:12:54.269954: train_loss -0.7873 
2025-07-12 08:12:54.270816: val_loss -0.7718 
2025-07-12 08:12:54.270893: Pseudo dice [0.9493] 
2025-07-12 08:12:54.270979: Epoch time: 146.98 s 
2025-07-12 08:12:55.821362:  
2025-07-12 08:12:55.822139: Epoch 470 
2025-07-12 08:12:55.822425: Current learning rate: 0.00565 
2025-07-12 08:15:23.220781: train_loss -0.7756 
2025-07-12 08:15:23.221709: val_loss -0.7619 
2025-07-12 08:15:23.221853: Pseudo dice [0.9551] 
2025-07-12 08:15:23.221982: Epoch time: 147.4 s 
2025-07-12 08:15:24.683727:  
2025-07-12 08:15:24.684247: Epoch 471 
2025-07-12 08:15:24.684520: Current learning rate: 0.00564 
2025-07-12 08:17:49.014702: train_loss -0.7939 
2025-07-12 08:17:49.017107: val_loss -0.8174 
2025-07-12 08:17:49.018568: Pseudo dice [0.9593] 
2025-07-12 08:17:49.018990: Epoch time: 144.33 s 
2025-07-12 08:17:51.218555:  
2025-07-12 08:17:51.219470: Epoch 472 
2025-07-12 08:17:51.219905: Current learning rate: 0.00563 
2025-07-12 08:20:15.439989: train_loss -0.7896 
2025-07-12 08:20:15.442040: val_loss -0.7934 
2025-07-12 08:20:15.442267: Pseudo dice [0.9457] 
2025-07-12 08:20:15.442413: Epoch time: 144.22 s 
2025-07-12 08:20:17.379469:  
2025-07-12 08:20:17.380233: Epoch 473 
2025-07-12 08:20:17.380527: Current learning rate: 0.00562 
2025-07-12 08:22:42.984872: train_loss -0.7863 
2025-07-12 08:22:42.986694: val_loss -0.789 
2025-07-12 08:22:42.986877: Pseudo dice [0.9595] 
2025-07-12 08:22:42.987022: Epoch time: 145.61 s 
2025-07-12 08:22:44.890672:  
2025-07-12 08:22:44.891434: Epoch 474 
2025-07-12 08:22:44.891769: Current learning rate: 0.00561 
2025-07-12 08:25:09.126173: train_loss -0.7832 
2025-07-12 08:25:09.128117: val_loss -0.8099 
2025-07-12 08:25:09.128601: Pseudo dice [0.9542] 
2025-07-12 08:25:09.129171: Epoch time: 144.24 s 
2025-07-12 08:25:10.853694:  
2025-07-12 08:25:10.854294: Epoch 475 
2025-07-12 08:25:10.854578: Current learning rate: 0.0056 
2025-07-12 08:27:38.589812: train_loss -0.781 
2025-07-12 08:27:38.590619: val_loss -0.8238 
2025-07-12 08:27:38.590681: Pseudo dice [0.9562] 
2025-07-12 08:27:38.590771: Epoch time: 147.74 s 
2025-07-12 08:27:39.917950:  
2025-07-12 08:27:39.918354: Epoch 476 
2025-07-12 08:27:39.918492: Current learning rate: 0.00559 
2025-07-12 08:29:59.148080: train_loss -0.7754 
2025-07-12 08:29:59.149993: val_loss -0.8117 
2025-07-12 08:29:59.150080: Pseudo dice [0.9633] 
2025-07-12 08:29:59.150214: Epoch time: 139.23 s 
2025-07-12 08:30:05.764402:  
2025-07-12 08:30:05.764872: Epoch 477 
2025-07-12 08:30:05.764970: Current learning rate: 0.00558 
2025-07-12 08:32:29.592800: train_loss -0.7948 
2025-07-12 08:32:29.593899: val_loss -0.8044 
2025-07-12 08:32:29.593981: Pseudo dice [0.9656] 
2025-07-12 08:32:29.594067: Epoch time: 143.83 s 
2025-07-12 08:32:30.927385:  
2025-07-12 08:32:30.927854: Epoch 478 
2025-07-12 08:32:30.927976: Current learning rate: 0.00557 
2025-07-12 08:34:50.988036: train_loss -0.7937 
2025-07-12 08:34:50.990063: val_loss -0.8091 
2025-07-12 08:34:50.990366: Pseudo dice [0.9631] 
2025-07-12 08:34:50.990566: Epoch time: 140.06 s 
2025-07-12 08:34:52.885445:  
2025-07-12 08:34:52.886067: Epoch 479 
2025-07-12 08:34:52.886285: Current learning rate: 0.00556 
2025-07-12 08:37:16.872521: train_loss -0.799 
2025-07-12 08:37:16.873900: val_loss -0.8219 
2025-07-12 08:37:16.873999: Pseudo dice [0.9602] 
2025-07-12 08:37:16.874099: Epoch time: 143.99 s 
2025-07-12 08:37:18.809775:  
2025-07-12 08:37:18.810645: Epoch 480 
2025-07-12 08:37:18.811031: Current learning rate: 0.00555 
2025-07-12 08:39:39.399681: train_loss -0.7982 
2025-07-12 08:39:39.405473: val_loss -0.7998 
2025-07-12 08:39:39.405856: Pseudo dice [0.9598] 
2025-07-12 08:39:39.406162: Epoch time: 140.59 s 
2025-07-12 08:39:39.406353: Yayy! New best EMA pseudo Dice: 0.9563 
2025-07-12 08:39:42.933533:  
2025-07-12 08:39:42.934289: Epoch 481 
2025-07-12 08:39:42.934572: Current learning rate: 0.00554 
2025-07-12 08:42:03.421479: train_loss -0.7856 
2025-07-12 08:42:03.423010: val_loss -0.7932 
2025-07-12 08:42:03.423177: Pseudo dice [0.9622] 
2025-07-12 08:42:03.423354: Epoch time: 140.49 s 
2025-07-12 08:42:03.423444: Yayy! New best EMA pseudo Dice: 0.9569 
2025-07-12 08:42:06.728822:  
2025-07-12 08:42:06.729553: Epoch 482 
2025-07-12 08:42:06.729840: Current learning rate: 0.00553 
2025-07-12 08:44:27.182361: train_loss -0.7803 
2025-07-12 08:44:27.184156: val_loss -0.8236 
2025-07-12 08:44:27.184410: Pseudo dice [0.9471] 
2025-07-12 08:44:27.184603: Epoch time: 140.45 s 
2025-07-12 08:44:29.306122:  
2025-07-12 08:44:29.307194: Epoch 483 
2025-07-12 08:44:29.307632: Current learning rate: 0.00552 
2025-07-12 08:46:53.509401: train_loss -0.775 
2025-07-12 08:46:53.512803: val_loss -0.79 
2025-07-12 08:46:53.513758: Pseudo dice [0.9462] 
2025-07-12 08:46:53.514341: Epoch time: 144.21 s 
2025-07-12 08:46:55.207373:  
2025-07-12 08:46:55.208024: Epoch 484 
2025-07-12 08:46:55.208297: Current learning rate: 0.00551 
2025-07-12 08:49:15.792806: train_loss -0.7811 
2025-07-12 08:49:15.794708: val_loss -0.8156 
2025-07-12 08:49:15.794982: Pseudo dice [0.9619] 
2025-07-12 08:49:15.795234: Epoch time: 140.59 s 
2025-07-12 08:49:17.453718:  
2025-07-12 08:49:17.454172: Epoch 485 
2025-07-12 08:49:17.454341: Current learning rate: 0.0055 
2025-07-12 08:51:40.350841: train_loss -0.7694 
2025-07-12 08:51:40.351902: val_loss -0.8049 
2025-07-12 08:51:40.352095: Pseudo dice [0.9564] 
2025-07-12 08:51:40.352207: Epoch time: 142.9 s 
2025-07-12 08:51:42.127742:  
2025-07-12 08:51:42.128644: Epoch 486 
2025-07-12 08:51:42.128971: Current learning rate: 0.00549 
2025-07-12 08:54:09.605048: train_loss -0.7929 
2025-07-12 08:54:09.606027: val_loss -0.7852 
2025-07-12 08:54:09.606097: Pseudo dice [0.9576] 
2025-07-12 08:54:09.606163: Epoch time: 147.48 s 
2025-07-12 08:54:11.142381:  
2025-07-12 08:54:11.143077: Epoch 487 
2025-07-12 08:54:11.143317: Current learning rate: 0.00548 
2025-07-12 08:56:37.011884: train_loss -0.7903 
2025-07-12 08:56:37.013365: val_loss -0.7818 
2025-07-12 08:56:37.013522: Pseudo dice [0.9588] 
2025-07-12 08:56:37.013679: Epoch time: 145.87 s 
2025-07-12 08:56:38.987392:  
2025-07-12 08:56:38.988303: Epoch 488 
2025-07-12 08:56:38.988659: Current learning rate: 0.00547 
2025-07-12 08:59:03.836744: train_loss -0.7988 
2025-07-12 08:59:03.837667: val_loss -0.8353 
2025-07-12 08:59:03.837803: Pseudo dice [0.9628] 
2025-07-12 08:59:03.837894: Epoch time: 144.85 s 
2025-07-12 08:59:05.304843:  
2025-07-12 08:59:05.305322: Epoch 489 
2025-07-12 08:59:05.305482: Current learning rate: 0.00546 
2025-07-12 09:01:27.297523: train_loss -0.8023 
2025-07-12 09:01:27.298563: val_loss -0.7905 
2025-07-12 09:01:27.298703: Pseudo dice [0.9597] 
2025-07-12 09:01:27.298839: Epoch time: 141.99 s 
2025-07-12 09:01:27.298939: Yayy! New best EMA pseudo Dice: 0.9571 
2025-07-12 09:01:29.808759:  
2025-07-12 09:01:29.809305: Epoch 490 
2025-07-12 09:01:29.809498: Current learning rate: 0.00546 
2025-07-12 09:03:50.938015: train_loss -0.7944 
2025-07-12 09:03:50.940147: val_loss -0.8463 
2025-07-12 09:03:50.940262: Pseudo dice [0.9635] 
2025-07-12 09:03:50.940404: Epoch time: 141.13 s 
2025-07-12 09:03:50.940495: Yayy! New best EMA pseudo Dice: 0.9578 
2025-07-12 09:03:53.977866:  
2025-07-12 09:03:53.978148: Epoch 491 
2025-07-12 09:03:53.978259: Current learning rate: 0.00545 
2025-07-12 09:06:17.644906: train_loss -0.7957 
2025-07-12 09:06:17.646402: val_loss -0.8098 
2025-07-12 09:06:17.646497: Pseudo dice [0.9542] 
2025-07-12 09:06:17.646612: Epoch time: 143.67 s 
2025-07-12 09:06:19.577591:  
2025-07-12 09:06:19.578492: Epoch 492 
2025-07-12 09:06:19.578914: Current learning rate: 0.00544 
2025-07-12 09:08:47.558713: train_loss -0.8006 
2025-07-12 09:08:47.559781: val_loss -0.7933 
2025-07-12 09:08:47.559863: Pseudo dice [0.9607] 
2025-07-12 09:08:47.559954: Epoch time: 147.98 s 
2025-07-12 09:08:49.229971:  
2025-07-12 09:08:49.230523: Epoch 493 
2025-07-12 09:08:49.230809: Current learning rate: 0.00543 
2025-07-12 09:11:14.844020: train_loss -0.7895 
2025-07-12 09:11:14.845775: val_loss -0.8162 
2025-07-12 09:11:14.846204: Pseudo dice [0.9653] 
2025-07-12 09:11:14.847231: Epoch time: 145.62 s 
2025-07-12 09:11:14.847628: Yayy! New best EMA pseudo Dice: 0.9585 
2025-07-12 09:11:17.506925:  
2025-07-12 09:11:17.507415: Epoch 494 
2025-07-12 09:11:17.507584: Current learning rate: 0.00542 
2025-07-12 09:13:43.524484: train_loss -0.8008 
2025-07-12 09:13:43.525610: val_loss -0.8118 
2025-07-12 09:13:43.525698: Pseudo dice [0.9635] 
2025-07-12 09:13:43.525779: Epoch time: 146.02 s 
2025-07-12 09:13:43.525826: Yayy! New best EMA pseudo Dice: 0.959 
2025-07-12 09:13:46.168480:  
2025-07-12 09:13:46.168868: Epoch 495 
2025-07-12 09:13:46.169011: Current learning rate: 0.00541 
2025-07-12 09:16:09.064373: train_loss -0.7966 
2025-07-12 09:16:09.065528: val_loss -0.8149 
2025-07-12 09:16:09.065630: Pseudo dice [0.9676] 
2025-07-12 09:16:09.065738: Epoch time: 142.9 s 
2025-07-12 09:16:09.065793: Yayy! New best EMA pseudo Dice: 0.9599 
2025-07-12 09:16:14.678604:  
2025-07-12 09:16:14.678973: Epoch 496 
2025-07-12 09:16:14.679055: Current learning rate: 0.0054 
2025-07-12 09:18:34.697134: train_loss -0.7982 
2025-07-12 09:18:34.698922: val_loss -0.8078 
2025-07-12 09:18:34.699116: Pseudo dice [0.965] 
2025-07-12 09:18:34.699274: Epoch time: 140.02 s 
2025-07-12 09:18:34.699390: Yayy! New best EMA pseudo Dice: 0.9604 
2025-07-12 09:18:37.954115:  
2025-07-12 09:18:37.954613: Epoch 497 
2025-07-12 09:18:37.954724: Current learning rate: 0.00539 
2025-07-12 09:21:01.591504: train_loss -0.7934 
2025-07-12 09:21:01.592567: val_loss -0.8005 
2025-07-12 09:21:01.592643: Pseudo dice [0.9611] 
2025-07-12 09:21:01.592752: Epoch time: 143.64 s 
2025-07-12 09:21:01.592794: Yayy! New best EMA pseudo Dice: 0.9605 
2025-07-12 09:21:05.212665:  
2025-07-12 09:21:05.213551: Epoch 498 
2025-07-12 09:21:05.213830: Current learning rate: 0.00538 
2025-07-12 09:23:25.477264: train_loss -0.7868 
2025-07-12 09:23:25.478961: val_loss -0.8382 
2025-07-12 09:23:25.479059: Pseudo dice [0.9633] 
2025-07-12 09:23:25.479193: Epoch time: 140.27 s 
2025-07-12 09:23:25.479245: Yayy! New best EMA pseudo Dice: 0.9607 
2025-07-12 09:23:29.115168:  
2025-07-12 09:23:29.115901: Epoch 499 
2025-07-12 09:23:29.116280: Current learning rate: 0.00537 
2025-07-12 09:25:52.927058: train_loss -0.7845 
2025-07-12 09:25:52.928612: val_loss -0.8284 
2025-07-12 09:25:52.928704: Pseudo dice [0.9627] 
2025-07-12 09:25:52.928799: Epoch time: 143.81 s 
2025-07-12 09:25:54.352104: Yayy! New best EMA pseudo Dice: 0.9609 
2025-07-12 09:25:56.707637:  
2025-07-12 09:25:56.708272: Epoch 500 
2025-07-12 09:25:56.708495: Current learning rate: 0.00536 
2025-07-12 09:28:19.829921: train_loss -0.786 
2025-07-12 09:28:19.830997: val_loss -0.7926 
2025-07-12 09:28:19.831098: Pseudo dice [0.9444] 
2025-07-12 09:28:19.831200: Epoch time: 143.12 s 
2025-07-12 09:28:21.616503:  
2025-07-12 09:28:21.617374: Epoch 501 
2025-07-12 09:28:21.617699: Current learning rate: 0.00535 
2025-07-12 09:30:43.887167: train_loss -0.7747 
2025-07-12 09:30:43.888838: val_loss -0.7837 
2025-07-12 09:30:43.889096: Pseudo dice [0.9475] 
2025-07-12 09:30:43.889299: Epoch time: 142.27 s 
2025-07-12 09:30:45.825172:  
2025-07-12 09:30:45.826132: Epoch 502 
2025-07-12 09:30:45.826473: Current learning rate: 0.00534 
2025-07-12 09:33:08.066514: train_loss -0.7805 
2025-07-12 09:33:08.067884: val_loss -0.8059 
2025-07-12 09:33:08.068185: Pseudo dice [0.9549] 
2025-07-12 09:33:08.068362: Epoch time: 142.24 s 
2025-07-12 09:33:09.996379:  
2025-07-12 09:33:09.997208: Epoch 503 
2025-07-12 09:33:09.997548: Current learning rate: 0.00533 
2025-07-12 09:35:37.199269: train_loss -0.7975 
2025-07-12 09:35:37.200171: val_loss -0.8192 
2025-07-12 09:35:37.200236: Pseudo dice [0.9624] 
2025-07-12 09:35:37.200329: Epoch time: 147.2 s 
2025-07-12 09:35:38.654126:  
2025-07-12 09:35:38.655012: Epoch 504 
2025-07-12 09:35:38.655319: Current learning rate: 0.00532 
2025-07-12 09:38:03.602847: train_loss -0.7814 
2025-07-12 09:38:03.603983: val_loss -0.796 
2025-07-12 09:38:03.604227: Pseudo dice [0.9479] 
2025-07-12 09:38:03.604424: Epoch time: 144.95 s 
2025-07-12 09:38:05.764699:  
2025-07-12 09:38:05.765770: Epoch 505 
2025-07-12 09:38:05.766171: Current learning rate: 0.00531 
2025-07-12 09:40:31.476485: train_loss -0.779 
2025-07-12 09:40:31.477276: val_loss -0.7936 
2025-07-12 09:40:31.477399: Pseudo dice [0.94] 
2025-07-12 09:40:31.477474: Epoch time: 145.71 s 
2025-07-12 09:40:33.046772:  
2025-07-12 09:40:33.047327: Epoch 506 
2025-07-12 09:40:33.047515: Current learning rate: 0.0053 
2025-07-12 09:42:59.246798: train_loss -0.7691 
2025-07-12 09:42:59.248204: val_loss -0.7889 
2025-07-12 09:42:59.248364: Pseudo dice [0.9566] 
2025-07-12 09:42:59.248504: Epoch time: 146.2 s 
2025-07-12 09:43:01.241628:  
2025-07-12 09:43:01.242604: Epoch 507 
2025-07-12 09:43:01.242967: Current learning rate: 0.00529 
2025-07-12 09:45:26.926714: train_loss -0.7872 
2025-07-12 09:45:26.928417: val_loss -0.7744 
2025-07-12 09:45:26.928644: Pseudo dice [0.9494] 
2025-07-12 09:45:26.928794: Epoch time: 145.69 s 
2025-07-12 09:45:28.795164:  
2025-07-12 09:45:28.796122: Epoch 508 
2025-07-12 09:45:28.796497: Current learning rate: 0.00528 
2025-07-12 09:47:51.067058: train_loss -0.7854 
2025-07-12 09:47:51.068635: val_loss -0.7947 
2025-07-12 09:47:51.068784: Pseudo dice [0.9573] 
2025-07-12 09:47:51.068924: Epoch time: 142.27 s 
2025-07-12 09:47:52.760171:  
2025-07-12 09:47:52.761083: Epoch 509 
2025-07-12 09:47:52.761354: Current learning rate: 0.00527 
2025-07-12 09:50:18.689316: train_loss -0.7501 
2025-07-12 09:50:18.690335: val_loss -0.7816 
2025-07-12 09:50:18.690403: Pseudo dice [0.9381] 
2025-07-12 09:50:18.690519: Epoch time: 145.93 s 
2025-07-12 09:50:20.263336:  
2025-07-12 09:50:20.264036: Epoch 510 
2025-07-12 09:50:20.264373: Current learning rate: 0.00526 
2025-07-12 09:52:46.423625: train_loss -0.7664 
2025-07-12 09:52:46.424791: val_loss -0.7834 
2025-07-12 09:52:46.424906: Pseudo dice [0.9349] 
2025-07-12 09:52:46.425017: Epoch time: 146.16 s 
2025-07-12 09:52:47.899419:  
2025-07-12 09:52:47.899897: Epoch 511 
2025-07-12 09:52:47.900078: Current learning rate: 0.00525 
2025-07-12 09:55:14.092964: train_loss -0.777 
2025-07-12 09:55:14.094530: val_loss -0.7871 
2025-07-12 09:55:14.094619: Pseudo dice [0.9445] 
2025-07-12 09:55:14.094735: Epoch time: 146.19 s 
2025-07-12 09:55:15.755327:  
2025-07-12 09:55:15.756277: Epoch 512 
2025-07-12 09:55:15.756721: Current learning rate: 0.00524 
2025-07-12 09:57:37.410965: train_loss -0.7842 
2025-07-12 09:57:37.412520: val_loss -0.8035 
2025-07-12 09:57:37.412629: Pseudo dice [0.9458] 
2025-07-12 09:57:37.412743: Epoch time: 141.66 s 
2025-07-12 09:57:39.478267:  
2025-07-12 09:57:39.478957: Epoch 513 
2025-07-12 09:57:39.479233: Current learning rate: 0.00523 
2025-07-12 10:00:06.455070: train_loss -0.7847 
2025-07-12 10:00:06.456426: val_loss -0.7997 
2025-07-12 10:00:06.456504: Pseudo dice [0.9497] 
2025-07-12 10:00:06.456592: Epoch time: 146.98 s 
2025-07-12 10:00:08.447978:  
2025-07-12 10:00:08.448692: Epoch 514 
2025-07-12 10:00:08.448983: Current learning rate: 0.00522 
2025-07-12 10:02:30.597847: train_loss -0.7795 
2025-07-12 10:02:30.598973: val_loss -0.8071 
2025-07-12 10:02:30.599066: Pseudo dice [0.9584] 
2025-07-12 10:02:30.599179: Epoch time: 142.15 s 
2025-07-12 10:02:34.079865:  
2025-07-12 10:02:34.080298: Epoch 515 
2025-07-12 10:02:34.080425: Current learning rate: 0.00521 
2025-07-12 10:04:54.786783: train_loss -0.7946 
2025-07-12 10:04:54.790971: val_loss -0.7698 
2025-07-12 10:04:54.791083: Pseudo dice [0.9468] 
2025-07-12 10:04:54.791185: Epoch time: 140.71 s 
2025-07-12 10:04:56.629970:  
2025-07-12 10:04:56.630807: Epoch 516 
2025-07-12 10:04:56.631076: Current learning rate: 0.0052 
2025-07-12 10:07:22.363731: train_loss -0.7828 
2025-07-12 10:07:22.365119: val_loss -0.7944 
2025-07-12 10:07:22.365225: Pseudo dice [0.9536] 
2025-07-12 10:07:22.365340: Epoch time: 145.73 s 
2025-07-12 10:07:24.212159:  
2025-07-12 10:07:24.213429: Epoch 517 
2025-07-12 10:07:24.213828: Current learning rate: 0.00519 
2025-07-12 10:09:51.246387: train_loss -0.7756 
2025-07-12 10:09:51.247374: val_loss -0.7907 
2025-07-12 10:09:51.247441: Pseudo dice [0.9563] 
2025-07-12 10:09:51.247511: Epoch time: 147.04 s 
2025-07-12 10:09:52.641243:  
2025-07-12 10:09:52.641952: Epoch 518 
2025-07-12 10:09:52.642159: Current learning rate: 0.00518 
2025-07-12 10:12:19.271887: train_loss -0.7807 
2025-07-12 10:12:19.273762: val_loss -0.7932 
2025-07-12 10:12:19.274205: Pseudo dice [0.9597] 
2025-07-12 10:12:19.274692: Epoch time: 146.63 s 
2025-07-12 10:12:20.843067:  
2025-07-12 10:12:20.844235: Epoch 519 
2025-07-12 10:12:20.844627: Current learning rate: 0.00518 
2025-07-12 10:14:43.136968: train_loss -0.7695 
2025-07-12 10:14:43.138248: val_loss -0.7956 
2025-07-12 10:14:43.138349: Pseudo dice [0.9499] 
2025-07-12 10:14:43.138459: Epoch time: 142.3 s 
2025-07-12 10:14:45.015094:  
2025-07-12 10:14:45.015837: Epoch 520 
2025-07-12 10:14:45.016168: Current learning rate: 0.00517 
2025-07-12 10:17:11.998752: train_loss -0.7736 
2025-07-12 10:17:11.999985: val_loss -0.7708 
2025-07-12 10:17:12.000096: Pseudo dice [0.9461] 
2025-07-12 10:17:12.000244: Epoch time: 146.99 s 
2025-07-12 10:17:13.895790:  
2025-07-12 10:17:13.896811: Epoch 521 
2025-07-12 10:17:13.897187: Current learning rate: 0.00516 
2025-07-12 10:19:35.459204: train_loss -0.782 
2025-07-12 10:19:35.460507: val_loss -0.7901 
2025-07-12 10:19:35.460593: Pseudo dice [0.9524] 
2025-07-12 10:19:35.460674: Epoch time: 141.57 s 
2025-07-12 10:19:37.465030:  
2025-07-12 10:19:37.466375: Epoch 522 
2025-07-12 10:19:37.466853: Current learning rate: 0.00515 
2025-07-12 10:22:00.630782: train_loss -0.7852 
2025-07-12 10:22:00.632315: val_loss -0.8181 
2025-07-12 10:22:00.632469: Pseudo dice [0.9611] 
2025-07-12 10:22:00.632569: Epoch time: 143.17 s 
2025-07-12 10:22:02.277628:  
2025-07-12 10:22:02.278671: Epoch 523 
2025-07-12 10:22:02.279058: Current learning rate: 0.00514 
2025-07-12 10:24:25.475405: train_loss -0.7882 
2025-07-12 10:24:25.477565: val_loss -0.8108 
2025-07-12 10:24:25.479342: Pseudo dice [0.963] 
2025-07-12 10:24:25.480236: Epoch time: 143.2 s 
2025-07-12 10:24:27.134243:  
2025-07-12 10:24:27.135032: Epoch 524 
2025-07-12 10:24:27.135336: Current learning rate: 0.00513 
2025-07-12 10:26:50.715816: train_loss -0.785 
2025-07-12 10:26:50.717283: val_loss -0.792 
2025-07-12 10:26:50.717371: Pseudo dice [0.9625] 
2025-07-12 10:26:50.717478: Epoch time: 143.58 s 
2025-07-12 10:26:52.541717:  
2025-07-12 10:26:52.542415: Epoch 525 
2025-07-12 10:26:52.542673: Current learning rate: 0.00512 
2025-07-12 10:29:21.140397: train_loss -0.7993 
2025-07-12 10:29:21.141992: val_loss -0.7893 
2025-07-12 10:29:21.142092: Pseudo dice [0.9632] 
2025-07-12 10:29:21.142205: Epoch time: 148.6 s 
2025-07-12 10:29:22.962405:  
2025-07-12 10:29:22.963465: Epoch 526 
2025-07-12 10:29:22.963796: Current learning rate: 0.00511 
2025-07-12 10:31:47.635216: train_loss -0.7893 
2025-07-12 10:31:47.636358: val_loss -0.8395 
2025-07-12 10:31:47.636447: Pseudo dice [0.9601] 
2025-07-12 10:31:47.636549: Epoch time: 144.67 s 
2025-07-12 10:31:49.688011:  
2025-07-12 10:31:49.689273: Epoch 527 
2025-07-12 10:31:49.689743: Current learning rate: 0.0051 
2025-07-12 10:34:15.920721: train_loss -0.7906 
2025-07-12 10:34:15.921934: val_loss -0.7964 
2025-07-12 10:34:15.922067: Pseudo dice [0.9541] 
2025-07-12 10:34:15.922214: Epoch time: 146.24 s 
2025-07-12 10:34:17.775749:  
2025-07-12 10:34:17.777016: Epoch 528 
2025-07-12 10:34:17.777478: Current learning rate: 0.00509 
2025-07-12 10:36:43.173817: train_loss -0.7831 
2025-07-12 10:36:43.174918: val_loss -0.8023 
2025-07-12 10:36:43.174981: Pseudo dice [0.9649] 
2025-07-12 10:36:43.175056: Epoch time: 145.4 s 
2025-07-12 10:36:44.659233:  
2025-07-12 10:36:44.659868: Epoch 529 
2025-07-12 10:36:44.660155: Current learning rate: 0.00508 
2025-07-12 10:39:06.703210: train_loss -0.7928 
2025-07-12 10:39:06.705922: val_loss -0.8279 
2025-07-12 10:39:06.706378: Pseudo dice [0.9594] 
2025-07-12 10:39:06.706687: Epoch time: 142.05 s 
2025-07-12 10:39:08.878507:  
2025-07-12 10:39:08.879173: Epoch 530 
2025-07-12 10:39:08.879446: Current learning rate: 0.00507 
2025-07-12 10:41:29.291260: train_loss -0.7943 
2025-07-12 10:41:29.292355: val_loss -0.7903 
2025-07-12 10:41:29.292438: Pseudo dice [0.9554] 
2025-07-12 10:41:29.292530: Epoch time: 140.41 s 
2025-07-12 10:41:31.151835:  
2025-07-12 10:41:31.152894: Epoch 531 
2025-07-12 10:41:31.153338: Current learning rate: 0.00506 
2025-07-12 10:43:54.949319: train_loss -0.7977 
2025-07-12 10:43:54.950637: val_loss -0.8134 
2025-07-12 10:43:54.950725: Pseudo dice [0.9592] 
2025-07-12 10:43:54.950823: Epoch time: 143.8 s 
2025-07-12 10:43:57.158947:  
2025-07-12 10:43:57.160020: Epoch 532 
2025-07-12 10:43:57.160518: Current learning rate: 0.00505 
2025-07-12 10:46:20.826100: train_loss -0.7892 
2025-07-12 10:46:20.827424: val_loss -0.7897 
2025-07-12 10:46:20.827542: Pseudo dice [0.9526] 
2025-07-12 10:46:20.827668: Epoch time: 143.67 s 
2025-07-12 10:46:22.813141:  
2025-07-12 10:46:22.814018: Epoch 533 
2025-07-12 10:46:22.814346: Current learning rate: 0.00504 
2025-07-12 10:48:48.440039: train_loss -0.7845 
2025-07-12 10:48:48.441831: val_loss -0.8129 
2025-07-12 10:48:48.442072: Pseudo dice [0.9495] 
2025-07-12 10:48:48.442241: Epoch time: 145.63 s 
2025-07-12 10:48:50.160533:  
2025-07-12 10:48:50.161375: Epoch 534 
2025-07-12 10:48:50.161689: Current learning rate: 0.00503 
2025-07-12 10:51:12.653804: train_loss -0.7876 
2025-07-12 10:51:12.656555: val_loss -0.8204 
2025-07-12 10:51:12.656975: Pseudo dice [0.9625] 
2025-07-12 10:51:12.657159: Epoch time: 142.5 s 
2025-07-12 10:51:14.394857:  
2025-07-12 10:51:14.395529: Epoch 535 
2025-07-12 10:51:14.395810: Current learning rate: 0.00502 
2025-07-12 10:53:35.379559: train_loss -0.7877 
2025-07-12 10:53:35.381094: val_loss -0.8067 
2025-07-12 10:53:35.381328: Pseudo dice [0.947] 
2025-07-12 10:53:35.381574: Epoch time: 140.99 s 
2025-07-12 10:53:39.462598:  
2025-07-12 10:53:39.463035: Epoch 536 
2025-07-12 10:53:39.463149: Current learning rate: 0.00501 
2025-07-12 10:56:01.598281: train_loss -0.7774 
2025-07-12 10:56:01.601072: val_loss -0.8128 
2025-07-12 10:56:01.601957: Pseudo dice [0.9656] 
2025-07-12 10:56:01.603070: Epoch time: 142.14 s 
2025-07-12 10:56:03.628491:  
2025-07-12 10:56:03.629567: Epoch 537 
2025-07-12 10:56:03.629932: Current learning rate: 0.005 
2025-07-12 10:58:28.160391: train_loss -0.7955 
2025-07-12 10:58:28.162631: val_loss -0.8131 
2025-07-12 10:58:28.162953: Pseudo dice [0.9543] 
2025-07-12 10:58:28.163363: Epoch time: 144.53 s 
2025-07-12 10:58:30.090468:  
2025-07-12 10:58:30.091615: Epoch 538 
2025-07-12 10:58:30.091999: Current learning rate: 0.00499 
2025-07-12 11:00:55.195731: train_loss -0.7791 
2025-07-12 11:00:55.198060: val_loss -0.7766 
2025-07-12 11:00:55.198359: Pseudo dice [0.962] 
2025-07-12 11:00:55.198589: Epoch time: 145.1 s 
2025-07-12 11:00:57.050408:  
2025-07-12 11:00:57.051503: Epoch 539 
2025-07-12 11:00:57.051963: Current learning rate: 0.00498 
2025-07-12 11:03:21.112548: train_loss -0.8 
2025-07-12 11:03:21.113498: val_loss -0.7818 
2025-07-12 11:03:21.113568: Pseudo dice [0.9576] 
2025-07-12 11:03:21.113655: Epoch time: 144.06 s 
2025-07-12 11:03:23.309084:  
2025-07-12 11:03:23.310261: Epoch 540 
2025-07-12 11:03:23.310630: Current learning rate: 0.00497 
2025-07-12 11:05:50.944933: train_loss -0.7983 
2025-07-12 11:05:50.946562: val_loss -0.7991 
2025-07-12 11:05:50.946811: Pseudo dice [0.9582] 
2025-07-12 11:05:50.946916: Epoch time: 147.64 s 
2025-07-12 11:05:52.871283:  
2025-07-12 11:05:52.872412: Epoch 541 
2025-07-12 11:05:52.872802: Current learning rate: 0.00496 
2025-07-12 11:08:16.071747: train_loss -0.7819 
2025-07-12 11:08:16.073631: val_loss -0.7913 
2025-07-12 11:08:16.073860: Pseudo dice [0.9447] 
2025-07-12 11:08:16.074009: Epoch time: 143.2 s 
2025-07-12 11:08:18.243792:  
2025-07-12 11:08:18.244847: Epoch 542 
2025-07-12 11:08:18.245280: Current learning rate: 0.00495 
2025-07-12 11:10:37.408150: train_loss -0.7823 
2025-07-12 11:10:37.409589: val_loss -0.7778 
2025-07-12 11:10:37.409678: Pseudo dice [0.9558] 
2025-07-12 11:10:37.409790: Epoch time: 139.17 s 
2025-07-12 11:10:39.446362:  
2025-07-12 11:10:39.447714: Epoch 543 
2025-07-12 11:10:39.448190: Current learning rate: 0.00494 
2025-07-12 11:13:01.720459: train_loss -0.7871 
2025-07-12 11:13:01.721387: val_loss -0.8204 
2025-07-12 11:13:01.721460: Pseudo dice [0.9646] 
2025-07-12 11:13:01.721551: Epoch time: 142.28 s 
2025-07-12 11:13:03.409745:  
2025-07-12 11:13:03.410485: Epoch 544 
2025-07-12 11:13:03.410731: Current learning rate: 0.00493 
2025-07-12 11:15:28.483197: train_loss -0.7967 
2025-07-12 11:15:28.484403: val_loss -0.8076 
2025-07-12 11:15:28.484493: Pseudo dice [0.9664] 
2025-07-12 11:15:28.484607: Epoch time: 145.08 s 
2025-07-12 11:15:30.411455:  
2025-07-12 11:15:30.412502: Epoch 545 
2025-07-12 11:15:30.412937: Current learning rate: 0.00492 
2025-07-12 11:17:53.002895: train_loss -0.7875 
2025-07-12 11:17:53.003992: val_loss -0.8201 
2025-07-12 11:17:53.004080: Pseudo dice [0.9609] 
2025-07-12 11:17:53.004162: Epoch time: 142.59 s 
2025-07-12 11:17:54.706333:  
2025-07-12 11:17:54.707174: Epoch 546 
2025-07-12 11:17:54.707477: Current learning rate: 0.00491 
2025-07-12 11:20:18.637933: train_loss -0.7999 
2025-07-12 11:20:18.639177: val_loss -0.8363 
2025-07-12 11:20:18.639313: Pseudo dice [0.9638] 
2025-07-12 11:20:18.639476: Epoch time: 143.93 s 
2025-07-12 11:20:20.732709:  
2025-07-12 11:20:20.734051: Epoch 547 
2025-07-12 11:20:20.734478: Current learning rate: 0.0049 
2025-07-12 11:22:43.593454: train_loss -0.777 
2025-07-12 11:22:43.594471: val_loss -0.8127 
2025-07-12 11:22:43.594546: Pseudo dice [0.9627] 
2025-07-12 11:22:43.594640: Epoch time: 142.86 s 
2025-07-12 11:22:45.290662:  
2025-07-12 11:22:45.291676: Epoch 548 
2025-07-12 11:22:45.291980: Current learning rate: 0.00489 
2025-07-12 11:25:07.435861: train_loss -0.7888 
2025-07-12 11:25:07.436645: val_loss -0.7844 
2025-07-12 11:25:07.436716: Pseudo dice [0.9645] 
2025-07-12 11:25:07.436789: Epoch time: 142.15 s 
2025-07-12 11:25:08.852180:  
2025-07-12 11:25:08.852666: Epoch 549 
2025-07-12 11:25:08.852912: Current learning rate: 0.00488 
2025-07-12 11:27:33.435112: train_loss -0.7975 
2025-07-12 11:27:33.436034: val_loss -0.8203 
2025-07-12 11:27:33.436107: Pseudo dice [0.967] 
2025-07-12 11:27:33.436196: Epoch time: 144.58 s 
2025-07-12 11:27:35.767247:  
2025-07-12 11:27:35.767638: Epoch 550 
2025-07-12 11:27:35.767732: Current learning rate: 0.00487 
2025-07-12 11:29:56.513807: train_loss -0.8041 
2025-07-12 11:29:56.514913: val_loss -0.8337 
2025-07-12 11:29:56.515004: Pseudo dice [0.9614] 
2025-07-12 11:29:56.515101: Epoch time: 140.75 s 
2025-07-12 11:29:58.272939:  
2025-07-12 11:29:58.273504: Epoch 551 
2025-07-12 11:29:58.273826: Current learning rate: 0.00486 
2025-07-12 11:32:23.644608: train_loss -0.7956 
2025-07-12 11:32:23.646121: val_loss -0.7983 
2025-07-12 11:32:23.646305: Pseudo dice [0.9677] 
2025-07-12 11:32:23.646500: Epoch time: 145.37 s 
2025-07-12 11:32:23.646588: Yayy! New best EMA pseudo Dice: 0.9611 
2025-07-12 11:32:26.590425:  
2025-07-12 11:32:26.591022: Epoch 552 
2025-07-12 11:32:26.591299: Current learning rate: 0.00485 
2025-07-12 11:34:50.834913: train_loss -0.7995 
2025-07-12 11:34:50.837039: val_loss -0.8295 
2025-07-12 11:34:50.837478: Pseudo dice [0.9657] 
2025-07-12 11:34:50.837914: Epoch time: 144.25 s 
2025-07-12 11:34:50.838134: Yayy! New best EMA pseudo Dice: 0.9616 
2025-07-12 11:34:54.424041:  
2025-07-12 11:34:54.424798: Epoch 553 
2025-07-12 11:34:54.425199: Current learning rate: 0.00484 
2025-07-12 11:37:17.452038: train_loss -0.7765 
2025-07-12 11:37:17.452978: val_loss -0.7983 
2025-07-12 11:37:17.453065: Pseudo dice [0.9652] 
2025-07-12 11:37:17.453154: Epoch time: 143.03 s 
2025-07-12 11:37:17.453315: Yayy! New best EMA pseudo Dice: 0.962 
2025-07-12 11:37:20.285783:  
2025-07-12 11:37:20.286130: Epoch 554 
2025-07-12 11:37:20.286266: Current learning rate: 0.00484 
2025-07-12 11:39:42.296417: train_loss -0.8066 
2025-07-12 11:39:42.300979: val_loss -0.8119 
2025-07-12 11:39:42.301061: Pseudo dice [0.9687] 
2025-07-12 11:39:42.301170: Epoch time: 142.01 s 
2025-07-12 11:39:42.301218: Yayy! New best EMA pseudo Dice: 0.9626 
2025-07-12 11:39:45.580633:  
2025-07-12 11:39:45.581373: Epoch 555 
2025-07-12 11:39:45.581763: Current learning rate: 0.00483 
2025-07-12 11:42:10.833987: train_loss -0.7981 
2025-07-12 11:42:10.835588: val_loss -0.7903 
2025-07-12 11:42:10.835981: Pseudo dice [0.9663] 
2025-07-12 11:42:10.836183: Epoch time: 145.25 s 
2025-07-12 11:42:10.836384: Yayy! New best EMA pseudo Dice: 0.963 
2025-07-12 11:42:16.829959:  
2025-07-12 11:42:16.830393: Epoch 556 
2025-07-12 11:42:16.830485: Current learning rate: 0.00482 
2025-07-12 11:44:39.267001: train_loss -0.7898 
2025-07-12 11:44:39.268169: val_loss -0.8137 
2025-07-12 11:44:39.268249: Pseudo dice [0.9702] 
2025-07-12 11:44:39.268353: Epoch time: 142.44 s 
2025-07-12 11:44:39.268414: Yayy! New best EMA pseudo Dice: 0.9637 
2025-07-12 11:44:42.710319:  
2025-07-12 11:44:42.710736: Epoch 557 
2025-07-12 11:44:42.710878: Current learning rate: 0.00481 
2025-07-12 11:47:05.508208: train_loss -0.7937 
2025-07-12 11:47:05.514219: val_loss -0.804 
2025-07-12 11:47:05.514433: Pseudo dice [0.9689] 
2025-07-12 11:47:05.514558: Epoch time: 142.8 s 
2025-07-12 11:47:05.514626: Yayy! New best EMA pseudo Dice: 0.9642 
2025-07-12 11:47:09.345866:  
2025-07-12 11:47:09.346765: Epoch 558 
2025-07-12 11:47:09.347093: Current learning rate: 0.0048 
2025-07-12 11:49:35.731382: train_loss -0.7987 
2025-07-12 11:49:35.732526: val_loss -0.8127 
2025-07-12 11:49:35.732610: Pseudo dice [0.9664] 
2025-07-12 11:49:35.732697: Epoch time: 146.39 s 
2025-07-12 11:49:35.732735: Yayy! New best EMA pseudo Dice: 0.9645 
2025-07-12 11:49:38.405146:  
2025-07-12 11:49:38.405427: Epoch 559 
2025-07-12 11:49:38.405557: Current learning rate: 0.00479 
2025-07-12 11:52:07.244017: train_loss -0.7864 
2025-07-12 11:52:07.245144: val_loss -0.8318 
2025-07-12 11:52:07.245226: Pseudo dice [0.9673] 
2025-07-12 11:52:07.245318: Epoch time: 148.84 s 
2025-07-12 11:52:07.245359: Yayy! New best EMA pseudo Dice: 0.9647 
2025-07-12 11:52:09.441333:  
2025-07-12 11:52:09.441807: Epoch 560 
2025-07-12 11:52:09.441913: Current learning rate: 0.00478 
2025-07-12 11:54:31.504790: train_loss -0.7766 
2025-07-12 11:54:31.506584: val_loss -0.8093 
2025-07-12 11:54:31.507120: Pseudo dice [0.9398] 
2025-07-12 11:54:31.507519: Epoch time: 142.06 s 
2025-07-12 11:54:33.466966:  
2025-07-12 11:54:33.467924: Epoch 561 
2025-07-12 11:54:33.468321: Current learning rate: 0.00477 
2025-07-12 11:56:57.969109: train_loss -0.7648 
2025-07-12 11:56:57.970151: val_loss -0.809 
2025-07-12 11:56:57.970217: Pseudo dice [0.956] 
2025-07-12 11:56:57.970320: Epoch time: 144.5 s 
2025-07-12 11:56:59.783678:  
2025-07-12 11:56:59.784643: Epoch 562 
2025-07-12 11:56:59.785034: Current learning rate: 0.00476 
2025-07-12 11:59:22.186033: train_loss -0.7774 
2025-07-12 11:59:22.187232: val_loss -0.7926 
2025-07-12 11:59:22.187367: Pseudo dice [0.9546] 
2025-07-12 11:59:22.187472: Epoch time: 142.4 s 
2025-07-12 11:59:24.224174:  
2025-07-12 11:59:24.225030: Epoch 563 
2025-07-12 11:59:24.225399: Current learning rate: 0.00475 
2025-07-12 12:01:47.130777: train_loss -0.7871 
2025-07-12 12:01:47.131866: val_loss -0.7899 
2025-07-12 12:01:47.131940: Pseudo dice [0.9609] 
2025-07-12 12:01:47.132022: Epoch time: 142.91 s 
2025-07-12 12:01:48.677339:  
2025-07-12 12:01:48.678216: Epoch 564 
2025-07-12 12:01:48.678540: Current learning rate: 0.00474 
2025-07-12 12:04:11.076354: train_loss -0.7926 
2025-07-12 12:04:11.078338: val_loss -0.8139 
2025-07-12 12:04:11.078483: Pseudo dice [0.9608] 
2025-07-12 12:04:11.078616: Epoch time: 142.4 s 
2025-07-12 12:04:13.083829:  
2025-07-12 12:04:13.084944: Epoch 565 
2025-07-12 12:04:13.085349: Current learning rate: 0.00473 
2025-07-12 12:06:33.554245: train_loss -0.7896 
2025-07-12 12:06:33.555644: val_loss -0.8081 
2025-07-12 12:06:33.555736: Pseudo dice [0.9566] 
2025-07-12 12:06:33.555851: Epoch time: 140.47 s 
2025-07-12 12:06:35.542390:  
2025-07-12 12:06:35.543217: Epoch 566 
2025-07-12 12:06:35.543556: Current learning rate: 0.00472 
2025-07-12 12:09:00.163704: train_loss -0.7924 
2025-07-12 12:09:00.165468: val_loss -0.8023 
2025-07-12 12:09:00.165884: Pseudo dice [0.9614] 
2025-07-12 12:09:00.166129: Epoch time: 144.62 s 
2025-07-12 12:09:01.840743:  
2025-07-12 12:09:01.841396: Epoch 567 
2025-07-12 12:09:01.841634: Current learning rate: 0.00471 
2025-07-12 12:11:25.780678: train_loss -0.7917 
2025-07-12 12:11:25.781660: val_loss -0.8069 
2025-07-12 12:11:25.781731: Pseudo dice [0.9624] 
2025-07-12 12:11:25.781822: Epoch time: 143.94 s 
2025-07-12 12:11:27.693753:  
2025-07-12 12:11:27.694636: Epoch 568 
2025-07-12 12:11:27.694995: Current learning rate: 0.0047 
2025-07-12 12:13:51.562427: train_loss -0.801 
2025-07-12 12:13:51.563617: val_loss -0.8189 
2025-07-12 12:13:51.563722: Pseudo dice [0.9631] 
2025-07-12 12:13:51.563855: Epoch time: 143.87 s 
2025-07-12 12:13:53.593618:  
2025-07-12 12:13:53.594595: Epoch 569 
2025-07-12 12:13:53.595050: Current learning rate: 0.00469 
2025-07-12 12:16:20.296619: train_loss -0.7922 
2025-07-12 12:16:20.298375: val_loss -0.7998 
2025-07-12 12:16:20.298667: Pseudo dice [0.9577] 
2025-07-12 12:16:20.298933: Epoch time: 146.71 s 
2025-07-12 12:16:22.423673:  
2025-07-12 12:16:22.424698: Epoch 570 
2025-07-12 12:16:22.425101: Current learning rate: 0.00468 
2025-07-12 12:18:45.970157: train_loss -0.7846 
2025-07-12 12:18:45.971197: val_loss -0.8042 
2025-07-12 12:18:45.971290: Pseudo dice [0.9593] 
2025-07-12 12:18:45.971405: Epoch time: 143.55 s 
2025-07-12 12:18:47.999665:  
2025-07-12 12:18:48.000524: Epoch 571 
2025-07-12 12:18:48.000959: Current learning rate: 0.00467 
2025-07-12 12:21:15.154846: train_loss -0.7644 
2025-07-12 12:21:15.156045: val_loss -0.8102 
2025-07-12 12:21:15.156137: Pseudo dice [0.954] 
2025-07-12 12:21:15.156242: Epoch time: 147.16 s 
2025-07-12 12:21:16.968840:  
2025-07-12 12:21:16.969270: Epoch 572 
2025-07-12 12:21:16.969423: Current learning rate: 0.00466 
2025-07-12 12:23:41.690673: train_loss -0.7666 
2025-07-12 12:23:41.691908: val_loss -0.8 
2025-07-12 12:23:41.692070: Pseudo dice [0.9538] 
2025-07-12 12:23:41.692220: Epoch time: 144.72 s 
2025-07-12 12:23:43.780021:  
2025-07-12 12:23:43.780907: Epoch 573 
2025-07-12 12:23:43.781274: Current learning rate: 0.00465 
2025-07-12 12:26:09.765330: train_loss -0.7911 
2025-07-12 12:26:09.766784: val_loss -0.8143 
2025-07-12 12:26:09.767033: Pseudo dice [0.9617] 
2025-07-12 12:26:09.767293: Epoch time: 145.99 s 
2025-07-12 12:26:11.355130:  
2025-07-12 12:26:11.355863: Epoch 574 
2025-07-12 12:26:11.356159: Current learning rate: 0.00464 
2025-07-12 12:28:36.573941: train_loss -0.782 
2025-07-12 12:28:36.574980: val_loss -0.7915 
2025-07-12 12:28:36.575097: Pseudo dice [0.954] 
2025-07-12 12:28:36.575214: Epoch time: 145.22 s 
2025-07-12 12:28:40.189941:  
2025-07-12 12:28:40.190176: Epoch 575 
2025-07-12 12:28:40.190305: Current learning rate: 0.00463 
2025-07-12 12:31:02.223803: train_loss -0.7831 
2025-07-12 12:31:02.224962: val_loss -0.8165 
2025-07-12 12:31:02.225039: Pseudo dice [0.957] 
2025-07-12 12:31:02.225133: Epoch time: 142.03 s 
2025-07-12 12:31:04.108793:  
2025-07-12 12:31:04.110153: Epoch 576 
2025-07-12 12:31:04.110506: Current learning rate: 0.00462 
2025-07-12 12:33:30.597243: train_loss -0.7794 
2025-07-12 12:33:30.598245: val_loss -0.7804 
2025-07-12 12:33:30.598329: Pseudo dice [0.9485] 
2025-07-12 12:33:30.598393: Epoch time: 146.49 s 
2025-07-12 12:33:32.049263:  
2025-07-12 12:33:32.049667: Epoch 577 
2025-07-12 12:33:32.049797: Current learning rate: 0.00461 
2025-07-12 12:35:54.704435: train_loss -0.7818 
2025-07-12 12:35:54.705682: val_loss -0.8344 
2025-07-12 12:35:54.705762: Pseudo dice [0.9647] 
2025-07-12 12:35:54.705844: Epoch time: 142.66 s 
2025-07-12 12:35:56.637217:  
2025-07-12 12:35:56.638705: Epoch 578 
2025-07-12 12:35:56.639107: Current learning rate: 0.0046 
2025-07-12 12:38:19.975853: train_loss -0.7921 
2025-07-12 12:38:19.976761: val_loss -0.8371 
2025-07-12 12:38:19.976825: Pseudo dice [0.964] 
2025-07-12 12:38:19.976910: Epoch time: 143.34 s 
2025-07-12 12:38:21.736207:  
2025-07-12 12:38:21.737461: Epoch 579 
2025-07-12 12:38:21.737937: Current learning rate: 0.00459 
2025-07-12 12:40:42.220118: train_loss -0.7959 
2025-07-12 12:40:42.221506: val_loss -0.8075 
2025-07-12 12:40:42.221601: Pseudo dice [0.9564] 
2025-07-12 12:40:42.221703: Epoch time: 140.49 s 
2025-07-12 12:40:44.013120:  
2025-07-12 12:40:44.014127: Epoch 580 
2025-07-12 12:40:44.014409: Current learning rate: 0.00458 
2025-07-12 12:43:08.960942: train_loss -0.7803 
2025-07-12 12:43:08.962094: val_loss -0.781 
2025-07-12 12:43:08.962183: Pseudo dice [0.9595] 
2025-07-12 12:43:08.962290: Epoch time: 144.95 s 
2025-07-12 12:43:10.760269:  
2025-07-12 12:43:10.761373: Epoch 581 
2025-07-12 12:43:10.761773: Current learning rate: 0.00457 
2025-07-12 12:45:37.417782: train_loss -0.7697 
2025-07-12 12:45:37.418886: val_loss -0.8081 
2025-07-12 12:45:37.419087: Pseudo dice [0.9556] 
2025-07-12 12:45:37.419196: Epoch time: 146.66 s 
2025-07-12 12:45:38.808971:  
2025-07-12 12:45:38.809320: Epoch 582 
2025-07-12 12:45:38.809441: Current learning rate: 0.00456 
2025-07-12 12:48:00.842529: train_loss -0.7834 
2025-07-12 12:48:00.843514: val_loss -0.784 
2025-07-12 12:48:00.843602: Pseudo dice [0.9477] 
2025-07-12 12:48:00.843691: Epoch time: 142.03 s 
2025-07-12 12:48:02.577644:  
2025-07-12 12:48:02.578577: Epoch 583 
2025-07-12 12:48:02.578969: Current learning rate: 0.00455 
2025-07-12 12:50:26.816816: train_loss -0.785 
2025-07-12 12:50:26.818952: val_loss -0.8159 
2025-07-12 12:50:26.819284: Pseudo dice [0.9624] 
2025-07-12 12:50:26.820159: Epoch time: 144.24 s 
2025-07-12 12:50:28.685830:  
2025-07-12 12:50:28.687032: Epoch 584 
2025-07-12 12:50:28.687427: Current learning rate: 0.00454 
2025-07-12 12:52:58.132982: train_loss -0.7936 
2025-07-12 12:52:58.134012: val_loss -0.7697 
2025-07-12 12:52:58.134092: Pseudo dice [0.9649] 
2025-07-12 12:52:58.134176: Epoch time: 149.45 s 
2025-07-12 12:52:59.728866:  
2025-07-12 12:52:59.729840: Epoch 585 
2025-07-12 12:52:59.730200: Current learning rate: 0.00453 
2025-07-12 12:55:25.491358: train_loss -0.7863 
2025-07-12 12:55:25.492451: val_loss -0.7995 
2025-07-12 12:55:25.492537: Pseudo dice [0.9616] 
2025-07-12 12:55:25.492634: Epoch time: 145.76 s 
2025-07-12 12:55:27.470888:  
2025-07-12 12:55:27.472039: Epoch 586 
2025-07-12 12:55:27.472433: Current learning rate: 0.00452 
2025-07-12 12:57:55.706886: train_loss -0.7947 
2025-07-12 12:57:55.708045: val_loss -0.7867 
2025-07-12 12:57:55.708126: Pseudo dice [0.9552] 
2025-07-12 12:57:55.708223: Epoch time: 148.24 s 
2025-07-12 12:57:57.379470:  
2025-07-12 12:57:57.380493: Epoch 587 
2025-07-12 12:57:57.380869: Current learning rate: 0.00451 
2025-07-12 13:00:21.495623: train_loss -0.7796 
2025-07-12 13:00:21.496969: val_loss -0.8063 
2025-07-12 13:00:21.497087: Pseudo dice [0.9622] 
2025-07-12 13:00:21.497198: Epoch time: 144.12 s 
2025-07-12 13:00:23.135540:  
2025-07-12 13:00:23.136453: Epoch 588 
2025-07-12 13:00:23.136684: Current learning rate: 0.0045 
2025-07-12 13:02:44.808163: train_loss -0.7966 
2025-07-12 13:02:44.809514: val_loss -0.8288 
2025-07-12 13:02:44.809630: Pseudo dice [0.9672] 
2025-07-12 13:02:44.809758: Epoch time: 141.67 s 
2025-07-12 13:02:46.837629:  
2025-07-12 13:02:46.838931: Epoch 589 
2025-07-12 13:02:46.839411: Current learning rate: 0.00449 
2025-07-12 13:05:11.161426: train_loss -0.8052 
2025-07-12 13:05:11.162845: val_loss -0.8237 
2025-07-12 13:05:11.162929: Pseudo dice [0.9669] 
2025-07-12 13:05:11.163029: Epoch time: 144.33 s 
2025-07-12 13:05:13.213801:  
2025-07-12 13:05:13.214437: Epoch 590 
2025-07-12 13:05:13.214690: Current learning rate: 0.00448 
2025-07-12 13:07:35.145443: train_loss -0.8077 
2025-07-12 13:07:35.147925: val_loss -0.8184 
2025-07-12 13:07:35.148489: Pseudo dice [0.9674] 
2025-07-12 13:07:35.148677: Epoch time: 141.93 s 
2025-07-12 13:07:37.260463:  
2025-07-12 13:07:37.261357: Epoch 591 
2025-07-12 13:07:37.261741: Current learning rate: 0.00447 
2025-07-12 13:09:57.859344: train_loss -0.803 
2025-07-12 13:09:57.860475: val_loss -0.7982 
2025-07-12 13:09:57.860554: Pseudo dice [0.9616] 
2025-07-12 13:09:57.860643: Epoch time: 140.6 s 
2025-07-12 13:09:59.930810:  
2025-07-12 13:09:59.931749: Epoch 592 
2025-07-12 13:09:59.932125: Current learning rate: 0.00446 
2025-07-12 13:12:23.220220: train_loss -0.7853 
2025-07-12 13:12:23.222194: val_loss -0.7792 
2025-07-12 13:12:23.222463: Pseudo dice [0.9635] 
2025-07-12 13:12:23.222664: Epoch time: 143.29 s 
2025-07-12 13:12:24.956768:  
2025-07-12 13:12:24.957552: Epoch 593 
2025-07-12 13:12:24.957888: Current learning rate: 0.00445 
2025-07-12 13:14:47.379082: train_loss -0.7918 
2025-07-12 13:14:47.380692: val_loss -0.8227 
2025-07-12 13:14:47.380834: Pseudo dice [0.9679] 
2025-07-12 13:14:47.381019: Epoch time: 142.42 s 
2025-07-12 13:14:49.460414:  
2025-07-12 13:14:49.461361: Epoch 594 
2025-07-12 13:14:49.461772: Current learning rate: 0.00444 
2025-07-12 13:17:13.691355: train_loss -0.7979 
2025-07-12 13:17:13.692394: val_loss -0.7955 
2025-07-12 13:17:13.692466: Pseudo dice [0.965] 
2025-07-12 13:17:13.692547: Epoch time: 144.23 s 
2025-07-12 13:17:18.726988:  
2025-07-12 13:17:18.727461: Epoch 595 
2025-07-12 13:17:18.727594: Current learning rate: 0.00443 
2025-07-12 13:19:40.619697: train_loss -0.7804 
2025-07-12 13:19:40.621645: val_loss -0.7888 
2025-07-12 13:19:40.621792: Pseudo dice [0.9628] 
2025-07-12 13:19:40.621891: Epoch time: 141.89 s 
2025-07-12 13:19:42.864662:  
2025-07-12 13:19:42.865776: Epoch 596 
2025-07-12 13:19:42.866162: Current learning rate: 0.00442 
2025-07-12 13:22:06.752080: train_loss -0.7899 
2025-07-12 13:22:06.754483: val_loss -0.7798 
2025-07-12 13:22:06.754959: Pseudo dice [0.9656] 
2025-07-12 13:22:06.755243: Epoch time: 143.89 s 
2025-07-12 13:22:08.794061:  
2025-07-12 13:22:08.795236: Epoch 597 
2025-07-12 13:22:08.795633: Current learning rate: 0.00441 
2025-07-12 13:24:33.568280: train_loss -0.785 
2025-07-12 13:24:33.569504: val_loss -0.8188 
2025-07-12 13:24:33.569641: Pseudo dice [0.9607] 
2025-07-12 13:24:33.569803: Epoch time: 144.78 s 
2025-07-12 13:24:35.282956:  
2025-07-12 13:24:35.283943: Epoch 598 
2025-07-12 13:24:35.284443: Current learning rate: 0.0044 
2025-07-12 13:27:00.512788: train_loss -0.7755 
2025-07-12 13:27:00.515153: val_loss -0.7775 
2025-07-12 13:27:00.515234: Pseudo dice [0.9529] 
2025-07-12 13:27:00.515340: Epoch time: 145.23 s 
2025-07-12 13:27:02.722291:  
2025-07-12 13:27:02.723155: Epoch 599 
2025-07-12 13:27:02.723452: Current learning rate: 0.00439 
2025-07-12 13:29:29.262692: train_loss -0.7805 
2025-07-12 13:29:29.263834: val_loss -0.7597 
2025-07-12 13:29:29.263921: Pseudo dice [0.9382] 
2025-07-12 13:29:29.263990: Epoch time: 146.54 s 
2025-07-12 13:29:33.108966:  
2025-07-12 13:29:33.110050: Epoch 600 
2025-07-12 13:29:33.110440: Current learning rate: 0.00438 
2025-07-12 13:31:56.958528: train_loss -0.7807 
2025-07-12 13:31:56.959740: val_loss -0.8115 
2025-07-12 13:31:56.959823: Pseudo dice [0.9588] 
2025-07-12 13:31:56.959921: Epoch time: 143.85 s 
2025-07-12 13:31:59.044667:  
2025-07-12 13:31:59.044971: Epoch 601 
2025-07-12 13:31:59.045124: Current learning rate: 0.00437 
2025-07-12 13:34:21.743643: train_loss -0.7856 
2025-07-12 13:34:21.744542: val_loss -0.795 
2025-07-12 13:34:21.744611: Pseudo dice [0.9635] 
2025-07-12 13:34:21.744726: Epoch time: 142.7 s 
2025-07-12 13:34:23.835676:  
2025-07-12 13:34:23.836806: Epoch 602 
2025-07-12 13:34:23.837204: Current learning rate: 0.00436 
2025-07-12 13:36:49.111064: train_loss -0.7885 
2025-07-12 13:36:49.112272: val_loss -0.814 
2025-07-12 13:36:49.112367: Pseudo dice [0.9622] 
2025-07-12 13:36:49.112455: Epoch time: 145.28 s 
2025-07-12 13:36:50.842565:  
2025-07-12 13:36:50.843443: Epoch 603 
2025-07-12 13:36:50.843774: Current learning rate: 0.00435 
2025-07-12 13:39:12.900096: train_loss -0.7854 
2025-07-12 13:39:12.901500: val_loss -0.8208 
2025-07-12 13:39:12.901695: Pseudo dice [0.9667] 
2025-07-12 13:39:12.901870: Epoch time: 142.06 s 
2025-07-12 13:39:14.838200:  
2025-07-12 13:39:14.839322: Epoch 604 
2025-07-12 13:39:14.839711: Current learning rate: 0.00434 
2025-07-12 13:41:41.326212: train_loss -0.7915 
2025-07-12 13:41:41.327709: val_loss -0.8 
2025-07-12 13:41:41.327798: Pseudo dice [0.9653] 
2025-07-12 13:41:41.327924: Epoch time: 146.49 s 
2025-07-12 13:41:42.881286:  
2025-07-12 13:41:42.881730: Epoch 605 
2025-07-12 13:41:42.881963: Current learning rate: 0.00433 
2025-07-12 13:44:07.173882: train_loss -0.8067 
2025-07-12 13:44:07.175456: val_loss -0.817 
2025-07-12 13:44:07.175686: Pseudo dice [0.97] 
2025-07-12 13:44:07.175946: Epoch time: 144.29 s 
2025-07-12 13:44:09.134412:  
2025-07-12 13:44:09.135453: Epoch 606 
2025-07-12 13:44:09.135847: Current learning rate: 0.00432 
2025-07-12 13:46:33.107256: train_loss -0.7932 
2025-07-12 13:46:33.108277: val_loss -0.8215 
2025-07-12 13:46:33.108366: Pseudo dice [0.9623] 
2025-07-12 13:46:33.108451: Epoch time: 143.97 s 
2025-07-12 13:46:35.008330:  
2025-07-12 13:46:35.009410: Epoch 607 
2025-07-12 13:46:35.009765: Current learning rate: 0.00431 
2025-07-12 13:48:58.537689: train_loss -0.7933 
2025-07-12 13:48:58.538832: val_loss -0.7896 
2025-07-12 13:48:58.538921: Pseudo dice [0.9688] 
2025-07-12 13:48:58.539016: Epoch time: 143.53 s 
2025-07-12 13:49:00.457314:  
2025-07-12 13:49:00.458460: Epoch 608 
2025-07-12 13:49:00.458854: Current learning rate: 0.0043 
2025-07-12 13:51:24.398410: train_loss -0.7905 
2025-07-12 13:51:24.400105: val_loss -0.8562 
2025-07-12 13:51:24.400276: Pseudo dice [0.969] 
2025-07-12 13:51:24.400407: Epoch time: 143.94 s 
2025-07-12 13:51:26.407141:  
2025-07-12 13:51:26.408010: Epoch 609 
2025-07-12 13:51:26.408313: Current learning rate: 0.00429 
2025-07-12 13:53:53.959016: train_loss -0.7871 
2025-07-12 13:53:53.960207: val_loss -0.827 
2025-07-12 13:53:53.960416: Pseudo dice [0.9647] 
2025-07-12 13:53:53.960592: Epoch time: 147.55 s 
2025-07-12 13:53:55.476625:  
2025-07-12 13:53:55.477347: Epoch 610 
2025-07-12 13:53:55.477675: Current learning rate: 0.00429 
2025-07-12 13:56:18.318821: train_loss -0.8069 
2025-07-12 13:56:18.319677: val_loss -0.8212 
2025-07-12 13:56:18.319748: Pseudo dice [0.9587] 
2025-07-12 13:56:18.319888: Epoch time: 142.84 s 
2025-07-12 13:56:19.749217:  
2025-07-12 13:56:19.749783: Epoch 611 
2025-07-12 13:56:19.750007: Current learning rate: 0.00428 
2025-07-12 13:58:43.742661: train_loss -0.7955 
2025-07-12 13:58:43.743877: val_loss -0.8194 
2025-07-12 13:58:43.744009: Pseudo dice [0.9617] 
2025-07-12 13:58:43.744144: Epoch time: 143.99 s 
2025-07-12 13:58:45.435731:  
2025-07-12 13:58:45.436428: Epoch 612 
2025-07-12 13:58:45.436735: Current learning rate: 0.00427 
2025-07-12 14:01:10.139725: train_loss -0.7837 
2025-07-12 14:01:10.140897: val_loss -0.8126 
2025-07-12 14:01:10.140978: Pseudo dice [0.9489] 
2025-07-12 14:01:10.141081: Epoch time: 144.71 s 
2025-07-12 14:01:11.929519:  
2025-07-12 14:01:11.930521: Epoch 613 
2025-07-12 14:01:11.930918: Current learning rate: 0.00426 
2025-07-12 14:03:33.546048: train_loss -0.7831 
2025-07-12 14:03:33.547737: val_loss -0.8031 
2025-07-12 14:03:33.547949: Pseudo dice [0.9561] 
2025-07-12 14:03:33.548102: Epoch time: 141.62 s 
2025-07-12 14:03:35.557602:  
2025-07-12 14:03:35.558369: Epoch 614 
2025-07-12 14:03:35.558754: Current learning rate: 0.00425 
2025-07-12 14:05:56.875236: train_loss -0.8003 
2025-07-12 14:05:56.878943: val_loss -0.7929 
2025-07-12 14:05:56.879292: Pseudo dice [0.9633] 
2025-07-12 14:05:56.879414: Epoch time: 141.32 s 
2025-07-12 14:06:02.017529:  
2025-07-12 14:06:02.017936: Epoch 615 
2025-07-12 14:06:02.018114: Current learning rate: 0.00424 
2025-07-12 14:08:25.274366: train_loss -0.7921 
2025-07-12 14:08:25.275417: val_loss -0.801 
2025-07-12 14:08:25.275502: Pseudo dice [0.9676] 
2025-07-12 14:08:25.275589: Epoch time: 143.26 s 
2025-07-12 14:08:26.809690:  
2025-07-12 14:08:26.810627: Epoch 616 
2025-07-12 14:08:26.810864: Current learning rate: 0.00423 
2025-07-12 14:10:50.596937: train_loss -0.796 
2025-07-12 14:10:50.598545: val_loss -0.8438 
2025-07-12 14:10:50.598710: Pseudo dice [0.9693] 
2025-07-12 14:10:50.598891: Epoch time: 143.79 s 
2025-07-12 14:10:52.516797:  
2025-07-12 14:10:52.518189: Epoch 617 
2025-07-12 14:10:52.518853: Current learning rate: 0.00422 
2025-07-12 14:13:16.895343: train_loss -0.7989 
2025-07-12 14:13:16.897838: val_loss -0.8313 
2025-07-12 14:13:16.897979: Pseudo dice [0.9659] 
2025-07-12 14:13:16.898111: Epoch time: 144.38 s 
2025-07-12 14:13:19.023669:  
2025-07-12 14:13:19.024963: Epoch 618 
2025-07-12 14:13:19.025336: Current learning rate: 0.00421 
2025-07-12 14:15:41.999355: train_loss -0.8053 
2025-07-12 14:15:42.001051: val_loss -0.8206 
2025-07-12 14:15:42.001275: Pseudo dice [0.9657] 
2025-07-12 14:15:42.001421: Epoch time: 142.98 s 
2025-07-12 14:15:43.927000:  
2025-07-12 14:15:43.928018: Epoch 619 
2025-07-12 14:15:43.928326: Current learning rate: 0.0042 
2025-07-12 14:18:13.099662: train_loss -0.7919 
2025-07-12 14:18:13.100911: val_loss -0.8547 
2025-07-12 14:18:13.100991: Pseudo dice [0.9707] 
2025-07-12 14:18:13.101083: Epoch time: 149.17 s 
2025-07-12 14:18:14.944103:  
2025-07-12 14:18:14.945066: Epoch 620 
2025-07-12 14:18:14.945380: Current learning rate: 0.00419 
2025-07-12 14:20:36.999048: train_loss -0.7921 
2025-07-12 14:20:37.000426: val_loss -0.8303 
2025-07-12 14:20:37.000518: Pseudo dice [0.9672] 
2025-07-12 14:20:37.000639: Epoch time: 142.06 s 
2025-07-12 14:20:38.858511:  
2025-07-12 14:20:38.859546: Epoch 621 
2025-07-12 14:20:38.859848: Current learning rate: 0.00418 
2025-07-12 14:23:03.637532: train_loss -0.7893 
2025-07-12 14:23:03.638695: val_loss -0.8219 
2025-07-12 14:23:03.638786: Pseudo dice [0.9692] 
2025-07-12 14:23:03.638904: Epoch time: 144.78 s 
2025-07-12 14:23:05.145165:  
2025-07-12 14:23:05.145869: Epoch 622 
2025-07-12 14:23:05.146184: Current learning rate: 0.00417 
2025-07-12 14:25:29.021154: train_loss -0.7914 
2025-07-12 14:25:29.022792: val_loss -0.8394 
2025-07-12 14:25:29.022910: Pseudo dice [0.9638] 
2025-07-12 14:25:29.023026: Epoch time: 143.88 s 
2025-07-12 14:25:30.929240:  
2025-07-12 14:25:30.930444: Epoch 623 
2025-07-12 14:25:30.930837: Current learning rate: 0.00416 
2025-07-12 14:27:58.190913: train_loss -0.7853 
2025-07-12 14:27:58.192382: val_loss -0.8016 
2025-07-12 14:27:58.192557: Pseudo dice [0.9619] 
2025-07-12 14:27:58.192687: Epoch time: 147.26 s 
2025-07-12 14:27:59.693532:  
2025-07-12 14:27:59.693933: Epoch 624 
2025-07-12 14:27:59.694117: Current learning rate: 0.00415 
2025-07-12 14:30:26.251171: train_loss -0.7971 
2025-07-12 14:30:26.255321: val_loss -0.7995 
2025-07-12 14:30:26.255432: Pseudo dice [0.9606] 
2025-07-12 14:30:26.255522: Epoch time: 146.56 s 
2025-07-12 14:30:27.989640:  
2025-07-12 14:30:27.990616: Epoch 625 
2025-07-12 14:30:27.991006: Current learning rate: 0.00414 
2025-07-12 14:32:51.154493: train_loss -0.7961 
2025-07-12 14:32:51.155667: val_loss -0.8256 
2025-07-12 14:32:51.155751: Pseudo dice [0.9639] 
2025-07-12 14:32:51.155859: Epoch time: 143.17 s 
2025-07-12 14:32:53.139139:  
2025-07-12 14:32:53.140128: Epoch 626 
2025-07-12 14:32:53.140502: Current learning rate: 0.00413 
2025-07-12 14:35:16.230760: train_loss -0.7962 
2025-07-12 14:35:16.231930: val_loss -0.8224 
2025-07-12 14:35:16.232012: Pseudo dice [0.968] 
2025-07-12 14:35:16.232115: Epoch time: 143.09 s 
2025-07-12 14:35:18.182567:  
2025-07-12 14:35:18.183552: Epoch 627 
2025-07-12 14:35:18.183942: Current learning rate: 0.00412 
2025-07-12 14:37:45.426090: train_loss -0.7885 
2025-07-12 14:37:45.427364: val_loss -0.8358 
2025-07-12 14:37:45.427479: Pseudo dice [0.9685] 
2025-07-12 14:37:45.427590: Epoch time: 147.25 s 
2025-07-12 14:37:45.427669: Yayy! New best EMA pseudo Dice: 0.9648 
2025-07-12 14:37:47.827694:  
2025-07-12 14:37:47.828024: Epoch 628 
2025-07-12 14:37:47.828130: Current learning rate: 0.00411 
2025-07-12 14:40:10.532126: train_loss -0.7967 
2025-07-12 14:40:10.533682: val_loss -0.8022 
2025-07-12 14:40:10.533776: Pseudo dice [0.9703] 
2025-07-12 14:40:10.533865: Epoch time: 142.71 s 
2025-07-12 14:40:10.533915: Yayy! New best EMA pseudo Dice: 0.9653 
2025-07-12 14:40:14.268102:  
2025-07-12 14:40:14.269109: Epoch 629 
2025-07-12 14:40:14.269572: Current learning rate: 0.0041 
2025-07-12 14:42:39.054745: train_loss -0.7905 
2025-07-12 14:42:39.059931: val_loss -0.8212 
2025-07-12 14:42:39.060057: Pseudo dice [0.9634] 
2025-07-12 14:42:39.060176: Epoch time: 144.79 s 
2025-07-12 14:42:41.074090:  
2025-07-12 14:42:41.075071: Epoch 630 
2025-07-12 14:42:41.075542: Current learning rate: 0.00409 
2025-07-12 14:45:06.648793: train_loss -0.8044 
2025-07-12 14:45:06.649764: val_loss -0.8136 
2025-07-12 14:45:06.649829: Pseudo dice [0.9666] 
2025-07-12 14:45:06.649909: Epoch time: 145.58 s 
2025-07-12 14:45:08.134270:  
2025-07-12 14:45:08.134771: Epoch 631 
2025-07-12 14:45:08.134957: Current learning rate: 0.00408 
2025-07-12 14:47:33.196427: train_loss -0.787 
2025-07-12 14:47:33.197633: val_loss -0.8238 
2025-07-12 14:47:33.197713: Pseudo dice [0.9674] 
2025-07-12 14:47:33.197785: Epoch time: 145.06 s 
2025-07-12 14:47:33.197824: Yayy! New best EMA pseudo Dice: 0.9655 
2025-07-12 14:47:35.325894:  
2025-07-12 14:47:35.326316: Epoch 632 
2025-07-12 14:47:35.326415: Current learning rate: 0.00407 
2025-07-12 14:49:57.914091: train_loss -0.8093 
2025-07-12 14:49:57.915779: val_loss -0.8265 
2025-07-12 14:49:57.915930: Pseudo dice [0.9698] 
2025-07-12 14:49:57.916047: Epoch time: 142.59 s 
2025-07-12 14:49:57.916158: Yayy! New best EMA pseudo Dice: 0.9659 
2025-07-12 14:50:00.817294:  
2025-07-12 14:50:00.817729: Epoch 633 
2025-07-12 14:50:00.817844: Current learning rate: 0.00406 
2025-07-12 14:52:23.237085: train_loss -0.7933 
2025-07-12 14:52:23.238503: val_loss -0.795 
2025-07-12 14:52:23.238760: Pseudo dice [0.9678] 
2025-07-12 14:52:23.238981: Epoch time: 142.42 s 
2025-07-12 14:52:23.239152: Yayy! New best EMA pseudo Dice: 0.9661 
2025-07-12 14:52:27.346770:  
2025-07-12 14:52:27.347216: Epoch 634 
2025-07-12 14:52:27.347311: Current learning rate: 0.00405 
2025-07-12 14:54:52.349524: train_loss -0.7681 
2025-07-12 14:54:52.350917: val_loss -0.8016 
2025-07-12 14:54:52.351038: Pseudo dice [0.9423] 
2025-07-12 14:54:52.351173: Epoch time: 145.0 s 
2025-07-12 14:54:53.859343:  
2025-07-12 14:54:53.859998: Epoch 635 
2025-07-12 14:54:53.860217: Current learning rate: 0.00404 
2025-07-12 14:57:17.172707: train_loss -0.778 
2025-07-12 14:57:17.173919: val_loss -0.7772 
2025-07-12 14:57:17.174003: Pseudo dice [0.9613] 
2025-07-12 14:57:17.174100: Epoch time: 143.31 s 
2025-07-12 14:57:19.223281:  
2025-07-12 14:57:19.224356: Epoch 636 
2025-07-12 14:57:19.224730: Current learning rate: 0.00403 
2025-07-12 14:59:45.044878: train_loss -0.7771 
2025-07-12 14:59:45.046465: val_loss -0.7987 
2025-07-12 14:59:45.046724: Pseudo dice [0.9655] 
2025-07-12 14:59:45.046964: Epoch time: 145.82 s 
2025-07-12 14:59:46.886982:  
2025-07-12 14:59:46.888057: Epoch 637 
2025-07-12 14:59:46.888421: Current learning rate: 0.00402 
2025-07-12 15:02:09.582551: train_loss -0.7846 
2025-07-12 15:02:09.583635: val_loss -0.8238 
2025-07-12 15:02:09.583722: Pseudo dice [0.9664] 
2025-07-12 15:02:09.583801: Epoch time: 142.7 s 
2025-07-12 15:02:11.339353:  
2025-07-12 15:02:11.340451: Epoch 638 
2025-07-12 15:02:11.340909: Current learning rate: 0.00401 
2025-07-12 15:04:35.380508: train_loss -0.7906 
2025-07-12 15:04:35.382609: val_loss -0.7948 
2025-07-12 15:04:35.382827: Pseudo dice [0.9631] 
2025-07-12 15:04:35.382979: Epoch time: 144.04 s 
2025-07-12 15:04:37.564787:  
2025-07-12 15:04:37.566051: Epoch 639 
2025-07-12 15:04:37.566476: Current learning rate: 0.004 
2025-07-12 15:07:02.566785: train_loss -0.7883 
2025-07-12 15:07:02.567759: val_loss -0.7818 
2025-07-12 15:07:02.567830: Pseudo dice [0.9572] 
2025-07-12 15:07:02.567900: Epoch time: 145.0 s 
2025-07-12 15:07:04.137322:  
2025-07-12 15:07:04.137963: Epoch 640 
2025-07-12 15:07:04.138216: Current learning rate: 0.00399 
2025-07-12 15:09:26.781694: train_loss -0.787 
2025-07-12 15:09:26.782810: val_loss -0.8449 
2025-07-12 15:09:26.782902: Pseudo dice [0.958] 
2025-07-12 15:09:26.782998: Epoch time: 142.65 s 
2025-07-12 15:09:28.351317:  
2025-07-12 15:09:28.351998: Epoch 641 
2025-07-12 15:09:28.352211: Current learning rate: 0.00398 
2025-07-12 15:11:49.772140: train_loss -0.7725 
2025-07-12 15:11:49.773345: val_loss -0.7814 
2025-07-12 15:11:49.773420: Pseudo dice [0.9461] 
2025-07-12 15:11:49.773507: Epoch time: 141.42 s 
2025-07-12 15:11:51.311308:  
2025-07-12 15:11:51.312090: Epoch 642 
2025-07-12 15:11:51.312321: Current learning rate: 0.00397 
2025-07-12 15:14:17.633864: train_loss -0.7852 
2025-07-12 15:14:17.635373: val_loss -0.8149 
2025-07-12 15:14:17.635499: Pseudo dice [0.9548] 
2025-07-12 15:14:17.635653: Epoch time: 146.32 s 
2025-07-12 15:14:19.077404:  
2025-07-12 15:14:19.077848: Epoch 643 
2025-07-12 15:14:19.078023: Current learning rate: 0.00396 
2025-07-12 15:16:40.160890: train_loss -0.7972 
2025-07-12 15:16:40.162085: val_loss -0.7811 
2025-07-12 15:16:40.162167: Pseudo dice [0.9579] 
2025-07-12 15:16:40.162289: Epoch time: 141.08 s 
2025-07-12 15:16:42.019284:  
2025-07-12 15:16:42.020307: Epoch 644 
2025-07-12 15:16:42.020748: Current learning rate: 0.00395 
2025-07-12 15:19:06.274632: train_loss -0.7904 
2025-07-12 15:19:06.275948: val_loss -0.8242 
2025-07-12 15:19:06.276173: Pseudo dice [0.9661] 
2025-07-12 15:19:06.276368: Epoch time: 144.26 s 
2025-07-12 15:19:07.747755:  
2025-07-12 15:19:07.748191: Epoch 645 
2025-07-12 15:19:07.748371: Current learning rate: 0.00394 
2025-07-12 15:21:29.752462: train_loss -0.7682 
2025-07-12 15:21:29.753844: val_loss -0.7139 
2025-07-12 15:21:29.753977: Pseudo dice [0.9059] 
2025-07-12 15:21:29.754097: Epoch time: 142.01 s 
2025-07-12 15:21:31.506071:  
2025-07-12 15:21:31.506851: Epoch 646 
2025-07-12 15:21:31.507241: Current learning rate: 0.00393 
2025-07-12 15:23:56.023554: train_loss -0.7419 
2025-07-12 15:23:56.024999: val_loss -0.7551 
2025-07-12 15:23:56.025104: Pseudo dice [0.8979] 
2025-07-12 15:23:56.025206: Epoch time: 144.52 s 
2025-07-12 15:23:57.929718:  
2025-07-12 15:23:57.930863: Epoch 647 
2025-07-12 15:23:57.931298: Current learning rate: 0.00392 
2025-07-12 15:26:26.504501: train_loss -0.769 
2025-07-12 15:26:26.505265: val_loss -0.795 
2025-07-12 15:26:26.505387: Pseudo dice [0.9488] 
2025-07-12 15:26:26.505460: Epoch time: 148.58 s 
2025-07-12 15:26:28.008278:  
2025-07-12 15:26:28.008796: Epoch 648 
2025-07-12 15:26:28.009029: Current learning rate: 0.00391 
2025-07-12 15:28:54.244017: train_loss -0.7888 
2025-07-12 15:28:54.245092: val_loss -0.771 
2025-07-12 15:28:54.245170: Pseudo dice [0.9541] 
2025-07-12 15:28:54.245277: Epoch time: 146.24 s 
2025-07-12 15:28:55.775698:  
2025-07-12 15:28:55.776438: Epoch 649 
2025-07-12 15:28:55.776968: Current learning rate: 0.0039 
2025-07-12 15:31:20.120016: train_loss -0.7915 
2025-07-12 15:31:20.121815: val_loss -0.8116 
2025-07-12 15:31:20.121918: Pseudo dice [0.958] 
2025-07-12 15:31:20.122018: Epoch time: 144.35 s 
2025-07-12 15:31:23.878291:  
2025-07-12 15:31:23.879180: Epoch 650 
2025-07-12 15:31:23.879517: Current learning rate: 0.00389 
2025-07-12 15:33:51.170916: train_loss -0.7804 
2025-07-12 15:33:51.171673: val_loss -0.7825 
2025-07-12 15:33:51.171741: Pseudo dice [0.9461] 
2025-07-12 15:33:51.171825: Epoch time: 147.29 s 
2025-07-12 15:33:52.684299:  
2025-07-12 15:33:52.684755: Epoch 651 
2025-07-12 15:33:52.684947: Current learning rate: 0.00388 
2025-07-12 15:36:14.962765: train_loss -0.7807 
2025-07-12 15:36:14.964062: val_loss -0.7931 
2025-07-12 15:36:14.964144: Pseudo dice [0.9598] 
2025-07-12 15:36:14.964225: Epoch time: 142.28 s 
2025-07-12 15:36:16.737675:  
2025-07-12 15:36:16.738337: Epoch 652 
2025-07-12 15:36:16.738601: Current learning rate: 0.00387 
2025-07-12 15:38:40.784773: train_loss -0.7838 
2025-07-12 15:38:40.786196: val_loss -0.7991 
2025-07-12 15:38:40.787234: Pseudo dice [0.9595] 
2025-07-12 15:38:40.787735: Epoch time: 144.05 s 
2025-07-12 15:38:44.617189:  
2025-07-12 15:38:44.617722: Epoch 653 
2025-07-12 15:38:44.617846: Current learning rate: 0.00386 
2025-07-12 15:41:05.900468: train_loss -0.7692 
2025-07-12 15:41:05.901674: val_loss -0.7887 
2025-07-12 15:41:05.901809: Pseudo dice [0.9275] 
2025-07-12 15:41:05.901902: Epoch time: 141.28 s 
2025-07-12 15:41:07.693326:  
2025-07-12 15:41:07.694865: Epoch 654 
2025-07-12 15:41:07.695311: Current learning rate: 0.00385 
2025-07-12 15:43:31.773275: train_loss -0.767 
2025-07-12 15:43:31.774668: val_loss -0.7486 
2025-07-12 15:43:31.774748: Pseudo dice [0.9281] 
2025-07-12 15:43:31.774846: Epoch time: 144.08 s 
2025-07-12 15:43:33.609633:  
2025-07-12 15:43:33.610666: Epoch 655 
2025-07-12 15:43:33.610886: Current learning rate: 0.00384 
2025-07-12 15:45:53.237580: train_loss -0.7596 
2025-07-12 15:45:53.238650: val_loss -0.7824 
2025-07-12 15:45:53.238720: Pseudo dice [0.9391] 
2025-07-12 15:45:53.238816: Epoch time: 139.63 s 
2025-07-12 15:45:54.780414:  
2025-07-12 15:45:54.780979: Epoch 656 
2025-07-12 15:45:54.781201: Current learning rate: 0.00383 
2025-07-12 15:48:19.720315: train_loss -0.7638 
2025-07-12 15:48:19.721559: val_loss -0.7944 
2025-07-12 15:48:19.721648: Pseudo dice [0.9488] 
2025-07-12 15:48:19.721752: Epoch time: 144.94 s 
2025-07-12 15:48:21.762593:  
2025-07-12 15:48:21.764059: Epoch 657 
2025-07-12 15:48:21.764463: Current learning rate: 0.00382 
2025-07-12 15:50:46.290740: train_loss -0.7812 
2025-07-12 15:50:46.292225: val_loss -0.8147 
2025-07-12 15:50:46.292413: Pseudo dice [0.9574] 
2025-07-12 15:50:46.292589: Epoch time: 144.53 s 
2025-07-12 15:50:48.321490:  
2025-07-12 15:50:48.322376: Epoch 658 
2025-07-12 15:50:48.322706: Current learning rate: 0.00381 
2025-07-12 15:53:13.353337: train_loss -0.7859 
2025-07-12 15:53:13.355124: val_loss -0.7888 
2025-07-12 15:53:13.355438: Pseudo dice [0.9657] 
2025-07-12 15:53:13.355610: Epoch time: 145.03 s 
2025-07-12 15:53:15.016893:  
2025-07-12 15:53:15.017610: Epoch 659 
2025-07-12 15:53:15.017875: Current learning rate: 0.0038 
2025-07-12 15:55:39.221544: train_loss -0.7905 
2025-07-12 15:55:39.223099: val_loss -0.8204 
2025-07-12 15:55:39.223188: Pseudo dice [0.9601] 
2025-07-12 15:55:39.223360: Epoch time: 144.21 s 
2025-07-12 15:55:41.196259:  
2025-07-12 15:55:41.197229: Epoch 660 
2025-07-12 15:55:41.197722: Current learning rate: 0.00379 
2025-07-12 15:58:02.881867: train_loss -0.7878 
2025-07-12 15:58:02.882931: val_loss -0.8209 
2025-07-12 15:58:02.883003: Pseudo dice [0.9634] 
2025-07-12 15:58:02.883080: Epoch time: 141.69 s 
2025-07-12 15:58:04.344249:  
2025-07-12 15:58:04.344650: Epoch 661 
2025-07-12 15:58:04.344776: Current learning rate: 0.00378 
2025-07-12 16:00:26.534937: train_loss -0.79 
2025-07-12 16:00:26.536294: val_loss -0.814 
2025-07-12 16:00:26.536440: Pseudo dice [0.959] 
2025-07-12 16:00:26.536565: Epoch time: 142.19 s 
2025-07-12 16:00:28.372952:  
2025-07-12 16:00:28.373943: Epoch 662 
2025-07-12 16:00:28.374328: Current learning rate: 0.00377 
2025-07-12 16:02:50.513690: train_loss -0.7911 
2025-07-12 16:02:50.518858: val_loss -0.7843 
2025-07-12 16:02:50.520295: Pseudo dice [0.9616] 
2025-07-12 16:02:50.520455: Epoch time: 142.14 s 
2025-07-12 16:02:52.423083:  
2025-07-12 16:02:52.424288: Epoch 663 
2025-07-12 16:02:52.424681: Current learning rate: 0.00376 
2025-07-12 16:05:17.389534: train_loss -0.803 
2025-07-12 16:05:17.394335: val_loss -0.8247 
2025-07-12 16:05:17.394417: Pseudo dice [0.9638] 
2025-07-12 16:05:17.394531: Epoch time: 144.97 s 
2025-07-12 16:05:19.211222:  
2025-07-12 16:05:19.212192: Epoch 664 
2025-07-12 16:05:19.212607: Current learning rate: 0.00375 
2025-07-12 16:07:39.666568: train_loss -0.793 
2025-07-12 16:07:39.668693: val_loss -0.7966 
2025-07-12 16:07:39.669104: Pseudo dice [0.964] 
2025-07-12 16:07:39.669625: Epoch time: 140.46 s 
2025-07-12 16:07:41.637339:  
2025-07-12 16:07:41.638530: Epoch 665 
2025-07-12 16:07:41.639040: Current learning rate: 0.00374 
2025-07-12 16:10:06.210678: train_loss -0.7785 
2025-07-12 16:10:06.212076: val_loss -0.81 
2025-07-12 16:10:06.212192: Pseudo dice [0.9548] 
2025-07-12 16:10:06.212442: Epoch time: 144.58 s 
2025-07-12 16:10:08.042179:  
2025-07-12 16:10:08.043054: Epoch 666 
2025-07-12 16:10:08.043431: Current learning rate: 0.00373 
2025-07-12 16:12:33.439609: train_loss -0.7825 
2025-07-12 16:12:33.440666: val_loss -0.8226 
2025-07-12 16:12:33.440742: Pseudo dice [0.9612] 
2025-07-12 16:12:33.440823: Epoch time: 145.4 s 
2025-07-12 16:12:34.885572:  
2025-07-12 16:12:34.886088: Epoch 667 
2025-07-12 16:12:34.886276: Current learning rate: 0.00372 
2025-07-12 16:14:55.851928: train_loss -0.7804 
2025-07-12 16:14:55.867817: val_loss -0.7995 
2025-07-12 16:14:55.876942: Pseudo dice [0.9637] 
2025-07-12 16:14:55.877690: Epoch time: 140.97 s 
2025-07-12 16:14:57.741784:  
2025-07-12 16:14:57.742473: Epoch 668 
2025-07-12 16:14:57.742855: Current learning rate: 0.00371 
2025-07-12 16:17:25.678893: train_loss -0.7911 
2025-07-12 16:17:25.679768: val_loss -0.825 
2025-07-12 16:17:25.679837: Pseudo dice [0.9675] 
2025-07-12 16:17:25.679953: Epoch time: 147.94 s 
2025-07-12 16:17:27.128549:  
2025-07-12 16:17:27.129301: Epoch 669 
2025-07-12 16:17:27.129589: Current learning rate: 0.0037 
2025-07-12 16:19:52.276576: train_loss -0.7678 
2025-07-12 16:19:52.278368: val_loss -0.7954 
2025-07-12 16:19:52.278512: Pseudo dice [0.9563] 
2025-07-12 16:19:52.278676: Epoch time: 145.15 s 
2025-07-12 16:19:54.261100:  
2025-07-12 16:19:54.262213: Epoch 670 
2025-07-12 16:19:54.262499: Current learning rate: 0.00369 
2025-07-12 16:22:18.862740: train_loss -0.7983 
2025-07-12 16:22:18.863768: val_loss -0.8106 
2025-07-12 16:22:18.863843: Pseudo dice [0.962] 
2025-07-12 16:22:18.863919: Epoch time: 144.6 s 
2025-07-12 16:22:21.036802:  
2025-07-12 16:22:21.037834: Epoch 671 
2025-07-12 16:22:21.038227: Current learning rate: 0.00368 
2025-07-12 16:24:47.385515: train_loss -0.7928 
2025-07-12 16:24:47.386899: val_loss -0.813 
2025-07-12 16:24:47.387054: Pseudo dice [0.9649] 
2025-07-12 16:24:47.387192: Epoch time: 146.35 s 
2025-07-12 16:24:49.476700:  
2025-07-12 16:24:49.477402: Epoch 672 
2025-07-12 16:24:49.477682: Current learning rate: 0.00367 
2025-07-12 16:27:14.744009: train_loss -0.794 
2025-07-12 16:27:14.745170: val_loss -0.8147 
2025-07-12 16:27:14.745249: Pseudo dice [0.9672] 
2025-07-12 16:27:14.745379: Epoch time: 145.27 s 
2025-07-12 16:27:18.986156:  
2025-07-12 16:27:18.986520: Epoch 673 
2025-07-12 16:27:18.986652: Current learning rate: 0.00366 
2025-07-12 16:29:43.210823: train_loss -0.7886 
2025-07-12 16:29:43.211627: val_loss -0.8308 
2025-07-12 16:29:43.211693: Pseudo dice [0.9699] 
2025-07-12 16:29:43.211777: Epoch time: 144.23 s 
2025-07-12 16:29:44.715857:  
2025-07-12 16:29:44.716813: Epoch 674 
2025-07-12 16:29:44.717159: Current learning rate: 0.00365 
2025-07-12 16:32:12.803890: train_loss -0.7938 
2025-07-12 16:32:12.805077: val_loss -0.8536 
2025-07-12 16:32:12.805175: Pseudo dice [0.9644] 
2025-07-12 16:32:12.805296: Epoch time: 148.09 s 
2025-07-12 16:32:14.921464:  
2025-07-12 16:32:14.922812: Epoch 675 
2025-07-12 16:32:14.923442: Current learning rate: 0.00364 
2025-07-12 16:34:38.051548: train_loss -0.7975 
2025-07-12 16:34:38.053468: val_loss -0.7873 
2025-07-12 16:34:38.053670: Pseudo dice [0.9672] 
2025-07-12 16:34:38.053824: Epoch time: 143.13 s 
2025-07-12 16:34:39.761101:  
2025-07-12 16:34:39.761712: Epoch 676 
2025-07-12 16:34:39.761944: Current learning rate: 0.00363 
2025-07-12 16:37:03.801367: train_loss -0.7679 
2025-07-12 16:37:03.802541: val_loss -0.8234 
2025-07-12 16:37:03.802705: Pseudo dice [0.9648] 
2025-07-12 16:37:03.802853: Epoch time: 144.04 s 
2025-07-12 16:37:05.560266:  
2025-07-12 16:37:05.561256: Epoch 677 
2025-07-12 16:37:05.561555: Current learning rate: 0.00362 
2025-07-12 16:39:31.821658: train_loss -0.7841 
2025-07-12 16:39:31.823365: val_loss -0.8187 
2025-07-12 16:39:31.823457: Pseudo dice [0.9698] 
2025-07-12 16:39:31.823569: Epoch time: 146.26 s 
2025-07-12 16:39:33.592126:  
2025-07-12 16:39:33.592668: Epoch 678 
2025-07-12 16:39:33.592879: Current learning rate: 0.00361 
2025-07-12 16:41:56.053621: train_loss -0.8036 
2025-07-12 16:41:56.054862: val_loss -0.8049 
2025-07-12 16:41:56.054960: Pseudo dice [0.9667] 
2025-07-12 16:41:56.055055: Epoch time: 142.46 s 
2025-07-12 16:41:57.830586:  
2025-07-12 16:41:57.830935: Epoch 679 
2025-07-12 16:41:57.831074: Current learning rate: 0.0036 
2025-07-12 16:44:22.628796: train_loss -0.798 
2025-07-12 16:44:22.630154: val_loss -0.8041 
2025-07-12 16:44:22.630381: Pseudo dice [0.9662] 
2025-07-12 16:44:22.630503: Epoch time: 144.8 s 
2025-07-12 16:44:24.368047:  
2025-07-12 16:44:24.368811: Epoch 680 
2025-07-12 16:44:24.369047: Current learning rate: 0.00359 
2025-07-12 16:46:47.472464: train_loss -0.8092 
2025-07-12 16:46:47.474699: val_loss -0.8127 
2025-07-12 16:46:47.475007: Pseudo dice [0.9666] 
2025-07-12 16:46:47.475344: Epoch time: 143.11 s 
2025-07-12 16:46:49.269103:  
2025-07-12 16:46:49.270057: Epoch 681 
2025-07-12 16:46:49.270420: Current learning rate: 0.00358 
2025-07-12 16:49:09.099071: train_loss -0.793 
2025-07-12 16:49:09.100460: val_loss -0.8299 
2025-07-12 16:49:09.100646: Pseudo dice [0.9663] 
2025-07-12 16:49:09.100774: Epoch time: 139.83 s 
2025-07-12 16:49:11.200496:  
2025-07-12 16:49:11.201656: Epoch 682 
2025-07-12 16:49:11.202000: Current learning rate: 0.00357 
2025-07-12 16:51:39.138776: train_loss -0.7912 
2025-07-12 16:51:39.140057: val_loss -0.8012 
2025-07-12 16:51:39.153131: Pseudo dice [0.9674] 
2025-07-12 16:51:39.153619: Epoch time: 147.94 s 
2025-07-12 16:51:41.345295:  
2025-07-12 16:51:41.346411: Epoch 683 
2025-07-12 16:51:41.346769: Current learning rate: 0.00356 
2025-07-12 16:54:04.413219: train_loss -0.7909 
2025-07-12 16:54:04.414485: val_loss -0.8064 
2025-07-12 16:54:04.414594: Pseudo dice [0.9677] 
2025-07-12 16:54:04.414712: Epoch time: 143.07 s 
2025-07-12 16:54:05.969187:  
2025-07-12 16:54:05.969727: Epoch 684 
2025-07-12 16:54:05.969985: Current learning rate: 0.00355 
2025-07-12 16:56:27.512159: train_loss -0.789 
2025-07-12 16:56:27.513572: val_loss -0.8094 
2025-07-12 16:56:27.513675: Pseudo dice [0.9669] 
2025-07-12 16:56:27.513766: Epoch time: 141.54 s 
2025-07-12 16:56:29.469389:  
2025-07-12 16:56:29.470311: Epoch 685 
2025-07-12 16:56:29.470687: Current learning rate: 0.00354 
2025-07-12 16:58:53.692928: train_loss -0.8032 
2025-07-12 16:58:53.694422: val_loss -0.8126 
2025-07-12 16:58:53.694564: Pseudo dice [0.9706] 
2025-07-12 16:58:53.694718: Epoch time: 144.23 s 
2025-07-12 16:58:55.210725:  
2025-07-12 16:58:55.211299: Epoch 686 
2025-07-12 16:58:55.211483: Current learning rate: 0.00353 
2025-07-12 17:01:15.217116: train_loss -0.7994 
2025-07-12 17:01:15.219404: val_loss -0.8147 
2025-07-12 17:01:15.219865: Pseudo dice [0.9669] 
2025-07-12 17:01:15.220616: Epoch time: 140.01 s 
2025-07-12 17:01:17.229465:  
2025-07-12 17:01:17.230600: Epoch 687 
2025-07-12 17:01:17.231120: Current learning rate: 0.00352 
2025-07-12 17:03:41.183508: train_loss -0.7976 
2025-07-12 17:03:41.192065: val_loss -0.8222 
2025-07-12 17:03:41.192579: Pseudo dice [0.9672] 
2025-07-12 17:03:41.192715: Epoch time: 143.96 s 
2025-07-12 17:03:43.377462:  
2025-07-12 17:03:43.378112: Epoch 688 
2025-07-12 17:03:43.378423: Current learning rate: 0.00351 
2025-07-12 17:06:09.274525: train_loss -0.7906 
2025-07-12 17:06:09.275621: val_loss -0.8143 
2025-07-12 17:06:09.275704: Pseudo dice [0.9681] 
2025-07-12 17:06:09.275794: Epoch time: 145.9 s 
2025-07-12 17:06:10.972927:  
2025-07-12 17:06:10.973717: Epoch 689 
2025-07-12 17:06:10.974061: Current learning rate: 0.0035 
2025-07-12 17:08:34.034192: train_loss -0.8117 
2025-07-12 17:08:34.035279: val_loss -0.8134 
2025-07-12 17:08:34.035365: Pseudo dice [0.9705] 
2025-07-12 17:08:34.035487: Epoch time: 143.06 s 
2025-07-12 17:08:34.035550: Yayy! New best EMA pseudo Dice: 0.9665 
2025-07-12 17:08:37.624370:  
2025-07-12 17:08:37.624988: Epoch 690 
2025-07-12 17:08:37.625261: Current learning rate: 0.00349 
2025-07-12 17:11:00.370573: train_loss -0.7962 
2025-07-12 17:11:00.371957: val_loss -0.805 
2025-07-12 17:11:00.372187: Pseudo dice [0.9703] 
2025-07-12 17:11:00.372394: Epoch time: 142.75 s 
2025-07-12 17:11:00.372610: Yayy! New best EMA pseudo Dice: 0.9669 
2025-07-12 17:11:04.161873:  
2025-07-12 17:11:04.162494: Epoch 691 
2025-07-12 17:11:04.162850: Current learning rate: 0.00348 
2025-07-12 17:13:23.476848: train_loss -0.7983 
2025-07-12 17:13:23.478382: val_loss -0.817 
2025-07-12 17:13:23.478474: Pseudo dice [0.9708] 
2025-07-12 17:13:23.478598: Epoch time: 139.32 s 
2025-07-12 17:13:23.478661: Yayy! New best EMA pseudo Dice: 0.9672 
2025-07-12 17:13:29.968721:  
2025-07-12 17:13:29.969105: Epoch 692 
2025-07-12 17:13:29.969184: Current learning rate: 0.00346 
2025-07-12 17:15:51.359797: train_loss -0.8063 
2025-07-12 17:15:51.361193: val_loss -0.8223 
2025-07-12 17:15:51.361420: Pseudo dice [0.9716] 
2025-07-12 17:15:51.361587: Epoch time: 141.39 s 
2025-07-12 17:15:51.361676: Yayy! New best EMA pseudo Dice: 0.9677 
2025-07-12 17:15:54.755434:  
2025-07-12 17:15:54.755994: Epoch 693 
2025-07-12 17:15:54.756197: Current learning rate: 0.00345 
2025-07-12 17:18:18.258877: train_loss -0.8043 
2025-07-12 17:18:18.260407: val_loss -0.8227 
2025-07-12 17:18:18.260537: Pseudo dice [0.9657] 
2025-07-12 17:18:18.260673: Epoch time: 143.5 s 
2025-07-12 17:18:19.832726:  
2025-07-12 17:18:19.833191: Epoch 694 
2025-07-12 17:18:19.833382: Current learning rate: 0.00344 
2025-07-12 17:20:40.671272: train_loss -0.7882 
2025-07-12 17:20:40.672561: val_loss -0.8324 
2025-07-12 17:20:40.672702: Pseudo dice [0.9711] 
2025-07-12 17:20:40.672879: Epoch time: 140.84 s 
2025-07-12 17:20:40.672976: Yayy! New best EMA pseudo Dice: 0.9678 
2025-07-12 17:20:44.884165:  
2025-07-12 17:20:44.885435: Epoch 695 
2025-07-12 17:20:44.885854: Current learning rate: 0.00343 
2025-07-12 17:23:06.397362: train_loss -0.7976 
2025-07-12 17:23:06.398755: val_loss -0.8145 
2025-07-12 17:23:06.398891: Pseudo dice [0.9703] 
2025-07-12 17:23:06.399114: Epoch time: 141.52 s 
2025-07-12 17:23:06.399203: Yayy! New best EMA pseudo Dice: 0.9681 
2025-07-12 17:23:09.537960:  
2025-07-12 17:23:09.538565: Epoch 696 
2025-07-12 17:23:09.538772: Current learning rate: 0.00342 
2025-07-12 17:25:33.282977: train_loss -0.7981 
2025-07-12 17:25:33.300597: val_loss -0.8269 
2025-07-12 17:25:33.301791: Pseudo dice [0.9722] 
2025-07-12 17:25:33.302202: Epoch time: 143.75 s 
2025-07-12 17:25:33.302395: Yayy! New best EMA pseudo Dice: 0.9685 
2025-07-12 17:25:36.915189:  
2025-07-12 17:25:36.915708: Epoch 697 
2025-07-12 17:25:36.915933: Current learning rate: 0.00341 
2025-07-12 17:27:58.820643: train_loss -0.8038 
2025-07-12 17:27:58.822013: val_loss -0.8215 
2025-07-12 17:27:58.822140: Pseudo dice [0.9707] 
2025-07-12 17:27:58.822265: Epoch time: 141.91 s 
2025-07-12 17:27:58.822320: Yayy! New best EMA pseudo Dice: 0.9687 
2025-07-12 17:28:02.435185:  
2025-07-12 17:28:02.435962: Epoch 698 
2025-07-12 17:28:02.436232: Current learning rate: 0.0034 
2025-07-12 17:30:25.147249: train_loss -0.8058 
2025-07-12 17:30:25.148621: val_loss -0.8344 
2025-07-12 17:30:25.148703: Pseudo dice [0.9724] 
2025-07-12 17:30:25.148794: Epoch time: 142.71 s 
2025-07-12 17:30:25.148843: Yayy! New best EMA pseudo Dice: 0.9691 
2025-07-12 17:30:28.259567:  
2025-07-12 17:30:28.259939: Epoch 699 
2025-07-12 17:30:28.260038: Current learning rate: 0.00339 
2025-07-12 17:32:48.535400: train_loss -0.809 
2025-07-12 17:32:48.540431: val_loss -0.8367 
2025-07-12 17:32:48.540625: Pseudo dice [0.9678] 
2025-07-12 17:32:48.540771: Epoch time: 140.28 s 
2025-07-12 17:32:52.116974:  
2025-07-12 17:32:52.118110: Epoch 700 
2025-07-12 17:32:52.118455: Current learning rate: 0.00338 
2025-07-12 17:35:17.223768: train_loss -0.8042 
2025-07-12 17:35:17.224799: val_loss -0.8203 
2025-07-12 17:35:17.224881: Pseudo dice [0.9692] 
2025-07-12 17:35:17.224976: Epoch time: 145.11 s 
2025-07-12 17:35:19.248369:  
2025-07-12 17:35:19.249380: Epoch 701 
2025-07-12 17:35:19.249718: Current learning rate: 0.00337 
2025-07-12 17:37:43.828239: train_loss -0.7829 
2025-07-12 17:37:43.829163: val_loss -0.8405 
2025-07-12 17:37:43.829229: Pseudo dice [0.965] 
2025-07-12 17:37:43.829332: Epoch time: 144.58 s 
2025-07-12 17:37:45.341784:  
2025-07-12 17:37:45.342649: Epoch 702 
2025-07-12 17:37:45.342944: Current learning rate: 0.00336 
2025-07-12 17:40:13.098728: train_loss -0.8001 
2025-07-12 17:40:13.099619: val_loss -0.806 
2025-07-12 17:40:13.099685: Pseudo dice [0.9712] 
2025-07-12 17:40:13.099762: Epoch time: 147.76 s 
2025-07-12 17:40:14.425456:  
2025-07-12 17:40:14.426108: Epoch 703 
2025-07-12 17:40:14.426406: Current learning rate: 0.00335 
2025-07-12 17:42:36.844709: train_loss -0.7847 
2025-07-12 17:42:36.847481: val_loss -0.8226 
2025-07-12 17:42:36.848144: Pseudo dice [0.9687] 
2025-07-12 17:42:36.848551: Epoch time: 142.42 s 
2025-07-12 17:42:38.592582:  
2025-07-12 17:42:38.593524: Epoch 704 
2025-07-12 17:42:38.593991: Current learning rate: 0.00334 
2025-07-12 17:45:02.337007: train_loss -0.8001 
2025-07-12 17:45:02.338151: val_loss -0.8035 
2025-07-12 17:45:02.338229: Pseudo dice [0.9715] 
2025-07-12 17:45:02.338329: Epoch time: 143.75 s 
2025-07-12 17:45:02.338377: Yayy! New best EMA pseudo Dice: 0.9691 
2025-07-12 17:45:05.034913:  
2025-07-12 17:45:05.035623: Epoch 705 
2025-07-12 17:45:05.035938: Current learning rate: 0.00333 
2025-07-12 17:47:28.480078: train_loss -0.8039 
2025-07-12 17:47:28.481369: val_loss -0.8094 
2025-07-12 17:47:28.481453: Pseudo dice [0.9705] 
2025-07-12 17:47:28.481587: Epoch time: 143.45 s 
2025-07-12 17:47:28.481651: Yayy! New best EMA pseudo Dice: 0.9692 
2025-07-12 17:47:32.199039:  
2025-07-12 17:47:32.199733: Epoch 706 
2025-07-12 17:47:32.200037: Current learning rate: 0.00332 
2025-07-12 17:49:55.541963: train_loss -0.8011 
2025-07-12 17:49:55.542998: val_loss -0.8288 
2025-07-12 17:49:55.543078: Pseudo dice [0.9744] 
2025-07-12 17:49:55.543171: Epoch time: 143.34 s 
2025-07-12 17:49:55.543224: Yayy! New best EMA pseudo Dice: 0.9698 
2025-07-12 17:49:59.110484:  
2025-07-12 17:49:59.110951: Epoch 707 
2025-07-12 17:49:59.111162: Current learning rate: 0.00331 
2025-07-12 17:52:24.294855: train_loss -0.7835 
2025-07-12 17:52:24.296772: val_loss -0.8217 
2025-07-12 17:52:24.297275: Pseudo dice [0.9719] 
2025-07-12 17:52:24.297558: Epoch time: 145.19 s 
2025-07-12 17:52:24.297623: Yayy! New best EMA pseudo Dice: 0.97 
2025-07-12 17:52:28.020856:  
2025-07-12 17:52:28.021736: Epoch 708 
2025-07-12 17:52:28.022046: Current learning rate: 0.0033 
2025-07-12 17:54:53.552871: train_loss -0.7993 
2025-07-12 17:54:53.553833: val_loss -0.827 
2025-07-12 17:54:53.553918: Pseudo dice [0.9737] 
2025-07-12 17:54:53.554014: Epoch time: 145.53 s 
2025-07-12 17:54:53.554059: Yayy! New best EMA pseudo Dice: 0.9703 
2025-07-12 17:54:56.646770:  
2025-07-12 17:54:56.647067: Epoch 709 
2025-07-12 17:54:56.647178: Current learning rate: 0.00329 
2025-07-12 17:57:19.662485: train_loss -0.8079 
2025-07-12 17:57:19.663792: val_loss -0.8243 
2025-07-12 17:57:19.663884: Pseudo dice [0.9708] 
2025-07-12 17:57:19.664007: Epoch time: 143.02 s 
2025-07-12 17:57:19.664068: Yayy! New best EMA pseudo Dice: 0.9704 
2025-07-12 17:57:24.937519:  
2025-07-12 17:57:24.937924: Epoch 710 
2025-07-12 17:57:24.938018: Current learning rate: 0.00328 
2025-07-12 17:59:44.184572: train_loss -0.7875 
2025-07-12 17:59:44.189146: val_loss -0.8055 
2025-07-12 17:59:44.189770: Pseudo dice [0.9624] 
2025-07-12 17:59:44.189925: Epoch time: 139.25 s 
2025-07-12 17:59:46.225514:  
2025-07-12 17:59:46.226556: Epoch 711 
2025-07-12 17:59:46.226925: Current learning rate: 0.00327 
2025-07-12 18:02:11.992381: train_loss -0.7976 
2025-07-12 18:02:12.006031: val_loss -0.8079 
2025-07-12 18:02:12.006339: Pseudo dice [0.9704] 
2025-07-12 18:02:12.006447: Epoch time: 145.77 s 
2025-07-12 18:02:13.843422:  
2025-07-12 18:02:13.844448: Epoch 712 
2025-07-12 18:02:13.844822: Current learning rate: 0.00326 
2025-07-12 18:04:38.228868: train_loss -0.7863 
2025-07-12 18:04:38.230245: val_loss -0.8003 
2025-07-12 18:04:38.230335: Pseudo dice [0.9637] 
2025-07-12 18:04:38.230432: Epoch time: 144.39 s 
2025-07-12 18:04:40.446246:  
2025-07-12 18:04:40.447453: Epoch 713 
2025-07-12 18:04:40.447841: Current learning rate: 0.00325 
2025-07-12 18:07:08.701023: train_loss -0.7878 
2025-07-12 18:07:08.702857: val_loss -0.7983 
2025-07-12 18:07:08.703090: Pseudo dice [0.97] 
2025-07-12 18:07:08.703295: Epoch time: 148.26 s 
2025-07-12 18:07:10.469468:  
2025-07-12 18:07:10.469929: Epoch 714 
2025-07-12 18:07:10.470101: Current learning rate: 0.00324 
2025-07-12 18:09:32.525609: train_loss -0.8022 
2025-07-12 18:09:32.526895: val_loss -0.8136 
2025-07-12 18:09:32.526978: Pseudo dice [0.9696] 
2025-07-12 18:09:32.527077: Epoch time: 142.06 s 
2025-07-12 18:09:34.712085:  
2025-07-12 18:09:34.713097: Epoch 715 
2025-07-12 18:09:34.713482: Current learning rate: 0.00323 
2025-07-12 18:11:57.962999: train_loss -0.796 
2025-07-12 18:11:57.964026: val_loss -0.819 
2025-07-12 18:11:57.964112: Pseudo dice [0.9724] 
2025-07-12 18:11:57.964242: Epoch time: 143.25 s 
2025-07-12 18:11:59.815188:  
2025-07-12 18:11:59.816124: Epoch 716 
2025-07-12 18:11:59.816417: Current learning rate: 0.00322 
2025-07-12 18:14:21.168944: train_loss -0.8014 
2025-07-12 18:14:21.170325: val_loss -0.8305 
2025-07-12 18:14:21.170430: Pseudo dice [0.9713] 
2025-07-12 18:14:21.170528: Epoch time: 141.36 s 
2025-07-12 18:14:23.388083:  
2025-07-12 18:14:23.389105: Epoch 717 
2025-07-12 18:14:23.389511: Current learning rate: 0.00321 
2025-07-12 18:16:44.629494: train_loss -0.7941 
2025-07-12 18:16:44.630468: val_loss -0.8474 
2025-07-12 18:16:44.630547: Pseudo dice [0.9732] 
2025-07-12 18:16:44.630642: Epoch time: 141.24 s 
2025-07-12 18:16:46.828935:  
2025-07-12 18:16:46.830292: Epoch 718 
2025-07-12 18:16:46.830720: Current learning rate: 0.0032 
2025-07-12 18:19:11.273125: train_loss -0.7986 
2025-07-12 18:19:11.275028: val_loss -0.779 
2025-07-12 18:19:11.275494: Pseudo dice [0.9732] 
2025-07-12 18:19:11.275718: Epoch time: 144.45 s 
2025-07-12 18:19:13.213095:  
2025-07-12 18:19:13.213995: Epoch 719 
2025-07-12 18:19:13.214360: Current learning rate: 0.00319 
2025-07-12 18:21:33.540379: train_loss -0.7923 
2025-07-12 18:21:33.541517: val_loss -0.8291 
2025-07-12 18:21:33.541591: Pseudo dice [0.9732] 
2025-07-12 18:21:33.541691: Epoch time: 140.33 s 
2025-07-12 18:21:33.541743: Yayy! New best EMA pseudo Dice: 0.9707 
2025-07-12 18:21:37.289568:  
2025-07-12 18:21:37.289873: Epoch 720 
2025-07-12 18:21:37.290025: Current learning rate: 0.00318 
2025-07-12 18:24:01.194494: train_loss -0.7958 
2025-07-12 18:24:01.196006: val_loss -0.833 
2025-07-12 18:24:01.196189: Pseudo dice [0.9719] 
2025-07-12 18:24:01.196394: Epoch time: 143.91 s 
2025-07-12 18:24:01.196498: Yayy! New best EMA pseudo Dice: 0.9708 
2025-07-12 18:24:04.506717:  
2025-07-12 18:24:04.507238: Epoch 721 
2025-07-12 18:24:04.507464: Current learning rate: 0.00317 
2025-07-12 18:26:27.196761: train_loss -0.791 
2025-07-12 18:26:27.198057: val_loss -0.8004 
2025-07-12 18:26:27.198148: Pseudo dice [0.9697] 
2025-07-12 18:26:27.198285: Epoch time: 142.69 s 
2025-07-12 18:26:29.106769:  
2025-07-12 18:26:29.107455: Epoch 722 
2025-07-12 18:26:29.107765: Current learning rate: 0.00316 
2025-07-12 18:28:53.223807: train_loss -0.8041 
2025-07-12 18:28:53.224625: val_loss -0.8409 
2025-07-12 18:28:53.224703: Pseudo dice [0.9725] 
2025-07-12 18:28:53.224780: Epoch time: 144.12 s 
2025-07-12 18:28:53.224822: Yayy! New best EMA pseudo Dice: 0.9709 
2025-07-12 18:28:55.541250:  
2025-07-12 18:28:55.541667: Epoch 723 
2025-07-12 18:28:55.541781: Current learning rate: 0.00315 
2025-07-12 18:31:15.952693: train_loss -0.8084 
2025-07-12 18:31:15.954245: val_loss -0.8066 
2025-07-12 18:31:15.954349: Pseudo dice [0.9738] 
2025-07-12 18:31:15.954442: Epoch time: 140.41 s 
2025-07-12 18:31:15.954492: Yayy! New best EMA pseudo Dice: 0.9711 
2025-07-12 18:31:19.360442:  
2025-07-12 18:31:19.361077: Epoch 724 
2025-07-12 18:31:19.361564: Current learning rate: 0.00314 
2025-07-12 18:33:43.553369: train_loss -0.7955 
2025-07-12 18:33:43.554984: val_loss -0.8204 
2025-07-12 18:33:43.555287: Pseudo dice [0.9711] 
2025-07-12 18:33:43.555519: Epoch time: 144.19 s 
2025-07-12 18:33:45.154536:  
2025-07-12 18:33:45.155102: Epoch 725 
2025-07-12 18:33:45.155329: Current learning rate: 0.00313 
2025-07-12 18:36:07.523055: train_loss -0.786 
2025-07-12 18:36:07.524760: val_loss -0.773 
2025-07-12 18:36:07.524917: Pseudo dice [0.9691] 
2025-07-12 18:36:07.525091: Epoch time: 142.37 s 
2025-07-12 18:36:09.523329:  
2025-07-12 18:36:09.524128: Epoch 726 
2025-07-12 18:36:09.524503: Current learning rate: 0.00312 
2025-07-12 18:38:29.075457: train_loss -0.7894 
2025-07-12 18:38:29.077168: val_loss -0.8261 
2025-07-12 18:38:29.077632: Pseudo dice [0.9682] 
2025-07-12 18:38:29.077854: Epoch time: 139.55 s 
2025-07-12 18:38:31.391257:  
2025-07-12 18:38:31.392020: Epoch 727 
2025-07-12 18:38:31.392406: Current learning rate: 0.00311 
2025-07-12 18:40:55.642436: train_loss -0.7972 
2025-07-12 18:40:55.643693: val_loss -0.8145 
2025-07-12 18:40:55.643771: Pseudo dice [0.9679] 
2025-07-12 18:40:55.643889: Epoch time: 144.25 s 
2025-07-12 18:41:00.929555:  
2025-07-12 18:41:00.929976: Epoch 728 
2025-07-12 18:41:00.930061: Current learning rate: 0.0031 
2025-07-12 18:43:23.890340: train_loss -0.7945 
2025-07-12 18:43:23.891447: val_loss -0.8418 
2025-07-12 18:43:23.891520: Pseudo dice [0.9713] 
2025-07-12 18:43:23.891617: Epoch time: 142.96 s 
2025-07-12 18:43:25.726163:  
2025-07-12 18:43:25.727136: Epoch 729 
2025-07-12 18:43:25.727598: Current learning rate: 0.00309 
2025-07-12 18:45:51.191966: train_loss -0.8047 
2025-07-12 18:45:51.192893: val_loss -0.8319 
2025-07-12 18:45:51.192979: Pseudo dice [0.9752] 
2025-07-12 18:45:51.193070: Epoch time: 145.47 s 
2025-07-12 18:45:52.768569:  
2025-07-12 18:45:52.769657: Epoch 730 
2025-07-12 18:45:52.769928: Current learning rate: 0.00308 
2025-07-12 18:48:14.477006: train_loss -0.7928 
2025-07-12 18:48:14.478167: val_loss -0.7909 
2025-07-12 18:48:14.478263: Pseudo dice [0.9673] 
2025-07-12 18:48:14.478365: Epoch time: 141.71 s 
2025-07-12 18:48:16.263977:  
2025-07-12 18:48:16.264912: Epoch 731 
2025-07-12 18:48:16.265245: Current learning rate: 0.00307 
2025-07-12 18:50:36.925996: train_loss -0.8029 
2025-07-12 18:50:36.927466: val_loss -0.8092 
2025-07-12 18:50:36.927798: Pseudo dice [0.973] 
2025-07-12 18:50:36.928071: Epoch time: 140.66 s 
2025-07-12 18:50:39.088177:  
2025-07-12 18:50:39.089297: Epoch 732 
2025-07-12 18:50:39.089653: Current learning rate: 0.00306 
2025-07-12 18:53:05.922553: train_loss -0.7888 
2025-07-12 18:53:05.923787: val_loss -0.815 
2025-07-12 18:53:05.923866: Pseudo dice [0.9743] 
2025-07-12 18:53:05.923958: Epoch time: 146.84 s 
2025-07-12 18:53:05.924006: Yayy! New best EMA pseudo Dice: 0.9712 
2025-07-12 18:53:08.706591:  
2025-07-12 18:53:08.707070: Epoch 733 
2025-07-12 18:53:08.707172: Current learning rate: 0.00305 
2025-07-12 18:55:28.220320: train_loss -0.7945 
2025-07-12 18:55:28.221751: val_loss -0.8312 
2025-07-12 18:55:28.221919: Pseudo dice [0.9683] 
2025-07-12 18:55:28.222095: Epoch time: 139.51 s 
2025-07-12 18:55:30.447454:  
2025-07-12 18:55:30.448579: Epoch 734 
2025-07-12 18:55:30.448988: Current learning rate: 0.00304 
2025-07-12 18:57:57.797991: train_loss -0.8043 
2025-07-12 18:57:57.799381: val_loss -0.7885 
2025-07-12 18:57:57.799559: Pseudo dice [0.972] 
2025-07-12 18:57:57.799698: Epoch time: 147.35 s 
2025-07-12 18:57:59.462904:  
2025-07-12 18:57:59.463951: Epoch 735 
2025-07-12 18:57:59.464324: Current learning rate: 0.00303 
2025-07-12 19:00:21.099460: train_loss -0.7937 
2025-07-12 19:00:21.100729: val_loss -0.8086 
2025-07-12 19:00:21.100811: Pseudo dice [0.9734] 
2025-07-12 19:00:21.100908: Epoch time: 141.64 s 
2025-07-12 19:00:21.100956: Yayy! New best EMA pseudo Dice: 0.9712 
2025-07-12 19:00:25.192143:  
2025-07-12 19:00:25.193081: Epoch 736 
2025-07-12 19:00:25.193560: Current learning rate: 0.00302 
2025-07-12 19:02:51.395915: train_loss -0.8059 
2025-07-12 19:02:51.397277: val_loss -0.8141 
2025-07-12 19:02:51.397378: Pseudo dice [0.9726] 
2025-07-12 19:02:51.397477: Epoch time: 146.21 s 
2025-07-12 19:02:51.397528: Yayy! New best EMA pseudo Dice: 0.9714 
2025-07-12 19:02:54.798301:  
2025-07-12 19:02:54.798767: Epoch 737 
2025-07-12 19:02:54.798937: Current learning rate: 0.00301 
2025-07-12 19:05:15.374771: train_loss -0.7981 
2025-07-12 19:05:15.376144: val_loss -0.7937 
2025-07-12 19:05:15.376239: Pseudo dice [0.9732] 
2025-07-12 19:05:15.376376: Epoch time: 140.58 s 
2025-07-12 19:05:15.376433: Yayy! New best EMA pseudo Dice: 0.9716 
2025-07-12 19:05:19.049300:  
2025-07-12 19:05:19.050061: Epoch 738 
2025-07-12 19:05:19.050291: Current learning rate: 0.003 
2025-07-12 19:07:40.357885: train_loss -0.7944 
2025-07-12 19:07:40.360456: val_loss -0.8257 
2025-07-12 19:07:40.362365: Pseudo dice [0.9727] 
2025-07-12 19:07:40.362595: Epoch time: 141.31 s 
2025-07-12 19:07:40.362707: Yayy! New best EMA pseudo Dice: 0.9717 
2025-07-12 19:07:43.658304:  
2025-07-12 19:07:43.659007: Epoch 739 
2025-07-12 19:07:43.659297: Current learning rate: 0.00299 
2025-07-12 19:10:06.293083: train_loss -0.7994 
2025-07-12 19:10:06.294425: val_loss -0.8393 
2025-07-12 19:10:06.294512: Pseudo dice [0.9746] 
2025-07-12 19:10:06.294621: Epoch time: 142.64 s 
2025-07-12 19:10:06.294669: Yayy! New best EMA pseudo Dice: 0.972 
2025-07-12 19:10:10.013808:  
2025-07-12 19:10:10.014654: Epoch 740 
2025-07-12 19:10:10.015070: Current learning rate: 0.00297 
2025-07-12 19:12:32.358368: train_loss -0.8013 
2025-07-12 19:12:32.359596: val_loss -0.8327 
2025-07-12 19:12:32.359681: Pseudo dice [0.9711] 
2025-07-12 19:12:32.359781: Epoch time: 142.35 s 
2025-07-12 19:12:34.658310:  
2025-07-12 19:12:34.659021: Epoch 741 
2025-07-12 19:12:34.659346: Current learning rate: 0.00296 
2025-07-12 19:14:57.864851: train_loss -0.791 
2025-07-12 19:14:57.865991: val_loss -0.7976 
2025-07-12 19:14:57.866070: Pseudo dice [0.9519] 
2025-07-12 19:14:57.866167: Epoch time: 143.21 s 
2025-07-12 19:14:59.636879:  
2025-07-12 19:14:59.637606: Epoch 742 
2025-07-12 19:14:59.637933: Current learning rate: 0.00295 
2025-07-12 19:17:21.209646: train_loss -0.7979 
2025-07-12 19:17:21.211992: val_loss -0.8196 
2025-07-12 19:17:21.212598: Pseudo dice [0.9628] 
2025-07-12 19:17:21.212902: Epoch time: 141.57 s 
2025-07-12 19:17:22.847561:  
2025-07-12 19:17:22.848206: Epoch 743 
2025-07-12 19:17:22.848448: Current learning rate: 0.00294 
2025-07-12 19:19:46.088819: train_loss -0.8007 
2025-07-12 19:19:46.090091: val_loss -0.7765 
2025-07-12 19:19:46.090258: Pseudo dice [0.9666] 
2025-07-12 19:19:46.090401: Epoch time: 143.24 s 
2025-07-12 19:19:47.755367:  
2025-07-12 19:19:47.756191: Epoch 744 
2025-07-12 19:19:47.756496: Current learning rate: 0.00293 
2025-07-12 19:22:10.754094: train_loss -0.7914 
2025-07-12 19:22:10.755063: val_loss -0.8162 
2025-07-12 19:22:10.755148: Pseudo dice [0.9656] 
2025-07-12 19:22:10.755249: Epoch time: 143.0 s 
2025-07-12 19:22:12.565516:  
2025-07-12 19:22:12.565906: Epoch 745 
2025-07-12 19:22:12.566085: Current learning rate: 0.00292 
2025-07-12 19:24:35.210063: train_loss -0.7909 
2025-07-12 19:24:35.212941: val_loss -0.8123 
2025-07-12 19:24:35.213119: Pseudo dice [0.9662] 
2025-07-12 19:24:35.213249: Epoch time: 142.65 s 
2025-07-12 19:24:37.262402:  
2025-07-12 19:24:37.263503: Epoch 746 
2025-07-12 19:24:37.263897: Current learning rate: 0.00291 
2025-07-12 19:27:04.609965: train_loss -0.8095 
2025-07-12 19:27:04.611248: val_loss -0.8453 
2025-07-12 19:27:04.611362: Pseudo dice [0.9708] 
2025-07-12 19:27:04.611461: Epoch time: 147.35 s 
2025-07-12 19:27:09.408663:  
2025-07-12 19:27:09.409032: Epoch 747 
2025-07-12 19:27:09.409222: Current learning rate: 0.0029 
2025-07-12 19:29:31.947679: train_loss -0.7907 
2025-07-12 19:29:31.948722: val_loss -0.8297 
2025-07-12 19:29:31.948796: Pseudo dice [0.9649] 
2025-07-12 19:29:31.948878: Epoch time: 142.54 s 
2025-07-12 19:29:33.663593:  
2025-07-12 19:29:33.665237: Epoch 748 
2025-07-12 19:29:33.665661: Current learning rate: 0.00289 
2025-07-12 19:31:58.701944: train_loss -0.8042 
2025-07-12 19:31:58.702828: val_loss -0.827 
2025-07-12 19:31:58.702904: Pseudo dice [0.9621] 
2025-07-12 19:31:58.702988: Epoch time: 145.04 s 
2025-07-12 19:32:00.281046:  
2025-07-12 19:32:00.281596: Epoch 749 
2025-07-12 19:32:00.281838: Current learning rate: 0.00288 
2025-07-12 19:34:22.324100: train_loss -0.7933 
2025-07-12 19:34:22.325409: val_loss -0.8349 
2025-07-12 19:34:22.325486: Pseudo dice [0.9624] 
2025-07-12 19:34:22.325573: Epoch time: 142.04 s 
2025-07-12 19:34:25.170191:  
2025-07-12 19:34:25.170760: Epoch 750 
2025-07-12 19:34:25.170925: Current learning rate: 0.00287 
2025-07-12 19:36:43.768893: train_loss -0.8024 
2025-07-12 19:36:43.770641: val_loss -0.8221 
2025-07-12 19:36:43.770872: Pseudo dice [0.9715] 
2025-07-12 19:36:43.771067: Epoch time: 138.6 s 
2025-07-12 19:36:46.319913:  
2025-07-12 19:36:46.321054: Epoch 751 
2025-07-12 19:36:46.321409: Current learning rate: 0.00286 
2025-07-12 19:39:09.720582: train_loss -0.7891 
2025-07-12 19:39:09.721836: val_loss -0.7859 
2025-07-12 19:39:09.721926: Pseudo dice [0.9587] 
2025-07-12 19:39:09.722039: Epoch time: 143.4 s 
2025-07-12 19:39:11.873635:  
2025-07-12 19:39:11.874870: Epoch 752 
2025-07-12 19:39:11.875280: Current learning rate: 0.00285 
2025-07-12 19:41:39.948846: train_loss -0.7936 
2025-07-12 19:41:39.950028: val_loss -0.7972 
2025-07-12 19:41:39.950115: Pseudo dice [0.9616] 
2025-07-12 19:41:39.950220: Epoch time: 148.08 s 
2025-07-12 19:41:41.668621:  
2025-07-12 19:41:41.669195: Epoch 753 
2025-07-12 19:41:41.669424: Current learning rate: 0.00284 
2025-07-12 19:44:04.311644: train_loss -0.792 
2025-07-12 19:44:04.313599: val_loss -0.7915 
2025-07-12 19:44:04.313839: Pseudo dice [0.959] 
2025-07-12 19:44:04.314016: Epoch time: 142.64 s 
2025-07-12 19:44:06.126171:  
2025-07-12 19:44:06.127040: Epoch 754 
2025-07-12 19:44:06.127410: Current learning rate: 0.00283 
2025-07-12 19:46:30.068415: train_loss -0.7888 
2025-07-12 19:46:30.069478: val_loss -0.8235 
2025-07-12 19:46:30.069548: Pseudo dice [0.9678] 
2025-07-12 19:46:30.069651: Epoch time: 143.94 s 
2025-07-12 19:46:32.076144:  
2025-07-12 19:46:32.077065: Epoch 755 
2025-07-12 19:46:32.077434: Current learning rate: 0.00282 
2025-07-12 19:48:57.178942: train_loss -0.802 
2025-07-12 19:48:57.180939: val_loss -0.8387 
2025-07-12 19:48:57.181316: Pseudo dice [0.967] 
2025-07-12 19:48:57.181573: Epoch time: 145.1 s 
2025-07-12 19:48:59.067037:  
2025-07-12 19:48:59.067983: Epoch 756 
2025-07-12 19:48:59.068310: Current learning rate: 0.00281 
2025-07-12 19:51:23.681216: train_loss -0.7877 
2025-07-12 19:51:23.683387: val_loss -0.8337 
2025-07-12 19:51:23.683534: Pseudo dice [0.97] 
2025-07-12 19:51:23.683749: Epoch time: 144.62 s 
2025-07-12 19:51:26.060461:  
2025-07-12 19:51:26.061596: Epoch 757 
2025-07-12 19:51:26.062036: Current learning rate: 0.0028 
2025-07-12 19:53:50.084039: train_loss -0.8006 
2025-07-12 19:53:50.085925: val_loss -0.8102 
2025-07-12 19:53:50.086131: Pseudo dice [0.971] 
2025-07-12 19:53:50.086345: Epoch time: 144.03 s 
2025-07-12 19:53:52.198008:  
2025-07-12 19:53:52.199157: Epoch 758 
2025-07-12 19:53:52.199680: Current learning rate: 0.00279 
2025-07-12 19:56:17.264631: train_loss -0.8047 
2025-07-12 19:56:17.265737: val_loss -0.7733 
2025-07-12 19:56:17.265810: Pseudo dice [0.9441] 
2025-07-12 19:56:17.265907: Epoch time: 145.07 s 
2025-07-12 19:56:19.220091:  
2025-07-12 19:56:19.221200: Epoch 759 
2025-07-12 19:56:19.221597: Current learning rate: 0.00278 
2025-07-12 19:58:41.664070: train_loss -0.7804 
2025-07-12 19:58:41.666213: val_loss -0.7911 
2025-07-12 19:58:41.666440: Pseudo dice [0.9589] 
2025-07-12 19:58:41.666548: Epoch time: 142.45 s 
2025-07-12 19:58:43.350809:  
2025-07-12 19:58:43.351704: Epoch 760 
2025-07-12 19:58:43.352100: Current learning rate: 0.00277 
2025-07-12 20:01:02.423199: train_loss -0.7905 
2025-07-12 20:01:02.424949: val_loss -0.8031 
2025-07-12 20:01:02.425167: Pseudo dice [0.9622] 
2025-07-12 20:01:02.425341: Epoch time: 139.07 s 
2025-07-12 20:01:04.313669:  
2025-07-12 20:01:04.314378: Epoch 761 
2025-07-12 20:01:04.314709: Current learning rate: 0.00276 
2025-07-12 20:03:30.254214: train_loss -0.7812 
2025-07-12 20:03:30.255734: val_loss -0.8162 
2025-07-12 20:03:30.255931: Pseudo dice [0.9663] 
2025-07-12 20:03:30.256091: Epoch time: 145.94 s 
2025-07-12 20:03:32.301516:  
2025-07-12 20:03:32.302217: Epoch 762 
2025-07-12 20:03:32.302516: Current learning rate: 0.00275 
2025-07-12 20:05:51.737763: train_loss -0.7722 
2025-07-12 20:05:51.740309: val_loss -0.8077 
2025-07-12 20:05:51.740850: Pseudo dice [0.9639] 
2025-07-12 20:05:51.741222: Epoch time: 139.44 s 
2025-07-12 20:05:53.704135:  
2025-07-12 20:05:53.705114: Epoch 763 
2025-07-12 20:05:53.705531: Current learning rate: 0.00274 
2025-07-12 20:08:16.526785: train_loss -0.7909 
2025-07-12 20:08:16.527934: val_loss -0.8095 
2025-07-12 20:08:16.528051: Pseudo dice [0.9621] 
2025-07-12 20:08:16.528240: Epoch time: 142.82 s 
2025-07-12 20:08:18.652593:  
2025-07-12 20:08:18.653495: Epoch 764 
2025-07-12 20:08:18.653871: Current learning rate: 0.00273 
2025-07-12 20:10:44.799576: train_loss -0.7934 
2025-07-12 20:10:44.804461: val_loss -0.7916 
2025-07-12 20:10:44.805159: Pseudo dice [0.9574] 
2025-07-12 20:10:44.805329: Epoch time: 146.15 s 
2025-07-12 20:10:46.482430:  
2025-07-12 20:10:46.482895: Epoch 765 
2025-07-12 20:10:46.483123: Current learning rate: 0.00272 
2025-07-12 20:13:09.844400: train_loss -0.7859 
2025-07-12 20:13:09.846830: val_loss -0.8392 
2025-07-12 20:13:09.847385: Pseudo dice [0.9588] 
2025-07-12 20:13:09.847746: Epoch time: 143.36 s 
2025-07-12 20:13:12.024745:  
2025-07-12 20:13:12.025866: Epoch 766 
2025-07-12 20:13:12.026246: Current learning rate: 0.00271 
2025-07-12 20:15:38.828428: train_loss -0.7957 
2025-07-12 20:15:38.829799: val_loss -0.7846 
2025-07-12 20:15:38.829968: Pseudo dice [0.9682] 
2025-07-12 20:15:38.830134: Epoch time: 146.81 s 
2025-07-12 20:15:41.039651:  
2025-07-12 20:15:41.040433: Epoch 767 
2025-07-12 20:15:41.040928: Current learning rate: 0.0027 
2025-07-12 20:18:07.330518: train_loss -0.8071 
2025-07-12 20:18:07.331635: val_loss -0.8276 
2025-07-12 20:18:07.331712: Pseudo dice [0.9713] 
2025-07-12 20:18:07.331802: Epoch time: 146.29 s 
2025-07-12 20:18:09.514154:  
2025-07-12 20:18:09.514901: Epoch 768 
2025-07-12 20:18:09.515176: Current learning rate: 0.00268 
2025-07-12 20:20:33.096117: train_loss -0.8038 
2025-07-12 20:20:33.098864: val_loss -0.8539 
2025-07-12 20:20:33.098953: Pseudo dice [0.9724] 
2025-07-12 20:20:33.099066: Epoch time: 143.58 s 
2025-07-12 20:20:35.317006:  
2025-07-12 20:20:35.318032: Epoch 769 
2025-07-12 20:20:35.318373: Current learning rate: 0.00267 
2025-07-12 20:23:01.471480: train_loss -0.8066 
2025-07-12 20:23:01.472492: val_loss -0.8304 
2025-07-12 20:23:01.472579: Pseudo dice [0.9702] 
2025-07-12 20:23:01.472677: Epoch time: 146.16 s 
2025-07-12 20:23:03.252892:  
2025-07-12 20:23:03.253922: Epoch 770 
2025-07-12 20:23:03.254303: Current learning rate: 0.00266 
2025-07-12 20:25:27.056359: train_loss -0.8086 
2025-07-12 20:25:27.057754: val_loss -0.8165 
2025-07-12 20:25:27.057890: Pseudo dice [0.9708] 
2025-07-12 20:25:27.058029: Epoch time: 143.81 s 
2025-07-12 20:25:28.922541:  
2025-07-12 20:25:28.923321: Epoch 771 
2025-07-12 20:25:28.923611: Current learning rate: 0.00265 
2025-07-12 20:27:52.078267: train_loss -0.7995 
2025-07-12 20:27:52.079328: val_loss -0.7997 
2025-07-12 20:27:52.079405: Pseudo dice [0.9642] 
2025-07-12 20:27:52.079513: Epoch time: 143.16 s 
2025-07-12 20:27:54.242628:  
2025-07-12 20:27:54.243779: Epoch 772 
2025-07-12 20:27:54.244182: Current learning rate: 0.00264 
2025-07-12 20:30:20.536975: train_loss -0.8089 
2025-07-12 20:30:20.538060: val_loss -0.8086 
2025-07-12 20:30:20.538162: Pseudo dice [0.9724] 
2025-07-12 20:30:20.538260: Epoch time: 146.3 s 
2025-07-12 20:30:22.036737:  
2025-07-12 20:30:22.037172: Epoch 773 
2025-07-12 20:30:22.037371: Current learning rate: 0.00263 
2025-07-12 20:32:46.455228: train_loss -0.8073 
2025-07-12 20:32:46.456324: val_loss -0.8434 
2025-07-12 20:32:46.456384: Pseudo dice [0.9736] 
2025-07-12 20:32:46.456453: Epoch time: 144.42 s 
2025-07-12 20:32:47.922034:  
2025-07-12 20:32:47.922650: Epoch 774 
2025-07-12 20:32:47.922894: Current learning rate: 0.00262 
2025-07-12 20:35:11.588930: train_loss -0.8013 
2025-07-12 20:35:11.594028: val_loss -0.812 
2025-07-12 20:35:11.594333: Pseudo dice [0.9709] 
2025-07-12 20:35:11.594627: Epoch time: 143.67 s 
2025-07-12 20:35:13.792036:  
2025-07-12 20:35:13.793191: Epoch 775 
2025-07-12 20:35:13.793567: Current learning rate: 0.00261 
2025-07-12 20:37:37.139294: train_loss -0.8105 
2025-07-12 20:37:37.140863: val_loss -0.8194 
2025-07-12 20:37:37.141217: Pseudo dice [0.9734] 
2025-07-12 20:37:37.141404: Epoch time: 143.35 s 
2025-07-12 20:37:39.024368:  
2025-07-12 20:37:39.025753: Epoch 776 
2025-07-12 20:37:39.026175: Current learning rate: 0.0026 
2025-07-12 20:40:00.623338: train_loss -0.7926 
2025-07-12 20:40:00.624689: val_loss -0.8156 
2025-07-12 20:40:00.624762: Pseudo dice [0.973] 
2025-07-12 20:40:00.624846: Epoch time: 141.6 s 
2025-07-12 20:40:02.603369:  
2025-07-12 20:40:02.604334: Epoch 777 
2025-07-12 20:40:02.604644: Current learning rate: 0.00259 
2025-07-12 20:42:24.914865: train_loss -0.8009 
2025-07-12 20:42:24.916695: val_loss -0.8152 
2025-07-12 20:42:24.916811: Pseudo dice [0.9671] 
2025-07-12 20:42:24.916895: Epoch time: 142.31 s 
2025-07-12 20:42:26.878341:  
2025-07-12 20:42:26.879438: Epoch 778 
2025-07-12 20:42:26.879884: Current learning rate: 0.00258 
2025-07-12 20:44:51.816429: train_loss -0.8043 
2025-07-12 20:44:51.817638: val_loss -0.8017 
2025-07-12 20:44:51.817719: Pseudo dice [0.9749] 
2025-07-12 20:44:51.817828: Epoch time: 144.94 s 
2025-07-12 20:44:53.771870:  
2025-07-12 20:44:53.772627: Epoch 779 
2025-07-12 20:44:53.772951: Current learning rate: 0.00257 
2025-07-12 20:47:19.031965: train_loss -0.8103 
2025-07-12 20:47:19.033994: val_loss -0.8068 
2025-07-12 20:47:19.034287: Pseudo dice [0.9737] 
2025-07-12 20:47:19.034560: Epoch time: 145.26 s 
2025-07-12 20:47:21.466617:  
2025-07-12 20:47:21.467808: Epoch 780 
2025-07-12 20:47:21.468274: Current learning rate: 0.00256 
2025-07-12 20:49:46.563957: train_loss -0.7991 
2025-07-12 20:49:46.566322: val_loss -0.8176 
2025-07-12 20:49:46.566521: Pseudo dice [0.9732] 
2025-07-12 20:49:46.566690: Epoch time: 145.1 s 
2025-07-12 20:49:48.531321:  
2025-07-12 20:49:48.532326: Epoch 781 
2025-07-12 20:49:48.532728: Current learning rate: 0.00255 
2025-07-12 20:52:11.199959: train_loss -0.7925 
2025-07-12 20:52:11.201050: val_loss -0.8004 
2025-07-12 20:52:11.201135: Pseudo dice [0.9737] 
2025-07-12 20:52:11.201233: Epoch time: 142.67 s 
2025-07-12 20:52:12.842744:  
2025-07-12 20:52:12.843173: Epoch 782 
2025-07-12 20:52:12.843347: Current learning rate: 0.00254 
2025-07-12 20:54:37.285737: train_loss -0.7871 
2025-07-12 20:54:37.286460: val_loss -0.8437 
2025-07-12 20:54:37.286544: Pseudo dice [0.9735] 
2025-07-12 20:54:37.286629: Epoch time: 144.44 s 
2025-07-12 20:54:39.366779:  
2025-07-12 20:54:39.367759: Epoch 783 
2025-07-12 20:54:39.368209: Current learning rate: 0.00253 
2025-07-12 20:57:05.992922: train_loss -0.7939 
2025-07-12 20:57:05.994117: val_loss -0.8226 
2025-07-12 20:57:05.994210: Pseudo dice [0.97] 
2025-07-12 20:57:05.994303: Epoch time: 146.63 s 
2025-07-12 20:57:09.607262:  
2025-07-12 20:57:09.607661: Epoch 784 
2025-07-12 20:57:09.607771: Current learning rate: 0.00252 
2025-07-12 20:59:29.815157: train_loss -0.7962 
2025-07-12 20:59:29.817292: val_loss -0.8014 
2025-07-12 20:59:29.817693: Pseudo dice [0.9739] 
2025-07-12 20:59:29.817913: Epoch time: 140.21 s 
2025-07-12 20:59:32.127293:  
2025-07-12 20:59:32.128432: Epoch 785 
2025-07-12 20:59:32.129010: Current learning rate: 0.00251 
2025-07-12 21:01:56.062402: train_loss -0.8152 
2025-07-12 21:01:56.063982: val_loss -0.7998 
2025-07-12 21:01:56.064105: Pseudo dice [0.9732] 
2025-07-12 21:01:56.064257: Epoch time: 143.94 s 
2025-07-12 21:01:57.773408:  
2025-07-12 21:01:57.774505: Epoch 786 
2025-07-12 21:01:57.774888: Current learning rate: 0.0025 
2025-07-12 21:04:24.823442: train_loss -0.8043 
2025-07-12 21:04:24.825454: val_loss -0.833 
2025-07-12 21:04:24.825804: Pseudo dice [0.9739] 
2025-07-12 21:04:24.826030: Epoch time: 147.05 s 
2025-07-12 21:04:26.369067:  
2025-07-12 21:04:26.369412: Epoch 787 
2025-07-12 21:04:26.369579: Current learning rate: 0.00249 
2025-07-12 21:06:49.823817: train_loss -0.8043 
2025-07-12 21:06:49.825010: val_loss -0.8239 
2025-07-12 21:06:49.825120: Pseudo dice [0.9716] 
2025-07-12 21:06:49.825243: Epoch time: 143.46 s 
2025-07-12 21:06:51.509351:  
2025-07-12 21:06:51.510067: Epoch 788 
2025-07-12 21:06:51.510367: Current learning rate: 0.00248 
2025-07-12 21:09:13.137650: train_loss -0.7903 
2025-07-12 21:09:13.138912: val_loss -0.7956 
2025-07-12 21:09:13.139026: Pseudo dice [0.9729] 
2025-07-12 21:09:13.139127: Epoch time: 141.63 s 
2025-07-12 21:09:15.259880:  
2025-07-12 21:09:15.260834: Epoch 789 
2025-07-12 21:09:15.261184: Current learning rate: 0.00247 
2025-07-12 21:11:40.506381: train_loss -0.8031 
2025-07-12 21:11:40.507358: val_loss -0.8318 
2025-07-12 21:11:40.507434: Pseudo dice [0.9758] 
2025-07-12 21:11:40.507511: Epoch time: 145.25 s 
2025-07-12 21:11:40.507557: Yayy! New best EMA pseudo Dice: 0.972 
2025-07-12 21:11:43.442827:  
2025-07-12 21:11:43.443295: Epoch 790 
2025-07-12 21:11:43.443505: Current learning rate: 0.00245 
2025-07-12 21:14:08.264742: train_loss -0.7823 
2025-07-12 21:14:08.265801: val_loss -0.8154 
2025-07-12 21:14:08.265882: Pseudo dice [0.9643] 
2025-07-12 21:14:08.265956: Epoch time: 144.82 s 
2025-07-12 21:14:09.814666:  
2025-07-12 21:14:09.815084: Epoch 791 
2025-07-12 21:14:09.815282: Current learning rate: 0.00244 
2025-07-12 21:16:33.094508: train_loss -0.7964 
2025-07-12 21:16:33.095404: val_loss -0.7886 
2025-07-12 21:16:33.095479: Pseudo dice [0.9735] 
2025-07-12 21:16:33.095574: Epoch time: 143.28 s 
2025-07-12 21:16:35.111392:  
2025-07-12 21:16:35.112593: Epoch 792 
2025-07-12 21:16:35.112984: Current learning rate: 0.00243 
2025-07-12 21:18:59.415588: train_loss -0.7892 
2025-07-12 21:18:59.416737: val_loss -0.8298 
2025-07-12 21:18:59.416800: Pseudo dice [0.9747] 
2025-07-12 21:18:59.416896: Epoch time: 144.31 s 
2025-07-12 21:19:01.050943:  
2025-07-12 21:19:01.051621: Epoch 793 
2025-07-12 21:19:01.051873: Current learning rate: 0.00242 
2025-07-12 21:21:23.280536: train_loss -0.7998 
2025-07-12 21:21:23.281429: val_loss -0.8239 
2025-07-12 21:21:23.281511: Pseudo dice [0.9745] 
2025-07-12 21:21:23.281615: Epoch time: 142.23 s 
2025-07-12 21:21:23.281677: Yayy! New best EMA pseudo Dice: 0.9721 
2025-07-12 21:21:25.437960:  
2025-07-12 21:21:25.438363: Epoch 794 
2025-07-12 21:21:25.438514: Current learning rate: 0.00241 
2025-07-12 21:23:46.707130: train_loss -0.7965 
2025-07-12 21:23:46.708197: val_loss -0.8192 
2025-07-12 21:23:46.708293: Pseudo dice [0.9651] 
2025-07-12 21:23:46.708407: Epoch time: 141.27 s 
2025-07-12 21:23:48.519590:  
2025-07-12 21:23:48.520441: Epoch 795 
2025-07-12 21:23:48.520828: Current learning rate: 0.0024 
2025-07-12 21:26:10.830789: train_loss -0.7911 
2025-07-12 21:26:10.831775: val_loss -0.8086 
2025-07-12 21:26:10.831854: Pseudo dice [0.9712] 
2025-07-12 21:26:10.832195: Epoch time: 142.31 s 
2025-07-12 21:26:12.943249:  
2025-07-12 21:26:12.944133: Epoch 796 
2025-07-12 21:26:12.944535: Current learning rate: 0.00239 
2025-07-12 21:28:40.341061: train_loss -0.8053 
2025-07-12 21:28:40.342035: val_loss -0.8137 
2025-07-12 21:28:40.342108: Pseudo dice [0.9747] 
2025-07-12 21:28:40.342208: Epoch time: 147.4 s 
2025-07-12 21:28:41.881241:  
2025-07-12 21:28:41.881776: Epoch 797 
2025-07-12 21:28:41.881961: Current learning rate: 0.00238 
2025-07-12 21:31:00.281380: train_loss -0.7953 
2025-07-12 21:31:00.282679: val_loss -0.7897 
2025-07-12 21:31:00.282764: Pseudo dice [0.9734] 
2025-07-12 21:31:00.282876: Epoch time: 138.4 s 
2025-07-12 21:31:02.353291:  
2025-07-12 21:31:02.354223: Epoch 798 
2025-07-12 21:31:02.354639: Current learning rate: 0.00237 
2025-07-12 21:33:25.007842: train_loss -0.7958 
2025-07-12 21:33:25.009116: val_loss -0.821 
2025-07-12 21:33:25.009206: Pseudo dice [0.9754] 
2025-07-12 21:33:25.009322: Epoch time: 142.66 s 
2025-07-12 21:33:25.009396: Yayy! New best EMA pseudo Dice: 0.9722 
2025-07-12 21:33:28.802538:  
2025-07-12 21:33:28.803331: Epoch 799 
2025-07-12 21:33:28.803616: Current learning rate: 0.00236 
2025-07-12 21:35:54.491613: train_loss -0.8086 
2025-07-12 21:35:54.493568: val_loss -0.8092 
2025-07-12 21:35:54.493879: Pseudo dice [0.9758] 
2025-07-12 21:35:54.493968: Epoch time: 145.69 s 
2025-07-12 21:35:56.203184: Yayy! New best EMA pseudo Dice: 0.9726 
2025-07-12 21:35:58.535705:  
2025-07-12 21:35:58.536104: Epoch 800 
2025-07-12 21:35:58.536216: Current learning rate: 0.00235 
2025-07-12 21:38:22.355463: train_loss -0.7967 
2025-07-12 21:38:22.356499: val_loss -0.7899 
2025-07-12 21:38:22.356586: Pseudo dice [0.97] 
2025-07-12 21:38:22.356697: Epoch time: 143.82 s 
2025-07-12 21:38:24.024307:  
2025-07-12 21:38:24.024919: Epoch 801 
2025-07-12 21:38:24.025279: Current learning rate: 0.00234 
2025-07-12 21:40:48.980124: train_loss -0.7977 
2025-07-12 21:40:48.981927: val_loss -0.8289 
2025-07-12 21:40:48.982278: Pseudo dice [0.9731] 
2025-07-12 21:40:48.982510: Epoch time: 144.96 s 
2025-07-12 21:40:54.785233:  
2025-07-12 21:40:54.785640: Epoch 802 
2025-07-12 21:40:54.785741: Current learning rate: 0.00233 
2025-07-12 21:43:16.091101: train_loss -0.7993 
2025-07-12 21:43:16.092374: val_loss -0.8436 
2025-07-12 21:43:16.092476: Pseudo dice [0.9733] 
2025-07-12 21:43:16.092558: Epoch time: 141.31 s 
2025-07-12 21:43:17.937240:  
2025-07-12 21:43:17.938145: Epoch 803 
2025-07-12 21:43:17.938549: Current learning rate: 0.00232 
2025-07-12 21:45:32.977288: train_loss -0.7934 
2025-07-12 21:45:32.979708: val_loss -0.806 
2025-07-12 21:45:32.980489: Pseudo dice [0.9735] 
2025-07-12 21:45:32.980875: Epoch time: 135.04 s 
2025-07-12 21:45:32.981061: Yayy! New best EMA pseudo Dice: 0.9726 
2025-07-12 21:45:36.766658:  
2025-07-12 21:45:36.767585: Epoch 804 
2025-07-12 21:45:36.767942: Current learning rate: 0.00231 
2025-07-12 21:47:57.427897: train_loss -0.8089 
2025-07-12 21:47:57.428884: val_loss -0.8176 
2025-07-12 21:47:57.428967: Pseudo dice [0.9745] 
2025-07-12 21:47:57.429066: Epoch time: 140.66 s 
2025-07-12 21:47:57.429117: Yayy! New best EMA pseudo Dice: 0.9728 
2025-07-12 21:48:00.079131:  
2025-07-12 21:48:00.079664: Epoch 805 
2025-07-12 21:48:00.079786: Current learning rate: 0.0023 
2025-07-12 21:50:22.552128: train_loss -0.808 
2025-07-12 21:50:22.552915: val_loss -0.8291 
2025-07-12 21:50:22.552979: Pseudo dice [0.9739] 
2025-07-12 21:50:22.553066: Epoch time: 142.47 s 
2025-07-12 21:50:22.553112: Yayy! New best EMA pseudo Dice: 0.9729 
2025-07-12 21:50:25.140046:  
2025-07-12 21:50:25.140291: Epoch 806 
2025-07-12 21:50:25.140400: Current learning rate: 0.00229 
2025-07-12 21:52:45.538564: train_loss -0.804 
2025-07-12 21:52:45.539669: val_loss -0.8006 
2025-07-12 21:52:45.539758: Pseudo dice [0.9721] 
2025-07-12 21:52:45.539860: Epoch time: 140.4 s 
2025-07-12 21:52:47.263817:  
2025-07-12 21:52:47.264973: Epoch 807 
2025-07-12 21:52:47.265328: Current learning rate: 0.00228 
2025-07-12 21:55:09.879810: train_loss -0.8035 
2025-07-12 21:55:09.881003: val_loss -0.8286 
2025-07-12 21:55:09.881089: Pseudo dice [0.9776] 
2025-07-12 21:55:09.881183: Epoch time: 142.62 s 
2025-07-12 21:55:09.881231: Yayy! New best EMA pseudo Dice: 0.9733 
2025-07-12 21:55:13.360664:  
2025-07-12 21:55:13.361075: Epoch 808 
2025-07-12 21:55:13.361269: Current learning rate: 0.00226 
2025-07-12 21:57:40.020643: train_loss -0.8005 
2025-07-12 21:57:40.021727: val_loss -0.8126 
2025-07-12 21:57:40.021797: Pseudo dice [0.9754] 
2025-07-12 21:57:40.021885: Epoch time: 146.66 s 
2025-07-12 21:57:40.021936: Yayy! New best EMA pseudo Dice: 0.9735 
2025-07-12 21:57:43.086094:  
2025-07-12 21:57:43.086766: Epoch 809 
2025-07-12 21:57:43.087001: Current learning rate: 0.00225 
2025-07-12 22:00:10.794053: train_loss -0.797 
2025-07-12 22:00:10.796117: val_loss -0.8018 
2025-07-12 22:00:10.796302: Pseudo dice [0.971] 
2025-07-12 22:00:10.796407: Epoch time: 147.71 s 
2025-07-12 22:00:12.441950:  
2025-07-12 22:00:12.442402: Epoch 810 
2025-07-12 22:00:12.442579: Current learning rate: 0.00224 
2025-07-12 22:02:34.673084: train_loss -0.8073 
2025-07-12 22:02:34.674237: val_loss -0.8055 
2025-07-12 22:02:34.674340: Pseudo dice [0.9767] 
2025-07-12 22:02:34.674477: Epoch time: 142.23 s 
2025-07-12 22:02:34.674546: Yayy! New best EMA pseudo Dice: 0.9736 
2025-07-12 22:02:38.435008:  
2025-07-12 22:02:38.435582: Epoch 811 
2025-07-12 22:02:38.435839: Current learning rate: 0.00223 
2025-07-12 22:05:01.200101: train_loss -0.8064 
2025-07-12 22:05:01.201391: val_loss -0.8263 
2025-07-12 22:05:01.201483: Pseudo dice [0.9745] 
2025-07-12 22:05:01.201585: Epoch time: 142.77 s 
2025-07-12 22:05:01.201637: Yayy! New best EMA pseudo Dice: 0.9737 
2025-07-12 22:05:05.358919:  
2025-07-12 22:05:05.360187: Epoch 812 
2025-07-12 22:05:05.360578: Current learning rate: 0.00222 
2025-07-12 22:07:33.350364: train_loss -0.8023 
2025-07-12 22:07:33.351525: val_loss -0.8345 
2025-07-12 22:07:33.351614: Pseudo dice [0.9764] 
2025-07-12 22:07:33.351712: Epoch time: 147.99 s 
2025-07-12 22:07:33.351756: Yayy! New best EMA pseudo Dice: 0.974 
2025-07-12 22:07:36.708527:  
2025-07-12 22:07:36.709321: Epoch 813 
2025-07-12 22:07:36.709605: Current learning rate: 0.00221 
2025-07-12 22:09:58.665749: train_loss -0.81 
2025-07-12 22:09:58.666910: val_loss -0.8273 
2025-07-12 22:09:58.666985: Pseudo dice [0.9758] 
2025-07-12 22:09:58.667065: Epoch time: 141.96 s 
2025-07-12 22:09:58.667104: Yayy! New best EMA pseudo Dice: 0.9741 
2025-07-12 22:10:01.394092:  
2025-07-12 22:10:01.394487: Epoch 814 
2025-07-12 22:10:01.394621: Current learning rate: 0.0022 
2025-07-12 22:12:24.514840: train_loss -0.8148 
2025-07-12 22:12:24.516018: val_loss -0.8127 
2025-07-12 22:12:24.516087: Pseudo dice [0.9721] 
2025-07-12 22:12:24.516176: Epoch time: 143.12 s 
2025-07-12 22:12:26.040838:  
2025-07-12 22:12:26.041393: Epoch 815 
2025-07-12 22:12:26.041588: Current learning rate: 0.00219 
2025-07-12 22:14:47.177265: train_loss -0.8024 
2025-07-12 22:14:47.178385: val_loss -0.8168 
2025-07-12 22:14:47.178471: Pseudo dice [0.975] 
2025-07-12 22:14:47.178600: Epoch time: 141.14 s 
2025-07-12 22:14:49.455345:  
2025-07-12 22:14:49.456695: Epoch 816 
2025-07-12 22:14:49.457299: Current learning rate: 0.00218 
2025-07-12 22:17:12.771778: train_loss -0.7982 
2025-07-12 22:17:12.772950: val_loss -0.7998 
2025-07-12 22:17:12.773033: Pseudo dice [0.9753] 
2025-07-12 22:17:12.773147: Epoch time: 143.32 s 
2025-07-12 22:17:12.773210: Yayy! New best EMA pseudo Dice: 0.9742 
2025-07-12 22:17:16.817050:  
2025-07-12 22:17:16.817761: Epoch 817 
2025-07-12 22:17:16.818058: Current learning rate: 0.00217 
2025-07-12 22:19:39.268965: train_loss -0.8014 
2025-07-12 22:19:39.270489: val_loss -0.8187 
2025-07-12 22:19:39.270743: Pseudo dice [0.9753] 
2025-07-12 22:19:39.270970: Epoch time: 142.45 s 
2025-07-12 22:19:39.271138: Yayy! New best EMA pseudo Dice: 0.9743 
2025-07-12 22:19:42.710830:  
2025-07-12 22:19:42.711443: Epoch 818 
2025-07-12 22:19:42.711715: Current learning rate: 0.00216 
2025-07-12 22:22:04.360400: train_loss -0.81 
2025-07-12 22:22:04.362042: val_loss -0.8013 
2025-07-12 22:22:04.362386: Pseudo dice [0.9767] 
2025-07-12 22:22:04.362598: Epoch time: 141.65 s 
2025-07-12 22:22:04.362764: Yayy! New best EMA pseudo Dice: 0.9745 
2025-07-12 22:22:10.145382:  
2025-07-12 22:22:10.145783: Epoch 819 
2025-07-12 22:22:10.145908: Current learning rate: 0.00215 
2025-07-12 22:24:30.862921: train_loss -0.8109 
2025-07-12 22:24:30.864784: val_loss -0.8279 
2025-07-12 22:24:30.864918: Pseudo dice [0.9763] 
2025-07-12 22:24:30.865055: Epoch time: 140.72 s 
2025-07-12 22:24:30.865130: Yayy! New best EMA pseudo Dice: 0.9747 
2025-07-12 22:24:34.377688:  
2025-07-12 22:24:34.378325: Epoch 820 
2025-07-12 22:24:34.378651: Current learning rate: 0.00214 
2025-07-12 22:26:55.059615: train_loss -0.7996 
2025-07-12 22:26:55.060686: val_loss -0.8003 
2025-07-12 22:26:55.060783: Pseudo dice [0.9744] 
2025-07-12 22:26:55.060873: Epoch time: 140.68 s 
2025-07-12 22:26:56.600591:  
2025-07-12 22:26:56.601409: Epoch 821 
2025-07-12 22:26:56.601700: Current learning rate: 0.00213 
2025-07-12 22:29:19.876925: train_loss -0.8023 
2025-07-12 22:29:19.877936: val_loss -0.7964 
2025-07-12 22:29:19.878087: Pseudo dice [0.9751] 
2025-07-12 22:29:19.878199: Epoch time: 143.28 s 
2025-07-12 22:29:19.878354: Yayy! New best EMA pseudo Dice: 0.9747 
2025-07-12 22:29:22.191091:  
2025-07-12 22:29:22.191531: Epoch 822 
2025-07-12 22:29:22.191643: Current learning rate: 0.00212 
2025-07-12 22:31:44.832407: train_loss -0.7976 
2025-07-12 22:31:44.834137: val_loss -0.8123 
2025-07-12 22:31:44.834286: Pseudo dice [0.973] 
2025-07-12 22:31:44.834396: Epoch time: 142.64 s 
2025-07-12 22:31:46.899055:  
2025-07-12 22:31:46.900521: Epoch 823 
2025-07-12 22:31:46.900959: Current learning rate: 0.0021 
2025-07-12 22:34:10.606244: train_loss -0.8063 
2025-07-12 22:34:10.606956: val_loss -0.824 
2025-07-12 22:34:10.607054: Pseudo dice [0.9723] 
2025-07-12 22:34:10.607167: Epoch time: 143.71 s 
2025-07-12 22:34:12.447214:  
2025-07-12 22:34:12.447993: Epoch 824 
2025-07-12 22:34:12.448276: Current learning rate: 0.00209 
2025-07-12 22:36:34.039648: train_loss -0.8016 
2025-07-12 22:36:34.041159: val_loss -0.832 
2025-07-12 22:36:34.041308: Pseudo dice [0.9743] 
2025-07-12 22:36:34.041475: Epoch time: 141.59 s 
2025-07-12 22:36:36.045611:  
2025-07-12 22:36:36.046671: Epoch 825 
2025-07-12 22:36:36.047042: Current learning rate: 0.00208 
2025-07-12 22:39:02.659551: train_loss -0.7913 
2025-07-12 22:39:02.661006: val_loss -0.8263 
2025-07-12 22:39:02.661137: Pseudo dice [0.9763] 
2025-07-12 22:39:02.661263: Epoch time: 146.62 s 
2025-07-12 22:39:04.375635:  
2025-07-12 22:39:04.376443: Epoch 826 
2025-07-12 22:39:04.376734: Current learning rate: 0.00207 
2025-07-12 22:41:30.235078: train_loss -0.8011 
2025-07-12 22:41:30.236493: val_loss -0.8102 
2025-07-12 22:41:30.236649: Pseudo dice [0.9757] 
2025-07-12 22:41:30.236768: Epoch time: 145.86 s 
2025-07-12 22:41:31.630044:  
2025-07-12 22:41:31.630806: Epoch 827 
2025-07-12 22:41:31.631148: Current learning rate: 0.00206 
2025-07-12 22:43:49.188915: train_loss -0.7985 
2025-07-12 22:43:49.190095: val_loss -0.8449 
2025-07-12 22:43:49.190207: Pseudo dice [0.9762] 
2025-07-12 22:43:49.190342: Epoch time: 137.56 s 
2025-07-12 22:43:49.190408: Yayy! New best EMA pseudo Dice: 0.9748 
2025-07-12 22:43:52.170991:  
2025-07-12 22:43:52.171368: Epoch 828 
2025-07-12 22:43:52.171572: Current learning rate: 0.00205 
2025-07-12 22:46:13.843075: train_loss -0.8096 
2025-07-12 22:46:13.844172: val_loss -0.8341 
2025-07-12 22:46:13.844314: Pseudo dice [0.9748] 
2025-07-12 22:46:13.844458: Epoch time: 141.67 s 
2025-07-12 22:46:15.726356:  
2025-07-12 22:46:15.727441: Epoch 829 
2025-07-12 22:46:15.727809: Current learning rate: 0.00204 
2025-07-12 22:48:39.112954: train_loss -0.7844 
2025-07-12 22:48:39.114161: val_loss -0.8325 
2025-07-12 22:48:39.114256: Pseudo dice [0.9728] 
2025-07-12 22:48:39.114348: Epoch time: 143.39 s 
2025-07-12 22:48:41.164244:  
2025-07-12 22:48:41.165006: Epoch 830 
2025-07-12 22:48:41.165414: Current learning rate: 0.00203 
2025-07-12 22:51:04.571932: train_loss -0.8055 
2025-07-12 22:51:04.573039: val_loss -0.8176 
2025-07-12 22:51:04.573162: Pseudo dice [0.9759] 
2025-07-12 22:51:04.573265: Epoch time: 143.41 s 
2025-07-12 22:51:06.407385:  
2025-07-12 22:51:06.408227: Epoch 831 
2025-07-12 22:51:06.408596: Current learning rate: 0.00202 
2025-07-12 22:53:29.316860: train_loss -0.7982 
2025-07-12 22:53:29.318078: val_loss -0.8051 
2025-07-12 22:53:29.318265: Pseudo dice [0.9709] 
2025-07-12 22:53:29.318440: Epoch time: 142.91 s 
2025-07-12 22:53:31.523303:  
2025-07-12 22:53:31.524200: Epoch 832 
2025-07-12 22:53:31.524586: Current learning rate: 0.00201 
2025-07-12 22:55:56.708263: train_loss -0.808 
2025-07-12 22:55:56.709965: val_loss -0.8344 
2025-07-12 22:55:56.710228: Pseudo dice [0.9744] 
2025-07-12 22:55:56.710546: Epoch time: 145.19 s 
2025-07-12 22:55:58.635231:  
2025-07-12 22:55:58.635953: Epoch 833 
2025-07-12 22:55:58.636232: Current learning rate: 0.002 
2025-07-12 22:58:24.903265: train_loss -0.8065 
2025-07-12 22:58:24.904428: val_loss -0.8255 
2025-07-12 22:58:24.904514: Pseudo dice [0.9761] 
2025-07-12 22:58:24.904613: Epoch time: 146.27 s 
2025-07-12 22:58:26.429589:  
2025-07-12 22:58:26.430404: Epoch 834 
2025-07-12 22:58:26.430720: Current learning rate: 0.00199 
2025-07-12 23:00:51.088410: train_loss -0.7954 
2025-07-12 23:00:51.089503: val_loss -0.8043 
2025-07-12 23:00:51.089579: Pseudo dice [0.9782] 
2025-07-12 23:00:51.089676: Epoch time: 144.66 s 
2025-07-12 23:00:51.089731: Yayy! New best EMA pseudo Dice: 0.9749 
2025-07-12 23:00:54.691050:  
2025-07-12 23:00:54.691987: Epoch 835 
2025-07-12 23:00:54.692393: Current learning rate: 0.00198 
2025-07-12 23:03:15.423968: train_loss -0.7921 
2025-07-12 23:03:15.425604: val_loss -0.8159 
2025-07-12 23:03:15.425808: Pseudo dice [0.9777] 
2025-07-12 23:03:15.426063: Epoch time: 140.73 s 
2025-07-12 23:03:15.426219: Yayy! New best EMA pseudo Dice: 0.9752 
2025-07-12 23:03:18.740268:  
2025-07-12 23:03:18.740855: Epoch 836 
2025-07-12 23:03:18.741128: Current learning rate: 0.00196 
2025-07-12 23:05:41.469580: train_loss -0.8127 
2025-07-12 23:05:41.470578: val_loss -0.7993 
2025-07-12 23:05:41.470664: Pseudo dice [0.9773] 
2025-07-12 23:05:41.470746: Epoch time: 142.73 s 
2025-07-12 23:05:41.470806: Yayy! New best EMA pseudo Dice: 0.9754 
2025-07-12 23:05:44.361155:  
2025-07-12 23:05:44.361605: Epoch 837 
2025-07-12 23:05:44.361725: Current learning rate: 0.00195 
2025-07-12 23:08:09.260538: train_loss -0.7974 
2025-07-12 23:08:09.261795: val_loss -0.8096 
2025-07-12 23:08:09.261974: Pseudo dice [0.9746] 
2025-07-12 23:08:09.262156: Epoch time: 144.9 s 
2025-07-12 23:08:14.499436:  
2025-07-12 23:08:14.499874: Epoch 838 
2025-07-12 23:08:14.499979: Current learning rate: 0.00194 
2025-07-12 23:10:34.901873: train_loss -0.7854 
2025-07-12 23:10:34.903758: val_loss -0.8255 
2025-07-12 23:10:34.903927: Pseudo dice [0.976] 
2025-07-12 23:10:34.904072: Epoch time: 140.4 s 
2025-07-12 23:10:37.049611:  
2025-07-12 23:10:37.050835: Epoch 839 
2025-07-12 23:10:37.051327: Current learning rate: 0.00193 
2025-07-12 23:12:59.752731: train_loss -0.8155 
2025-07-12 23:12:59.753799: val_loss -0.849 
2025-07-12 23:12:59.754089: Pseudo dice [0.9748] 
2025-07-12 23:12:59.754264: Epoch time: 142.71 s 
2025-07-12 23:13:01.466678:  
2025-07-12 23:13:01.467555: Epoch 840 
2025-07-12 23:13:01.467890: Current learning rate: 0.00192 
2025-07-12 23:15:21.476835: train_loss -0.8115 
2025-07-12 23:15:21.478284: val_loss -0.8419 
2025-07-12 23:15:21.478384: Pseudo dice [0.9772] 
2025-07-12 23:15:21.478470: Epoch time: 140.01 s 
2025-07-12 23:15:21.478518: Yayy! New best EMA pseudo Dice: 0.9755 
2025-07-12 23:15:25.124359:  
2025-07-12 23:15:25.125169: Epoch 841 
2025-07-12 23:15:25.125463: Current learning rate: 0.00191 
2025-07-12 23:17:45.538476: train_loss -0.8122 
2025-07-12 23:17:45.539711: val_loss -0.8236 
2025-07-12 23:17:45.539822: Pseudo dice [0.9776] 
2025-07-12 23:17:45.539964: Epoch time: 140.42 s 
2025-07-12 23:17:45.540021: Yayy! New best EMA pseudo Dice: 0.9757 
2025-07-12 23:17:48.036175:  
2025-07-12 23:17:48.036589: Epoch 842 
2025-07-12 23:17:48.036682: Current learning rate: 0.0019 
2025-07-12 23:20:06.702290: train_loss -0.8074 
2025-07-12 23:20:06.705132: val_loss -0.8089 
2025-07-12 23:20:06.705865: Pseudo dice [0.9769] 
2025-07-12 23:20:06.706050: Epoch time: 138.67 s 
2025-07-12 23:20:06.706162: Yayy! New best EMA pseudo Dice: 0.9758 
2025-07-12 23:20:10.544949:  
2025-07-12 23:20:10.545518: Epoch 843 
2025-07-12 23:20:10.545714: Current learning rate: 0.00189 
2025-07-12 23:22:31.913149: train_loss -0.7987 
2025-07-12 23:22:31.914469: val_loss -0.8302 
2025-07-12 23:22:31.914559: Pseudo dice [0.9723] 
2025-07-12 23:22:31.914664: Epoch time: 141.37 s 
2025-07-12 23:22:33.878999:  
2025-07-12 23:22:33.880306: Epoch 844 
2025-07-12 23:22:33.880695: Current learning rate: 0.00188 
2025-07-12 23:24:57.198978: train_loss -0.8052 
2025-07-12 23:24:57.200177: val_loss -0.8153 
2025-07-12 23:24:57.200421: Pseudo dice [0.9773] 
2025-07-12 23:24:57.200550: Epoch time: 143.32 s 
2025-07-12 23:24:59.026619:  
2025-07-12 23:24:59.027413: Epoch 845 
2025-07-12 23:24:59.027699: Current learning rate: 0.00187 
2025-07-12 23:27:18.590373: train_loss -0.8058 
2025-07-12 23:27:18.591432: val_loss -0.8045 
2025-07-12 23:27:18.591520: Pseudo dice [0.9779] 
2025-07-12 23:27:18.591719: Epoch time: 139.57 s 
2025-07-12 23:27:18.591776: Yayy! New best EMA pseudo Dice: 0.9759 
2025-07-12 23:27:22.203735:  
2025-07-12 23:27:22.205049: Epoch 846 
2025-07-12 23:27:22.205444: Current learning rate: 0.00186 
2025-07-12 23:29:46.525281: train_loss -0.8097 
2025-07-12 23:29:46.526418: val_loss -0.817 
2025-07-12 23:29:46.526547: Pseudo dice [0.9757] 
2025-07-12 23:29:46.526686: Epoch time: 144.32 s 
2025-07-12 23:29:48.270175:  
2025-07-12 23:29:48.270924: Epoch 847 
2025-07-12 23:29:48.271276: Current learning rate: 0.00185 
2025-07-12 23:32:12.129333: train_loss -0.7968 
2025-07-12 23:32:12.130364: val_loss -0.8463 
2025-07-12 23:32:12.130445: Pseudo dice [0.977] 
2025-07-12 23:32:12.130525: Epoch time: 143.86 s 
2025-07-12 23:32:12.130564: Yayy! New best EMA pseudo Dice: 0.976 
2025-07-12 23:32:15.089212:  
2025-07-12 23:32:15.089623: Epoch 848 
2025-07-12 23:32:15.089735: Current learning rate: 0.00184 
2025-07-12 23:34:33.852352: train_loss -0.8033 
2025-07-12 23:34:33.853536: val_loss -0.8233 
2025-07-12 23:34:33.853641: Pseudo dice [0.9779] 
2025-07-12 23:34:33.853723: Epoch time: 138.76 s 
2025-07-12 23:34:33.853768: Yayy! New best EMA pseudo Dice: 0.9762 
2025-07-12 23:34:36.713888:  
2025-07-12 23:34:36.714287: Epoch 849 
2025-07-12 23:34:36.714406: Current learning rate: 0.00182 
2025-07-12 23:36:55.229134: train_loss -0.8131 
2025-07-12 23:36:55.230415: val_loss -0.7936 
2025-07-12 23:36:55.230513: Pseudo dice [0.9748] 
2025-07-12 23:36:55.230625: Epoch time: 138.52 s 
2025-07-12 23:36:58.631992:  
2025-07-12 23:36:58.632701: Epoch 850 
2025-07-12 23:36:58.632975: Current learning rate: 0.00181 
2025-07-12 23:39:25.171641: train_loss -0.7924 
2025-07-12 23:39:25.172814: val_loss -0.807 
2025-07-12 23:39:25.172905: Pseudo dice [0.9741] 
2025-07-12 23:39:25.173030: Epoch time: 146.54 s 
2025-07-12 23:39:26.914931:  
2025-07-12 23:39:26.915762: Epoch 851 
2025-07-12 23:39:26.916070: Current learning rate: 0.0018 
2025-07-12 23:41:49.766820: train_loss -0.792 
2025-07-12 23:41:49.767768: val_loss -0.8244 
2025-07-12 23:41:49.767860: Pseudo dice [0.975] 
2025-07-12 23:41:49.767963: Epoch time: 142.85 s 
2025-07-12 23:41:51.590388:  
2025-07-12 23:41:51.591460: Epoch 852 
2025-07-12 23:41:51.591928: Current learning rate: 0.00179 
2025-07-12 23:44:13.377926: train_loss -0.7993 
2025-07-12 23:44:13.379319: val_loss -0.8279 
2025-07-12 23:44:13.379412: Pseudo dice [0.9759] 
2025-07-12 23:44:13.379508: Epoch time: 141.79 s 
2025-07-12 23:44:15.346767:  
2025-07-12 23:44:15.347760: Epoch 853 
2025-07-12 23:44:15.348159: Current learning rate: 0.00178 
2025-07-12 23:46:41.766837: train_loss -0.817 
2025-07-12 23:46:41.768218: val_loss -0.7934 
2025-07-12 23:46:41.768345: Pseudo dice [0.9767] 
2025-07-12 23:46:41.768475: Epoch time: 146.42 s 
2025-07-12 23:46:43.658863:  
2025-07-12 23:46:43.659595: Epoch 854 
2025-07-12 23:46:43.659948: Current learning rate: 0.00177 
2025-07-12 23:49:09.348683: train_loss -0.801 
2025-07-12 23:49:09.351065: val_loss -0.821 
2025-07-12 23:49:09.351909: Pseudo dice [0.9759] 
2025-07-12 23:49:09.352162: Epoch time: 145.69 s 
2025-07-12 23:49:11.258299:  
2025-07-12 23:49:11.258668: Epoch 855 
2025-07-12 23:49:11.258795: Current learning rate: 0.00176 
2025-07-12 23:51:33.926982: train_loss -0.8136 
2025-07-12 23:51:33.927857: val_loss -0.8207 
2025-07-12 23:51:33.928018: Pseudo dice [0.9758] 
2025-07-12 23:51:33.928142: Epoch time: 142.67 s 
2025-07-12 23:51:35.371635:  
2025-07-12 23:51:35.372282: Epoch 856 
2025-07-12 23:51:35.372592: Current learning rate: 0.00175 
2025-07-12 23:53:59.130808: train_loss -0.8063 
2025-07-12 23:53:59.132343: val_loss -0.8084 
2025-07-12 23:53:59.132527: Pseudo dice [0.9748] 
2025-07-12 23:53:59.132694: Epoch time: 143.76 s 
2025-07-12 23:54:05.099218:  
2025-07-12 23:54:05.099679: Epoch 857 
2025-07-12 23:54:05.099801: Current learning rate: 0.00174 
2025-07-12 23:56:29.600525: train_loss -0.8077 
2025-07-12 23:56:29.601997: val_loss -0.8144 
2025-07-12 23:56:29.602086: Pseudo dice [0.9719] 
2025-07-12 23:56:29.602193: Epoch time: 144.5 s 
2025-07-12 23:56:31.583966:  
2025-07-12 23:56:31.585204: Epoch 858 
2025-07-12 23:56:31.585745: Current learning rate: 0.00173 
2025-07-12 23:58:58.856061: train_loss -0.8172 
2025-07-12 23:58:58.858065: val_loss -0.8277 
2025-07-12 23:58:58.858925: Pseudo dice [0.9741] 
2025-07-12 23:58:58.859645: Epoch time: 147.27 s 
2025-07-12 23:59:00.876471:  
2025-07-12 23:59:00.877537: Epoch 859 
2025-07-12 23:59:00.877934: Current learning rate: 0.00172 
2025-07-13 00:01:26.989641: train_loss -0.8043 
2025-07-13 00:01:26.991028: val_loss -0.8326 
2025-07-13 00:01:26.991147: Pseudo dice [0.9748] 
2025-07-13 00:01:26.991244: Epoch time: 146.12 s 
2025-07-13 00:01:29.000934:  
2025-07-13 00:01:29.002017: Epoch 860 
2025-07-13 00:01:29.002399: Current learning rate: 0.0017 
2025-07-13 00:03:50.050065: train_loss -0.8091 
2025-07-13 00:03:50.053238: val_loss -0.8307 
2025-07-13 00:03:50.053583: Pseudo dice [0.9736] 
2025-07-13 00:03:50.053806: Epoch time: 141.05 s 
2025-07-13 00:03:51.782591:  
2025-07-13 00:03:51.783424: Epoch 861 
2025-07-13 00:03:51.783753: Current learning rate: 0.00169 
2025-07-13 00:06:15.935538: train_loss -0.7975 
2025-07-13 00:06:15.936704: val_loss -0.8326 
2025-07-13 00:06:15.936805: Pseudo dice [0.9776] 
2025-07-13 00:06:15.936900: Epoch time: 144.15 s 
2025-07-13 00:06:17.865261:  
2025-07-13 00:06:17.866355: Epoch 862 
2025-07-13 00:06:17.866692: Current learning rate: 0.00168 
2025-07-13 00:08:42.572748: train_loss -0.8068 
2025-07-13 00:08:42.573599: val_loss -0.8319 
2025-07-13 00:08:42.573663: Pseudo dice [0.9778] 
2025-07-13 00:08:42.573735: Epoch time: 144.71 s 
2025-07-13 00:08:44.015267:  
2025-07-13 00:08:44.016169: Epoch 863 
2025-07-13 00:08:44.016520: Current learning rate: 0.00167 
2025-07-13 00:11:05.449018: train_loss -0.803 
2025-07-13 00:11:05.450054: val_loss -0.8086 
2025-07-13 00:11:05.450135: Pseudo dice [0.9776] 
2025-07-13 00:11:05.450220: Epoch time: 141.44 s 
2025-07-13 00:11:07.381367:  
2025-07-13 00:11:07.382560: Epoch 864 
2025-07-13 00:11:07.382991: Current learning rate: 0.00166 
2025-07-13 00:13:32.883581: train_loss -0.8048 
2025-07-13 00:13:32.884658: val_loss -0.8142 
2025-07-13 00:13:32.884745: Pseudo dice [0.9757] 
2025-07-13 00:13:32.884849: Epoch time: 145.5 s 
2025-07-13 00:13:34.646683:  
2025-07-13 00:13:34.647557: Epoch 865 
2025-07-13 00:13:34.647836: Current learning rate: 0.00165 
2025-07-13 00:15:59.800619: train_loss -0.8052 
2025-07-13 00:15:59.801679: val_loss -0.7998 
2025-07-13 00:15:59.801747: Pseudo dice [0.974] 
2025-07-13 00:15:59.801836: Epoch time: 145.16 s 
2025-07-13 00:16:01.390731:  
2025-07-13 00:16:01.391692: Epoch 866 
2025-07-13 00:16:01.392132: Current learning rate: 0.00164 
2025-07-13 00:18:23.426964: train_loss -0.7996 
2025-07-13 00:18:23.428880: val_loss -0.8109 
2025-07-13 00:18:23.429051: Pseudo dice [0.9746] 
2025-07-13 00:18:23.429203: Epoch time: 142.04 s 
2025-07-13 00:18:25.571815:  
2025-07-13 00:18:25.572982: Epoch 867 
2025-07-13 00:18:25.573406: Current learning rate: 0.00163 
2025-07-13 00:20:52.057372: train_loss -0.8215 
2025-07-13 00:20:52.058490: val_loss -0.824 
2025-07-13 00:20:52.058576: Pseudo dice [0.9751] 
2025-07-13 00:20:52.058683: Epoch time: 146.49 s 
2025-07-13 00:20:53.966861:  
2025-07-13 00:20:53.968007: Epoch 868 
2025-07-13 00:20:53.968437: Current learning rate: 0.00162 
2025-07-13 00:23:20.324556: train_loss -0.7982 
2025-07-13 00:23:20.325872: val_loss -0.8357 
2025-07-13 00:23:20.325958: Pseudo dice [0.9751] 
2025-07-13 00:23:20.326068: Epoch time: 146.36 s 
2025-07-13 00:23:22.271363:  
2025-07-13 00:23:22.272543: Epoch 869 
2025-07-13 00:23:22.273005: Current learning rate: 0.00161 
2025-07-13 00:25:47.046539: train_loss -0.7977 
2025-07-13 00:25:47.047530: val_loss -0.8229 
2025-07-13 00:25:47.047611: Pseudo dice [0.9774] 
2025-07-13 00:25:47.047686: Epoch time: 144.78 s 
2025-07-13 00:25:48.557163:  
2025-07-13 00:25:48.558006: Epoch 870 
2025-07-13 00:25:48.558335: Current learning rate: 0.00159 
2025-07-13 00:28:14.552479: train_loss -0.8117 
2025-07-13 00:28:14.554161: val_loss -0.8231 
2025-07-13 00:28:14.554454: Pseudo dice [0.9766] 
2025-07-13 00:28:14.554598: Epoch time: 146.0 s 
2025-07-13 00:28:16.350876:  
2025-07-13 00:28:16.351752: Epoch 871 
2025-07-13 00:28:16.352083: Current learning rate: 0.00158 
2025-07-13 00:30:42.418385: train_loss -0.7876 
2025-07-13 00:30:42.420061: val_loss -0.836 
2025-07-13 00:30:42.420325: Pseudo dice [0.9765] 
2025-07-13 00:30:42.420554: Epoch time: 146.07 s 
2025-07-13 00:30:44.106833:  
2025-07-13 00:30:44.107614: Epoch 872 
2025-07-13 00:30:44.107951: Current learning rate: 0.00157 
2025-07-13 00:33:05.519895: train_loss -0.7867 
2025-07-13 00:33:05.520959: val_loss -0.7885 
2025-07-13 00:33:05.521056: Pseudo dice [0.9712] 
2025-07-13 00:33:05.521157: Epoch time: 141.41 s 
2025-07-13 00:33:07.255263:  
2025-07-13 00:33:07.255949: Epoch 873 
2025-07-13 00:33:07.256266: Current learning rate: 0.00156 
2025-07-13 00:35:32.722323: train_loss -0.805 
2025-07-13 00:35:32.723630: val_loss -0.8147 
2025-07-13 00:35:32.723722: Pseudo dice [0.9731] 
2025-07-13 00:35:32.723818: Epoch time: 145.47 s 
2025-07-13 00:35:34.539623:  
2025-07-13 00:35:34.540296: Epoch 874 
2025-07-13 00:35:34.540625: Current learning rate: 0.00155 
2025-07-13 00:38:02.898262: train_loss -0.8023 
2025-07-13 00:38:02.899621: val_loss -0.8181 
2025-07-13 00:38:02.899711: Pseudo dice [0.9762] 
2025-07-13 00:38:02.899809: Epoch time: 148.36 s 
2025-07-13 00:38:04.797369:  
2025-07-13 00:38:04.798265: Epoch 875 
2025-07-13 00:38:04.798594: Current learning rate: 0.00154 
2025-07-13 00:40:27.678674: train_loss -0.8096 
2025-07-13 00:40:27.679818: val_loss -0.7982 
2025-07-13 00:40:27.679896: Pseudo dice [0.9747] 
2025-07-13 00:40:27.680008: Epoch time: 142.88 s 
2025-07-13 00:40:29.415812:  
2025-07-13 00:40:29.416617: Epoch 876 
2025-07-13 00:40:29.416939: Current learning rate: 0.00153 
2025-07-13 00:42:54.021102: train_loss -0.8137 
2025-07-13 00:42:54.022016: val_loss -0.8483 
2025-07-13 00:42:54.022089: Pseudo dice [0.9776] 
2025-07-13 00:42:54.022196: Epoch time: 144.61 s 
2025-07-13 00:42:55.608135:  
2025-07-13 00:42:55.608919: Epoch 877 
2025-07-13 00:42:55.609319: Current learning rate: 0.00152 
2025-07-13 00:45:19.971668: train_loss -0.793 
2025-07-13 00:45:19.973830: val_loss -0.8584 
2025-07-13 00:45:19.979128: Pseudo dice [0.975] 
2025-07-13 00:45:19.979833: Epoch time: 144.37 s 
2025-07-13 00:45:24.441185:  
2025-07-13 00:45:24.441590: Epoch 878 
2025-07-13 00:45:24.441694: Current learning rate: 0.00151 
2025-07-13 00:47:48.996016: train_loss -0.8046 
2025-07-13 00:47:48.997451: val_loss -0.805 
2025-07-13 00:47:48.997550: Pseudo dice [0.9761] 
2025-07-13 00:47:48.997663: Epoch time: 144.56 s 
2025-07-13 00:47:50.633299:  
2025-07-13 00:47:50.633880: Epoch 879 
2025-07-13 00:47:50.634106: Current learning rate: 0.00149 
2025-07-13 00:50:13.879832: train_loss -0.8168 
2025-07-13 00:50:13.881068: val_loss -0.8353 
2025-07-13 00:50:13.881144: Pseudo dice [0.9763] 
2025-07-13 00:50:13.881244: Epoch time: 143.25 s 
2025-07-13 00:50:15.466179:  
2025-07-13 00:50:15.467030: Epoch 880 
2025-07-13 00:50:15.467378: Current learning rate: 0.00148 
2025-07-13 00:52:38.348600: train_loss -0.8069 
2025-07-13 00:52:38.350076: val_loss -0.815 
2025-07-13 00:52:38.350347: Pseudo dice [0.9772] 
2025-07-13 00:52:38.350578: Epoch time: 142.88 s 
2025-07-13 00:52:40.119435:  
2025-07-13 00:52:40.120574: Epoch 881 
2025-07-13 00:52:40.120996: Current learning rate: 0.00147 
2025-07-13 00:55:06.048428: train_loss -0.8076 
2025-07-13 00:55:06.050705: val_loss -0.8116 
2025-07-13 00:55:06.051244: Pseudo dice [0.9767] 
2025-07-13 00:55:06.051471: Epoch time: 145.93 s 
2025-07-13 00:55:07.878430:  
2025-07-13 00:55:07.879121: Epoch 882 
2025-07-13 00:55:07.879406: Current learning rate: 0.00146 
2025-07-13 00:57:28.326825: train_loss -0.8173 
2025-07-13 00:57:28.328001: val_loss -0.8396 
2025-07-13 00:57:28.328087: Pseudo dice [0.9765] 
2025-07-13 00:57:28.328195: Epoch time: 140.45 s 
2025-07-13 00:57:30.261998:  
2025-07-13 00:57:30.262993: Epoch 883 
2025-07-13 00:57:30.263529: Current learning rate: 0.00145 
2025-07-13 00:59:55.214153: train_loss -0.7992 
2025-07-13 00:59:55.215101: val_loss -0.8138 
2025-07-13 00:59:55.215178: Pseudo dice [0.9719] 
2025-07-13 00:59:55.215281: Epoch time: 144.95 s 
2025-07-13 00:59:56.851043:  
2025-07-13 00:59:56.851957: Epoch 884 
2025-07-13 00:59:56.852272: Current learning rate: 0.00144 
2025-07-13 01:02:20.143472: train_loss -0.8019 
2025-07-13 01:02:20.144600: val_loss -0.8199 
2025-07-13 01:02:20.144687: Pseudo dice [0.977] 
2025-07-13 01:02:20.144785: Epoch time: 143.29 s 
2025-07-13 01:02:21.874396:  
2025-07-13 01:02:21.875461: Epoch 885 
2025-07-13 01:02:21.875807: Current learning rate: 0.00143 
2025-07-13 01:04:47.440854: train_loss -0.7945 
2025-07-13 01:04:47.442930: val_loss -0.8347 
2025-07-13 01:04:47.443045: Pseudo dice [0.9709] 
2025-07-13 01:04:47.444749: Epoch time: 145.57 s 
2025-07-13 01:04:49.388672:  
2025-07-13 01:04:49.389663: Epoch 886 
2025-07-13 01:04:49.389958: Current learning rate: 0.00142 
2025-07-13 01:07:16.652626: train_loss -0.7932 
2025-07-13 01:07:16.657383: val_loss -0.8326 
2025-07-13 01:07:16.657521: Pseudo dice [0.976] 
2025-07-13 01:07:16.657621: Epoch time: 147.27 s 
2025-07-13 01:07:18.210763:  
2025-07-13 01:07:18.211567: Epoch 887 
2025-07-13 01:07:18.211860: Current learning rate: 0.00141 
2025-07-13 01:09:42.703987: train_loss -0.7926 
2025-07-13 01:09:42.704910: val_loss -0.8316 
2025-07-13 01:09:42.704978: Pseudo dice [0.9772] 
2025-07-13 01:09:42.705055: Epoch time: 144.49 s 
2025-07-13 01:09:44.119274:  
2025-07-13 01:09:44.119673: Epoch 888 
2025-07-13 01:09:44.119817: Current learning rate: 0.00139 
2025-07-13 01:12:04.241822: train_loss -0.8056 
2025-07-13 01:12:04.242790: val_loss -0.8007 
2025-07-13 01:12:04.242868: Pseudo dice [0.9743] 
2025-07-13 01:12:04.242952: Epoch time: 140.12 s 
2025-07-13 01:12:05.902204:  
2025-07-13 01:12:05.903028: Epoch 889 
2025-07-13 01:12:05.903388: Current learning rate: 0.00138 
2025-07-13 01:14:27.507290: train_loss -0.8091 
2025-07-13 01:14:27.508767: val_loss -0.7915 
2025-07-13 01:14:27.508860: Pseudo dice [0.9753] 
2025-07-13 01:14:27.508988: Epoch time: 141.61 s 
2025-07-13 01:14:29.625742:  
2025-07-13 01:14:29.626617: Epoch 890 
2025-07-13 01:14:29.627074: Current learning rate: 0.00137 
2025-07-13 01:16:55.391752: train_loss -0.8096 
2025-07-13 01:16:55.395399: val_loss -0.8289 
2025-07-13 01:16:55.396301: Pseudo dice [0.9763] 
2025-07-13 01:16:55.396974: Epoch time: 145.77 s 
2025-07-13 01:16:57.604887:  
2025-07-13 01:16:57.605972: Epoch 891 
2025-07-13 01:16:57.606351: Current learning rate: 0.00136 
2025-07-13 01:19:19.856164: train_loss -0.8041 
2025-07-13 01:19:19.857344: val_loss -0.8081 
2025-07-13 01:19:19.857432: Pseudo dice [0.972] 
2025-07-13 01:19:19.857529: Epoch time: 142.25 s 
2025-07-13 01:19:21.509627:  
2025-07-13 01:19:21.510161: Epoch 892 
2025-07-13 01:19:21.510500: Current learning rate: 0.00135 
2025-07-13 01:21:43.209055: train_loss -0.807 
2025-07-13 01:21:43.215753: val_loss -0.8012 
2025-07-13 01:21:43.216028: Pseudo dice [0.9699] 
2025-07-13 01:21:43.216155: Epoch time: 141.7 s 
2025-07-13 01:21:45.267401:  
2025-07-13 01:21:45.268286: Epoch 893 
2025-07-13 01:21:45.268581: Current learning rate: 0.00134 
2025-07-13 01:24:07.834509: train_loss -0.8047 
2025-07-13 01:24:07.836033: val_loss -0.8098 
2025-07-13 01:24:07.836152: Pseudo dice [0.9739] 
2025-07-13 01:24:07.836236: Epoch time: 142.57 s 
2025-07-13 01:24:09.750728:  
2025-07-13 01:24:09.751503: Epoch 894 
2025-07-13 01:24:09.751818: Current learning rate: 0.00133 
2025-07-13 01:26:35.804945: train_loss -0.8114 
2025-07-13 01:26:35.805997: val_loss -0.8463 
2025-07-13 01:26:35.806090: Pseudo dice [0.9765] 
2025-07-13 01:26:35.806189: Epoch time: 146.06 s 
2025-07-13 01:26:37.534677:  
2025-07-13 01:26:37.535345: Epoch 895 
2025-07-13 01:26:37.535613: Current learning rate: 0.00132 
2025-07-13 01:28:59.517305: train_loss -0.7915 
2025-07-13 01:28:59.518400: val_loss -0.8295 
2025-07-13 01:28:59.518479: Pseudo dice [0.9771] 
2025-07-13 01:28:59.518580: Epoch time: 141.98 s 
2025-07-13 01:29:00.880085:  
2025-07-13 01:29:00.880602: Epoch 896 
2025-07-13 01:29:00.880768: Current learning rate: 0.0013 
2025-07-13 01:31:21.549020: train_loss -0.8049 
2025-07-13 01:31:21.550095: val_loss -0.7982 
2025-07-13 01:31:21.550178: Pseudo dice [0.9769] 
2025-07-13 01:31:21.550297: Epoch time: 140.67 s 
2025-07-13 01:31:23.281651:  
2025-07-13 01:31:23.282819: Epoch 897 
2025-07-13 01:31:23.283366: Current learning rate: 0.00129 
2025-07-13 01:33:50.595295: train_loss -0.8164 
2025-07-13 01:33:50.597462: val_loss -0.8477 
2025-07-13 01:33:50.597791: Pseudo dice [0.9789] 
2025-07-13 01:33:50.597919: Epoch time: 147.32 s 
2025-07-13 01:33:52.138424:  
2025-07-13 01:33:52.138956: Epoch 898 
2025-07-13 01:33:52.139195: Current learning rate: 0.00128 
2025-07-13 01:36:14.410223: train_loss -0.7944 
2025-07-13 01:36:14.412017: val_loss -0.8322 
2025-07-13 01:36:14.412529: Pseudo dice [0.9757] 
2025-07-13 01:36:14.412848: Epoch time: 142.27 s 
2025-07-13 01:36:19.474649:  
2025-07-13 01:36:19.474945: Epoch 899 
2025-07-13 01:36:19.475050: Current learning rate: 0.00127 
2025-07-13 01:38:42.524176: train_loss -0.7862 
2025-07-13 01:38:42.525321: val_loss -0.8229 
2025-07-13 01:38:42.525438: Pseudo dice [0.9782] 
2025-07-13 01:38:42.525535: Epoch time: 143.05 s 
2025-07-13 01:38:45.971540:  
2025-07-13 01:38:45.972349: Epoch 900 
2025-07-13 01:38:45.972737: Current learning rate: 0.00126 
2025-07-13 01:41:10.715411: train_loss -0.8097 
2025-07-13 01:41:10.717378: val_loss -0.8028 
2025-07-13 01:41:10.717703: Pseudo dice [0.9779] 
2025-07-13 01:41:10.717892: Epoch time: 144.75 s 
2025-07-13 01:41:12.397112:  
2025-07-13 01:41:12.397802: Epoch 901 
2025-07-13 01:41:12.398040: Current learning rate: 0.00125 
2025-07-13 01:43:36.397047: train_loss -0.7926 
2025-07-13 01:43:36.398890: val_loss -0.8331 
2025-07-13 01:43:36.399047: Pseudo dice [0.9792] 
2025-07-13 01:43:36.399176: Epoch time: 144.0 s 
2025-07-13 01:43:36.399276: Yayy! New best EMA pseudo Dice: 0.9763 
2025-07-13 01:43:39.235224:  
2025-07-13 01:43:39.235756: Epoch 902 
2025-07-13 01:43:39.235908: Current learning rate: 0.00124 
2025-07-13 01:46:01.951584: train_loss -0.7941 
2025-07-13 01:46:01.952856: val_loss -0.7904 
2025-07-13 01:46:01.952970: Pseudo dice [0.9793] 
2025-07-13 01:46:01.953098: Epoch time: 142.72 s 
2025-07-13 01:46:01.953155: Yayy! New best EMA pseudo Dice: 0.9766 
2025-07-13 01:46:04.899898:  
2025-07-13 01:46:04.900321: Epoch 903 
2025-07-13 01:46:04.900425: Current learning rate: 0.00122 
2025-07-13 01:48:25.757166: train_loss -0.7987 
2025-07-13 01:48:25.758864: val_loss -0.8425 
2025-07-13 01:48:25.759137: Pseudo dice [0.9777] 
2025-07-13 01:48:25.759368: Epoch time: 140.86 s 
2025-07-13 01:48:25.759535: Yayy! New best EMA pseudo Dice: 0.9767 
2025-07-13 01:48:29.538539:  
2025-07-13 01:48:29.539454: Epoch 904 
2025-07-13 01:48:29.539872: Current learning rate: 0.00121 
2025-07-13 01:50:51.217646: train_loss -0.8084 
2025-07-13 01:50:51.219004: val_loss -0.8497 
2025-07-13 01:50:51.219094: Pseudo dice [0.9779] 
2025-07-13 01:50:51.219192: Epoch time: 141.68 s 
2025-07-13 01:50:51.219245: Yayy! New best EMA pseudo Dice: 0.9768 
2025-07-13 01:50:54.732416:  
2025-07-13 01:50:54.733139: Epoch 905 
2025-07-13 01:50:54.733459: Current learning rate: 0.0012 
2025-07-13 01:53:14.796192: train_loss -0.803 
2025-07-13 01:53:14.797472: val_loss -0.8119 
2025-07-13 01:53:14.797547: Pseudo dice [0.9792] 
2025-07-13 01:53:14.797637: Epoch time: 140.07 s 
2025-07-13 01:53:14.797683: Yayy! New best EMA pseudo Dice: 0.9771 
2025-07-13 01:53:17.348960:  
2025-07-13 01:53:17.349398: Epoch 906 
2025-07-13 01:53:17.349509: Current learning rate: 0.00119 
2025-07-13 01:55:39.355898: train_loss -0.7931 
2025-07-13 01:55:39.357309: val_loss -0.8119 
2025-07-13 01:55:39.357446: Pseudo dice [0.9766] 
2025-07-13 01:55:39.357619: Epoch time: 142.01 s 
2025-07-13 01:55:41.167736:  
2025-07-13 01:55:41.168721: Epoch 907 
2025-07-13 01:55:41.169101: Current learning rate: 0.00118 
2025-07-13 01:58:09.661150: train_loss -0.8027 
2025-07-13 01:58:09.664397: val_loss -0.82 
2025-07-13 01:58:09.664549: Pseudo dice [0.9774] 
2025-07-13 01:58:09.664644: Epoch time: 148.5 s 
2025-07-13 01:58:11.395956:  
2025-07-13 01:58:11.397044: Epoch 908 
2025-07-13 01:58:11.397479: Current learning rate: 0.00117 
2025-07-13 02:00:33.777940: train_loss -0.8102 
2025-07-13 02:00:33.779492: val_loss -0.8425 
2025-07-13 02:00:33.779667: Pseudo dice [0.9792] 
2025-07-13 02:00:33.779761: Epoch time: 142.38 s 
2025-07-13 02:00:33.779804: Yayy! New best EMA pseudo Dice: 0.9773 
2025-07-13 02:00:37.540992:  
2025-07-13 02:00:37.541916: Epoch 909 
2025-07-13 02:00:37.542301: Current learning rate: 0.00116 
2025-07-13 02:03:00.580695: train_loss -0.7986 
2025-07-13 02:03:00.581689: val_loss -0.8096 
2025-07-13 02:03:00.581776: Pseudo dice [0.9794] 
2025-07-13 02:03:00.581883: Epoch time: 143.04 s 
2025-07-13 02:03:00.581934: Yayy! New best EMA pseudo Dice: 0.9775 
2025-07-13 02:03:04.065567:  
2025-07-13 02:03:04.066237: Epoch 910 
2025-07-13 02:03:04.066487: Current learning rate: 0.00115 
2025-07-13 02:05:27.107355: train_loss -0.7952 
2025-07-13 02:05:27.108407: val_loss -0.8157 
2025-07-13 02:05:27.108583: Pseudo dice [0.9781] 
2025-07-13 02:05:27.108723: Epoch time: 143.04 s 
2025-07-13 02:05:27.108857: Yayy! New best EMA pseudo Dice: 0.9775 
2025-07-13 02:05:29.554175:  
2025-07-13 02:05:29.554775: Epoch 911 
2025-07-13 02:05:29.554971: Current learning rate: 0.00113 
2025-07-13 02:07:52.033639: train_loss -0.8072 
2025-07-13 02:07:52.034900: val_loss -0.7854 
2025-07-13 02:07:52.034983: Pseudo dice [0.9774] 
2025-07-13 02:07:52.035082: Epoch time: 142.48 s 
2025-07-13 02:07:53.893079:  
2025-07-13 02:07:53.894000: Epoch 912 
2025-07-13 02:07:53.894349: Current learning rate: 0.00112 
2025-07-13 02:10:18.768893: train_loss -0.8002 
2025-07-13 02:10:18.769984: val_loss -0.8157 
2025-07-13 02:10:18.770061: Pseudo dice [0.9776] 
2025-07-13 02:10:18.770140: Epoch time: 144.88 s 
2025-07-13 02:10:20.615761:  
2025-07-13 02:10:20.616479: Epoch 913 
2025-07-13 02:10:20.616722: Current learning rate: 0.00111 
2025-07-13 02:12:43.521219: train_loss -0.8068 
2025-07-13 02:12:43.522761: val_loss -0.8416 
2025-07-13 02:12:43.522942: Pseudo dice [0.9797] 
2025-07-13 02:12:43.523145: Epoch time: 142.91 s 
2025-07-13 02:12:43.523297: Yayy! New best EMA pseudo Dice: 0.9777 
2025-07-13 02:12:46.978526:  
2025-07-13 02:12:46.978974: Epoch 914 
2025-07-13 02:12:46.979212: Current learning rate: 0.0011 
2025-07-13 02:15:09.340829: train_loss -0.8117 
2025-07-13 02:15:09.341854: val_loss -0.8516 
2025-07-13 02:15:09.341937: Pseudo dice [0.9804] 
2025-07-13 02:15:09.342052: Epoch time: 142.36 s 
2025-07-13 02:15:09.342114: Yayy! New best EMA pseudo Dice: 0.978 
2025-07-13 02:15:12.112564:  
2025-07-13 02:15:12.112973: Epoch 915 
2025-07-13 02:15:12.113072: Current learning rate: 0.00109 
2025-07-13 02:17:37.842931: train_loss -0.8076 
2025-07-13 02:17:37.844239: val_loss -0.8423 
2025-07-13 02:17:37.844480: Pseudo dice [0.9779] 
2025-07-13 02:17:37.844641: Epoch time: 145.73 s 
2025-07-13 02:17:39.944305:  
2025-07-13 02:17:39.945271: Epoch 916 
2025-07-13 02:17:39.945801: Current learning rate: 0.00108 
2025-07-13 02:20:02.808298: train_loss -0.8124 
2025-07-13 02:20:02.809439: val_loss -0.8477 
2025-07-13 02:20:02.809528: Pseudo dice [0.9784] 
2025-07-13 02:20:02.809824: Epoch time: 142.87 s 
2025-07-13 02:20:02.809871: Yayy! New best EMA pseudo Dice: 0.978 
2025-07-13 02:20:06.051623:  
2025-07-13 02:20:06.052145: Epoch 917 
2025-07-13 02:20:06.052368: Current learning rate: 0.00106 
2025-07-13 02:22:29.787799: train_loss -0.811 
2025-07-13 02:22:29.791419: val_loss -0.8193 
2025-07-13 02:22:29.791577: Pseudo dice [0.9788] 
2025-07-13 02:22:29.791697: Epoch time: 143.74 s 
2025-07-13 02:22:29.791752: Yayy! New best EMA pseudo Dice: 0.9781 
2025-07-13 02:22:34.833394:  
2025-07-13 02:22:34.833804: Epoch 918 
2025-07-13 02:22:34.833872: Current learning rate: 0.00105 
2025-07-13 02:24:54.640414: train_loss -0.8073 
2025-07-13 02:24:54.641696: val_loss -0.8586 
2025-07-13 02:24:54.641790: Pseudo dice [0.9769] 
2025-07-13 02:24:54.641965: Epoch time: 139.81 s 
2025-07-13 02:24:56.144798:  
2025-07-13 02:24:56.145772: Epoch 919 
2025-07-13 02:24:56.146114: Current learning rate: 0.00104 
2025-07-13 02:27:18.078977: train_loss -0.8081 
2025-07-13 02:27:18.080204: val_loss -0.8266 
2025-07-13 02:27:18.080305: Pseudo dice [0.9756] 
2025-07-13 02:27:18.080405: Epoch time: 141.94 s 
2025-07-13 02:27:19.822874:  
2025-07-13 02:27:19.823889: Epoch 920 
2025-07-13 02:27:19.824228: Current learning rate: 0.00103 
2025-07-13 02:29:44.318455: train_loss -0.8189 
2025-07-13 02:29:44.320392: val_loss -0.8145 
2025-07-13 02:29:44.320684: Pseudo dice [0.9783] 
2025-07-13 02:29:44.320894: Epoch time: 144.5 s 
2025-07-13 02:29:45.999953:  
2025-07-13 02:29:46.000678: Epoch 921 
2025-07-13 02:29:46.000964: Current learning rate: 0.00102 
2025-07-13 02:32:06.121219: train_loss -0.8003 
2025-07-13 02:32:06.122804: val_loss -0.8024 
2025-07-13 02:32:06.122903: Pseudo dice [0.9777] 
2025-07-13 02:32:06.122994: Epoch time: 140.12 s 
2025-07-13 02:32:08.067440:  
2025-07-13 02:32:08.068221: Epoch 922 
2025-07-13 02:32:08.068563: Current learning rate: 0.00101 
2025-07-13 02:34:29.788649: train_loss -0.8118 
2025-07-13 02:34:29.789987: val_loss -0.8375 
2025-07-13 02:34:29.790192: Pseudo dice [0.9794] 
2025-07-13 02:34:29.790329: Epoch time: 141.72 s 
2025-07-13 02:34:31.511783:  
2025-07-13 02:34:31.513407: Epoch 923 
2025-07-13 02:34:31.513896: Current learning rate: 0.001 
2025-07-13 02:36:57.153464: train_loss -0.7985 
2025-07-13 02:36:57.154467: val_loss -0.8046 
2025-07-13 02:36:57.154544: Pseudo dice [0.9794] 
2025-07-13 02:36:57.154648: Epoch time: 145.64 s 
2025-07-13 02:36:59.057162:  
2025-07-13 02:36:59.058092: Epoch 924 
2025-07-13 02:36:59.058401: Current learning rate: 0.00098 
2025-07-13 02:39:19.815674: train_loss -0.806 
2025-07-13 02:39:19.818396: val_loss -0.8176 
2025-07-13 02:39:19.819145: Pseudo dice [0.98] 
2025-07-13 02:39:19.819993: Epoch time: 140.76 s 
2025-07-13 02:39:19.820859: Yayy! New best EMA pseudo Dice: 0.9783 
2025-07-13 02:39:23.164831:  
2025-07-13 02:39:23.165401: Epoch 925 
2025-07-13 02:39:23.165536: Current learning rate: 0.00097 
2025-07-13 02:41:50.633658: train_loss -0.8065 
2025-07-13 02:41:50.635142: val_loss -0.8259 
2025-07-13 02:41:50.635290: Pseudo dice [0.9782] 
2025-07-13 02:41:50.635397: Epoch time: 147.47 s 
2025-07-13 02:41:52.480577:  
2025-07-13 02:41:52.481952: Epoch 926 
2025-07-13 02:41:52.482390: Current learning rate: 0.00096 
2025-07-13 02:44:23.366342: train_loss -0.8013 
2025-07-13 02:44:23.367503: val_loss -0.8184 
2025-07-13 02:44:23.367572: Pseudo dice [0.9774] 
2025-07-13 02:44:23.367691: Epoch time: 150.89 s 
2025-07-13 02:44:24.779708:  
2025-07-13 02:44:24.780089: Epoch 927 
2025-07-13 02:44:24.780232: Current learning rate: 0.00095 
2025-07-13 02:46:44.555861: train_loss -0.8061 
2025-07-13 02:46:44.557450: val_loss -0.8434 
2025-07-13 02:46:44.557606: Pseudo dice [0.9783] 
2025-07-13 02:46:44.557749: Epoch time: 139.78 s 
2025-07-13 02:46:46.749855:  
2025-07-13 02:46:46.750865: Epoch 928 
2025-07-13 02:46:46.751259: Current learning rate: 0.00094 
2025-07-13 02:49:08.668083: train_loss -0.8099 
2025-07-13 02:49:08.670177: val_loss -0.8421 
2025-07-13 02:49:08.670686: Pseudo dice [0.9786] 
2025-07-13 02:49:08.671014: Epoch time: 141.92 s 
2025-07-13 02:49:11.027579:  
2025-07-13 02:49:11.028585: Epoch 929 
2025-07-13 02:49:11.028948: Current learning rate: 0.00092 
2025-07-13 02:51:33.983363: train_loss -0.8026 
2025-07-13 02:51:33.984644: val_loss -0.8109 
2025-07-13 02:51:33.984786: Pseudo dice [0.9784] 
2025-07-13 02:51:33.984956: Epoch time: 142.96 s 
2025-07-13 02:51:36.085777:  
2025-07-13 02:51:36.087036: Epoch 930 
2025-07-13 02:51:36.087522: Current learning rate: 0.00091 
2025-07-13 02:53:59.170676: train_loss -0.8027 
2025-07-13 02:53:59.171925: val_loss -0.8244 
2025-07-13 02:53:59.172018: Pseudo dice [0.9792] 
2025-07-13 02:53:59.172118: Epoch time: 143.09 s 
2025-07-13 02:53:59.172165: Yayy! New best EMA pseudo Dice: 0.9784 
2025-07-13 02:54:02.977228:  
2025-07-13 02:54:02.977886: Epoch 931 
2025-07-13 02:54:02.978192: Current learning rate: 0.0009 
2025-07-13 02:56:25.784801: train_loss -0.8174 
2025-07-13 02:56:25.786420: val_loss -0.8501 
2025-07-13 02:56:25.786724: Pseudo dice [0.979] 
2025-07-13 02:56:25.786963: Epoch time: 142.81 s 
2025-07-13 02:56:25.787169: Yayy! New best EMA pseudo Dice: 0.9784 
2025-07-13 02:56:28.702330:  
2025-07-13 02:56:28.702840: Epoch 932 
2025-07-13 02:56:28.703077: Current learning rate: 0.00089 
2025-07-13 02:58:49.168763: train_loss -0.8147 
2025-07-13 02:58:49.169736: val_loss -0.8319 
2025-07-13 02:58:49.169804: Pseudo dice [0.9801] 
2025-07-13 02:58:49.169899: Epoch time: 140.47 s 
2025-07-13 02:58:49.169944: Yayy! New best EMA pseudo Dice: 0.9786 
2025-07-13 02:58:52.235070:  
2025-07-13 02:58:52.235534: Epoch 933 
2025-07-13 02:58:52.235658: Current learning rate: 0.00088 
2025-07-13 03:01:17.047405: train_loss -0.7964 
2025-07-13 03:01:17.048711: val_loss -0.8502 
2025-07-13 03:01:17.048826: Pseudo dice [0.9781] 
2025-07-13 03:01:17.048962: Epoch time: 144.81 s 
2025-07-13 03:01:18.492442:  
2025-07-13 03:01:18.492783: Epoch 934 
2025-07-13 03:01:18.492945: Current learning rate: 0.00087 
2025-07-13 03:03:42.578943: train_loss -0.7957 
2025-07-13 03:03:42.581442: val_loss -0.8256 
2025-07-13 03:03:42.582312: Pseudo dice [0.9783] 
2025-07-13 03:03:42.582728: Epoch time: 144.09 s 
2025-07-13 03:03:44.358531:  
2025-07-13 03:03:44.359599: Epoch 935 
2025-07-13 03:03:44.360199: Current learning rate: 0.00085 
2025-07-13 03:06:06.397678: train_loss -0.8129 
2025-07-13 03:06:06.399186: val_loss -0.8316 
2025-07-13 03:06:06.399301: Pseudo dice [0.9798] 
2025-07-13 03:06:06.399376: Epoch time: 142.04 s 
2025-07-13 03:06:06.399419: Yayy! New best EMA pseudo Dice: 0.9786 
2025-07-13 03:06:08.726195:  
2025-07-13 03:06:08.726574: Epoch 936 
2025-07-13 03:06:08.726705: Current learning rate: 0.00084 
2025-07-13 03:08:28.410677: train_loss -0.8141 
2025-07-13 03:08:28.412163: val_loss -0.8438 
2025-07-13 03:08:28.412462: Pseudo dice [0.9781] 
2025-07-13 03:08:28.412705: Epoch time: 139.69 s 
2025-07-13 03:08:30.069665:  
2025-07-13 03:08:30.070465: Epoch 937 
2025-07-13 03:08:30.070817: Current learning rate: 0.00083 
2025-07-13 03:10:50.198647: train_loss -0.8218 
2025-07-13 03:10:50.200753: val_loss -0.8113 
2025-07-13 03:10:50.200843: Pseudo dice [0.9775] 
2025-07-13 03:10:50.200981: Epoch time: 140.13 s 
2025-07-13 03:10:52.086233:  
2025-07-13 03:10:52.087629: Epoch 938 
2025-07-13 03:10:52.088140: Current learning rate: 0.00082 
2025-07-13 03:13:15.677319: train_loss -0.8039 
2025-07-13 03:13:15.678758: val_loss -0.8248 
2025-07-13 03:13:15.678887: Pseudo dice [0.978] 
2025-07-13 03:13:15.679043: Epoch time: 143.59 s 
2025-07-13 03:13:17.547435:  
2025-07-13 03:13:17.548723: Epoch 939 
2025-07-13 03:13:17.549138: Current learning rate: 0.00081 
2025-07-13 03:15:36.159270: train_loss -0.8073 
2025-07-13 03:15:36.160233: val_loss -0.8358 
2025-07-13 03:15:36.160364: Pseudo dice [0.9796] 
2025-07-13 03:15:36.160473: Epoch time: 138.61 s 
2025-07-13 03:15:38.118427:  
2025-07-13 03:15:38.119726: Epoch 940 
2025-07-13 03:15:38.120211: Current learning rate: 0.00079 
2025-07-13 03:18:03.983998: train_loss -0.8047 
2025-07-13 03:18:03.985157: val_loss -0.8228 
2025-07-13 03:18:03.985248: Pseudo dice [0.979] 
2025-07-13 03:18:03.985338: Epoch time: 145.87 s 
2025-07-13 03:18:05.774632:  
2025-07-13 03:18:05.776782: Epoch 941 
2025-07-13 03:18:05.777523: Current learning rate: 0.00078 
2025-07-13 03:20:36.889000: train_loss -0.8147 
2025-07-13 03:20:36.890312: val_loss -0.7957 
2025-07-13 03:20:36.890438: Pseudo dice [0.9806] 
2025-07-13 03:20:36.890579: Epoch time: 151.12 s 
2025-07-13 03:20:36.890641: Yayy! New best EMA pseudo Dice: 0.9788 
2025-07-13 03:20:39.787928:  
2025-07-13 03:20:39.788494: Epoch 942 
2025-07-13 03:20:39.788657: Current learning rate: 0.00077 
2025-07-13 03:22:58.882283: train_loss -0.8062 
2025-07-13 03:22:58.883466: val_loss -0.8684 
2025-07-13 03:22:58.883542: Pseudo dice [0.9794] 
2025-07-13 03:22:58.883666: Epoch time: 139.1 s 
2025-07-13 03:22:58.883796: Yayy! New best EMA pseudo Dice: 0.9789 
2025-07-13 03:23:02.697385:  
2025-07-13 03:23:02.698262: Epoch 943 
2025-07-13 03:23:02.698647: Current learning rate: 0.00076 
2025-07-13 03:25:24.249655: train_loss -0.8026 
2025-07-13 03:25:24.250560: val_loss -0.8266 
2025-07-13 03:25:24.250630: Pseudo dice [0.9802] 
2025-07-13 03:25:24.250696: Epoch time: 141.55 s 
2025-07-13 03:25:24.250744: Yayy! New best EMA pseudo Dice: 0.979 
2025-07-13 03:25:27.485821:  
2025-07-13 03:25:27.486428: Epoch 944 
2025-07-13 03:25:27.486599: Current learning rate: 0.00075 
2025-07-13 03:27:51.571149: train_loss -0.8052 
2025-07-13 03:27:51.572593: val_loss -0.8616 
2025-07-13 03:27:51.572765: Pseudo dice [0.9795] 
2025-07-13 03:27:51.572912: Epoch time: 144.09 s 
2025-07-13 03:27:51.573007: Yayy! New best EMA pseudo Dice: 0.979 
2025-07-13 03:27:54.739993:  
2025-07-13 03:27:54.740442: Epoch 945 
2025-07-13 03:27:54.740554: Current learning rate: 0.00074 
2025-07-13 03:30:13.791985: train_loss -0.7922 
2025-07-13 03:30:13.793432: val_loss -0.8147 
2025-07-13 03:30:13.793684: Pseudo dice [0.9788] 
2025-07-13 03:30:13.793879: Epoch time: 139.05 s 
2025-07-13 03:30:15.937340:  
2025-07-13 03:30:15.938429: Epoch 946 
2025-07-13 03:30:15.938792: Current learning rate: 0.00072 
2025-07-13 03:32:38.561428: train_loss -0.8102 
2025-07-13 03:32:38.562540: val_loss -0.8547 
2025-07-13 03:32:38.562643: Pseudo dice [0.9807] 
2025-07-13 03:32:38.562742: Epoch time: 142.63 s 
2025-07-13 03:32:38.562788: Yayy! New best EMA pseudo Dice: 0.9792 
2025-07-13 03:32:41.968086:  
2025-07-13 03:32:41.969331: Epoch 947 
2025-07-13 03:32:41.969736: Current learning rate: 0.00071 
2025-07-13 03:35:08.557011: train_loss -0.8064 
2025-07-13 03:35:08.558000: val_loss -0.8288 
2025-07-13 03:35:08.558078: Pseudo dice [0.9788] 
2025-07-13 03:35:08.558171: Epoch time: 146.59 s 
2025-07-13 03:35:10.331950:  
2025-07-13 03:35:10.332782: Epoch 948 
2025-07-13 03:35:10.333105: Current learning rate: 0.0007 
2025-07-13 03:37:32.011542: train_loss -0.8008 
2025-07-13 03:37:32.012933: val_loss -0.8506 
2025-07-13 03:37:32.013160: Pseudo dice [0.9811] 
2025-07-13 03:37:32.013357: Epoch time: 141.68 s 
2025-07-13 03:37:32.013481: Yayy! New best EMA pseudo Dice: 0.9793 
2025-07-13 03:37:35.563455:  
2025-07-13 03:37:35.564186: Epoch 949 
2025-07-13 03:37:35.564498: Current learning rate: 0.00069 
2025-07-13 03:39:55.684513: train_loss -0.8008 
2025-07-13 03:39:55.686297: val_loss -0.8411 
2025-07-13 03:39:55.686562: Pseudo dice [0.9794] 
2025-07-13 03:39:55.686782: Epoch time: 140.12 s 
2025-07-13 03:39:57.751389: Yayy! New best EMA pseudo Dice: 0.9793 
2025-07-13 03:40:00.295173:  
2025-07-13 03:40:00.295530: Epoch 950 
2025-07-13 03:40:00.295650: Current learning rate: 0.00067 
2025-07-13 03:42:22.702149: train_loss -0.8138 
2025-07-13 03:42:22.707138: val_loss -0.8529 
2025-07-13 03:42:22.711310: Pseudo dice [0.9799] 
2025-07-13 03:42:22.711555: Epoch time: 142.41 s 
2025-07-13 03:42:22.711642: Yayy! New best EMA pseudo Dice: 0.9794 
2025-07-13 03:42:25.890984:  
2025-07-13 03:42:25.891380: Epoch 951 
2025-07-13 03:42:25.891495: Current learning rate: 0.00066 
2025-07-13 03:44:47.402882: train_loss -0.796 
2025-07-13 03:44:47.404195: val_loss -0.8079 
2025-07-13 03:44:47.404300: Pseudo dice [0.9792] 
2025-07-13 03:44:47.404417: Epoch time: 141.51 s 
2025-07-13 03:44:49.253455:  
2025-07-13 03:44:49.254430: Epoch 952 
2025-07-13 03:44:49.254817: Current learning rate: 0.00065 
2025-07-13 03:47:13.302769: train_loss -0.8058 
2025-07-13 03:47:13.303742: val_loss -0.8182 
2025-07-13 03:47:13.303851: Pseudo dice [0.9799] 
2025-07-13 03:47:13.303960: Epoch time: 144.05 s 
2025-07-13 03:47:13.304020: Yayy! New best EMA pseudo Dice: 0.9794 
2025-07-13 03:47:16.752471:  
2025-07-13 03:47:16.752969: Epoch 953 
2025-07-13 03:47:16.753159: Current learning rate: 0.00064 
2025-07-13 03:49:38.915799: train_loss -0.8012 
2025-07-13 03:49:38.917519: val_loss -0.8168 
2025-07-13 03:49:38.917720: Pseudo dice [0.9787] 
2025-07-13 03:49:38.917929: Epoch time: 142.16 s 
2025-07-13 03:49:40.871884:  
2025-07-13 03:49:40.872920: Epoch 954 
2025-07-13 03:49:40.873364: Current learning rate: 0.00063 
2025-07-13 03:52:09.090132: train_loss -0.8045 
2025-07-13 03:52:09.091143: val_loss -0.8258 
2025-07-13 03:52:09.091218: Pseudo dice [0.9797] 
2025-07-13 03:52:09.091358: Epoch time: 148.22 s 
2025-07-13 03:52:10.966793:  
2025-07-13 03:52:10.967515: Epoch 955 
2025-07-13 03:52:10.967817: Current learning rate: 0.00061 
2025-07-13 03:54:31.323821: train_loss -0.8244 
2025-07-13 03:54:31.325037: val_loss -0.798 
2025-07-13 03:54:31.325113: Pseudo dice [0.9781] 
2025-07-13 03:54:31.325228: Epoch time: 140.36 s 
2025-07-13 03:54:37.112576:  
2025-07-13 03:54:37.113050: Epoch 956 
2025-07-13 03:54:37.113199: Current learning rate: 0.0006 
2025-07-13 03:57:00.429139: train_loss -0.8152 
2025-07-13 03:57:00.430441: val_loss -0.8161 
2025-07-13 03:57:00.430584: Pseudo dice [0.9786] 
2025-07-13 03:57:00.430717: Epoch time: 143.32 s 
2025-07-13 03:57:02.302690:  
2025-07-13 03:57:02.303808: Epoch 957 
2025-07-13 03:57:02.304150: Current learning rate: 0.00059 
2025-07-13 03:59:28.927376: train_loss -0.8228 
2025-07-13 03:59:28.939719: val_loss -0.8138 
2025-07-13 03:59:28.940309: Pseudo dice [0.9814] 
2025-07-13 03:59:28.940571: Epoch time: 146.63 s 
2025-07-13 03:59:30.585768:  
2025-07-13 03:59:30.586605: Epoch 958 
2025-07-13 03:59:30.586960: Current learning rate: 0.00058 
2025-07-13 04:01:54.393779: train_loss -0.8051 
2025-07-13 04:01:54.395097: val_loss -0.8299 
2025-07-13 04:01:54.395242: Pseudo dice [0.9785] 
2025-07-13 04:01:54.395439: Epoch time: 143.81 s 
2025-07-13 04:01:56.336920:  
2025-07-13 04:01:56.337717: Epoch 959 
2025-07-13 04:01:56.337951: Current learning rate: 0.00056 
2025-07-13 04:04:19.635165: train_loss -0.8007 
2025-07-13 04:04:19.636868: val_loss -0.8068 
2025-07-13 04:04:19.637107: Pseudo dice [0.9802] 
2025-07-13 04:04:19.637280: Epoch time: 143.3 s 
2025-07-13 04:04:21.175942:  
2025-07-13 04:04:21.176459: Epoch 960 
2025-07-13 04:04:21.176672: Current learning rate: 0.00055 
2025-07-13 04:06:42.908670: train_loss -0.8082 
2025-07-13 04:06:42.909929: val_loss -0.8281 
2025-07-13 04:06:42.910062: Pseudo dice [0.9798] 
2025-07-13 04:06:42.910177: Epoch time: 141.73 s 
2025-07-13 04:06:42.910236: Yayy! New best EMA pseudo Dice: 0.9795 
2025-07-13 04:06:46.005944:  
2025-07-13 04:06:46.006407: Epoch 961 
2025-07-13 04:06:46.006592: Current learning rate: 0.00054 
2025-07-13 04:09:08.046491: train_loss -0.8009 
2025-07-13 04:09:08.047406: val_loss -0.8346 
2025-07-13 04:09:08.047480: Pseudo dice [0.9788] 
2025-07-13 04:09:08.047567: Epoch time: 142.04 s 
2025-07-13 04:09:09.517694:  
2025-07-13 04:09:09.518376: Epoch 962 
2025-07-13 04:09:09.518625: Current learning rate: 0.00053 
2025-07-13 04:11:32.675642: train_loss -0.8022 
2025-07-13 04:11:32.676735: val_loss -0.8166 
2025-07-13 04:11:32.676860: Pseudo dice [0.9787] 
2025-07-13 04:11:32.677086: Epoch time: 143.16 s 
2025-07-13 04:11:34.557739:  
2025-07-13 04:11:34.558992: Epoch 963 
2025-07-13 04:11:34.559419: Current learning rate: 0.00051 
2025-07-13 04:13:58.956511: train_loss -0.8055 
2025-07-13 04:13:58.965785: val_loss -0.8327 
2025-07-13 04:13:58.966134: Pseudo dice [0.9803] 
2025-07-13 04:13:58.966259: Epoch time: 144.4 s 
2025-07-13 04:14:01.351890:  
2025-07-13 04:14:01.352893: Epoch 964 
2025-07-13 04:14:01.353273: Current learning rate: 0.0005 
2025-07-13 04:16:25.815172: train_loss -0.8095 
2025-07-13 04:16:25.816764: val_loss -0.8152 
2025-07-13 04:16:25.816960: Pseudo dice [0.9819] 
2025-07-13 04:16:25.817116: Epoch time: 144.47 s 
2025-07-13 04:16:25.817242: Yayy! New best EMA pseudo Dice: 0.9797 
2025-07-13 04:16:29.583108:  
2025-07-13 04:16:29.583940: Epoch 965 
2025-07-13 04:16:29.584255: Current learning rate: 0.00049 
2025-07-13 04:18:52.550388: train_loss -0.8069 
2025-07-13 04:18:52.551449: val_loss -0.7994 
2025-07-13 04:18:52.551522: Pseudo dice [0.9799] 
2025-07-13 04:18:52.551633: Epoch time: 142.97 s 
2025-07-13 04:18:52.555812: Yayy! New best EMA pseudo Dice: 0.9797 
2025-07-13 04:18:56.303346:  
2025-07-13 04:18:56.304423: Epoch 966 
2025-07-13 04:18:56.304810: Current learning rate: 0.00048 
2025-07-13 04:21:21.629128: train_loss -0.8145 
2025-07-13 04:21:21.630655: val_loss -0.8516 
2025-07-13 04:21:21.630875: Pseudo dice [0.9809] 
2025-07-13 04:21:21.630976: Epoch time: 145.33 s 
2025-07-13 04:21:21.631033: Yayy! New best EMA pseudo Dice: 0.9798 
2025-07-13 04:21:24.370431:  
2025-07-13 04:21:24.370884: Epoch 967 
2025-07-13 04:21:24.371007: Current learning rate: 0.00046 
2025-07-13 04:23:46.266260: train_loss -0.7926 
2025-07-13 04:23:46.267589: val_loss -0.8183 
2025-07-13 04:23:46.267686: Pseudo dice [0.9765] 
2025-07-13 04:23:46.267779: Epoch time: 141.9 s 
2025-07-13 04:23:47.968655:  
2025-07-13 04:23:47.969735: Epoch 968 
2025-07-13 04:23:47.970155: Current learning rate: 0.00045 
2025-07-13 04:26:10.002365: train_loss -0.8071 
2025-07-13 04:26:10.003747: val_loss -0.7865 
2025-07-13 04:26:10.003857: Pseudo dice [0.9805] 
2025-07-13 04:26:10.003991: Epoch time: 142.04 s 
2025-07-13 04:26:12.055048:  
2025-07-13 04:26:12.056075: Epoch 969 
2025-07-13 04:26:12.056465: Current learning rate: 0.00044 
2025-07-13 04:28:38.082596: train_loss -0.8028 
2025-07-13 04:28:38.084396: val_loss -0.8326 
2025-07-13 04:28:38.084598: Pseudo dice [0.9799] 
2025-07-13 04:28:38.084745: Epoch time: 146.03 s 
2025-07-13 04:28:39.931611:  
2025-07-13 04:28:39.932459: Epoch 970 
2025-07-13 04:28:39.932779: Current learning rate: 0.00043 
2025-07-13 04:31:02.308464: train_loss -0.8002 
2025-07-13 04:31:02.309380: val_loss -0.8468 
2025-07-13 04:31:02.309712: Pseudo dice [0.9803] 
2025-07-13 04:31:02.309817: Epoch time: 142.38 s 
2025-07-13 04:31:03.803894:  
2025-07-13 04:31:03.804402: Epoch 971 
2025-07-13 04:31:03.804592: Current learning rate: 0.00041 
2025-07-13 04:33:22.546750: train_loss -0.8037 
2025-07-13 04:33:22.549709: val_loss -0.8062 
2025-07-13 04:33:22.550965: Pseudo dice [0.9808] 
2025-07-13 04:33:22.551369: Epoch time: 138.74 s 
2025-07-13 04:33:24.560677:  
2025-07-13 04:33:24.561615: Epoch 972 
2025-07-13 04:33:24.561981: Current learning rate: 0.0004 
2025-07-13 04:35:49.136797: train_loss -0.8013 
2025-07-13 04:35:49.138235: val_loss -0.8384 
2025-07-13 04:35:49.138355: Pseudo dice [0.9812] 
2025-07-13 04:35:49.138445: Epoch time: 144.58 s 
2025-07-13 04:35:49.138484: Yayy! New best EMA pseudo Dice: 0.9799 
2025-07-13 04:35:51.897317:  
2025-07-13 04:35:51.897819: Epoch 973 
2025-07-13 04:35:51.898079: Current learning rate: 0.00039 
2025-07-13 04:38:13.152035: train_loss -0.814 
2025-07-13 04:38:13.153034: val_loss -0.8244 
2025-07-13 04:38:13.153113: Pseudo dice [0.9809] 
2025-07-13 04:38:13.153208: Epoch time: 141.26 s 
2025-07-13 04:38:13.153271: Yayy! New best EMA pseudo Dice: 0.98 
2025-07-13 04:38:16.381583:  
2025-07-13 04:38:16.382116: Epoch 974 
2025-07-13 04:38:16.382326: Current learning rate: 0.00037 
2025-07-13 04:40:39.016584: train_loss -0.7952 
2025-07-13 04:40:39.018027: val_loss -0.8401 
2025-07-13 04:40:39.018125: Pseudo dice [0.9805] 
2025-07-13 04:40:39.018229: Epoch time: 142.64 s 
2025-07-13 04:40:39.018306: Yayy! New best EMA pseudo Dice: 0.9801 
2025-07-13 04:40:42.570978:  
2025-07-13 04:40:42.571450: Epoch 975 
2025-07-13 04:40:42.571572: Current learning rate: 0.00036 
2025-07-13 04:43:03.425542: train_loss -0.8053 
2025-07-13 04:43:03.426932: val_loss -0.837 
2025-07-13 04:43:03.427246: Pseudo dice [0.9821] 
2025-07-13 04:43:03.427408: Epoch time: 140.86 s 
2025-07-13 04:43:03.427472: Yayy! New best EMA pseudo Dice: 0.9803 
2025-07-13 04:43:08.402622:  
2025-07-13 04:43:08.402963: Epoch 976 
2025-07-13 04:43:08.403038: Current learning rate: 0.00035 
2025-07-13 04:45:27.969642: train_loss -0.8145 
2025-07-13 04:45:27.971397: val_loss -0.8156 
2025-07-13 04:45:27.971548: Pseudo dice [0.9804] 
2025-07-13 04:45:27.971674: Epoch time: 139.57 s 
2025-07-13 04:45:27.971756: Yayy! New best EMA pseudo Dice: 0.9803 
2025-07-13 04:45:31.489674:  
2025-07-13 04:45:31.490023: Epoch 977 
2025-07-13 04:45:31.490187: Current learning rate: 0.00034 
2025-07-13 04:47:54.131461: train_loss -0.8155 
2025-07-13 04:47:54.132967: val_loss -0.8561 
2025-07-13 04:47:54.133243: Pseudo dice [0.9796] 
2025-07-13 04:47:54.133558: Epoch time: 142.64 s 
2025-07-13 04:47:55.977126:  
2025-07-13 04:47:55.978053: Epoch 978 
2025-07-13 04:47:55.978504: Current learning rate: 0.00032 
2025-07-13 04:50:19.268687: train_loss -0.8221 
2025-07-13 04:50:19.269890: val_loss -0.8083 
2025-07-13 04:50:19.270001: Pseudo dice [0.9805] 
2025-07-13 04:50:19.270117: Epoch time: 143.29 s 
2025-07-13 04:50:21.540807:  
2025-07-13 04:50:21.541948: Epoch 979 
2025-07-13 04:50:21.542404: Current learning rate: 0.00031 
2025-07-13 04:52:48.937988: train_loss -0.8161 
2025-07-13 04:52:48.939346: val_loss -0.8608 
2025-07-13 04:52:48.939490: Pseudo dice [0.9793] 
2025-07-13 04:52:48.939598: Epoch time: 147.4 s 
2025-07-13 04:52:50.896376:  
2025-07-13 04:52:50.897647: Epoch 980 
2025-07-13 04:52:50.898155: Current learning rate: 0.0003 
2025-07-13 04:55:18.528728: train_loss -0.8011 
2025-07-13 04:55:18.530174: val_loss -0.8208 
2025-07-13 04:55:18.530394: Pseudo dice [0.9808] 
2025-07-13 04:55:18.530539: Epoch time: 147.63 s 
2025-07-13 04:55:20.282995:  
2025-07-13 04:55:20.284197: Epoch 981 
2025-07-13 04:55:20.284574: Current learning rate: 0.00028 
2025-07-13 04:57:44.695024: train_loss -0.8054 
2025-07-13 04:57:44.696363: val_loss -0.82 
2025-07-13 04:57:44.696449: Pseudo dice [0.9798] 
2025-07-13 04:57:44.696558: Epoch time: 144.41 s 
2025-07-13 04:57:46.458601:  
2025-07-13 04:57:46.459074: Epoch 982 
2025-07-13 04:57:46.459190: Current learning rate: 0.00027 
2025-07-13 05:00:06.398903: train_loss -0.8136 
2025-07-13 05:00:06.400668: val_loss -0.8291 
2025-07-13 05:00:06.400915: Pseudo dice [0.9806] 
2025-07-13 05:00:06.401185: Epoch time: 139.94 s 
2025-07-13 05:00:08.380093:  
2025-07-13 05:00:08.381183: Epoch 983 
2025-07-13 05:00:08.381625: Current learning rate: 0.00026 
2025-07-13 05:02:31.562915: train_loss -0.8083 
2025-07-13 05:02:31.564140: val_loss -0.8534 
2025-07-13 05:02:31.564237: Pseudo dice [0.9806] 
2025-07-13 05:02:31.564372: Epoch time: 143.18 s 
2025-07-13 05:02:33.381426:  
2025-07-13 05:02:33.382411: Epoch 984 
2025-07-13 05:02:33.382794: Current learning rate: 0.00024 
2025-07-13 05:04:55.600664: train_loss -0.7989 
2025-07-13 05:04:55.602121: val_loss -0.8367 
2025-07-13 05:04:55.602350: Pseudo dice [0.9813] 
2025-07-13 05:04:55.602524: Epoch time: 142.22 s 
2025-07-13 05:04:55.602604: Yayy! New best EMA pseudo Dice: 0.9804 
2025-07-13 05:04:59.417320:  
2025-07-13 05:04:59.418471: Epoch 985 
2025-07-13 05:04:59.418878: Current learning rate: 0.00023 
2025-07-13 05:07:22.469979: train_loss -0.8128 
2025-07-13 05:07:22.470949: val_loss -0.8518 
2025-07-13 05:07:22.471033: Pseudo dice [0.9815] 
2025-07-13 05:07:22.471119: Epoch time: 143.05 s 
2025-07-13 05:07:22.471165: Yayy! New best EMA pseudo Dice: 0.9805 
2025-07-13 05:07:24.975000:  
2025-07-13 05:07:24.975438: Epoch 986 
2025-07-13 05:07:24.975585: Current learning rate: 0.00021 
2025-07-13 05:09:48.459524: train_loss -0.8109 
2025-07-13 05:09:48.462033: val_loss -0.8316 
2025-07-13 05:09:48.463404: Pseudo dice [0.9803] 
2025-07-13 05:09:48.463763: Epoch time: 143.48 s 
2025-07-13 05:09:50.645194:  
2025-07-13 05:09:50.646437: Epoch 987 
2025-07-13 05:09:50.646868: Current learning rate: 0.0002 
2025-07-13 05:12:09.486404: train_loss -0.8103 
2025-07-13 05:12:09.487486: val_loss -0.8067 
2025-07-13 05:12:09.487571: Pseudo dice [0.9815] 
2025-07-13 05:12:09.487664: Epoch time: 138.84 s 
2025-07-13 05:12:09.487718: Yayy! New best EMA pseudo Dice: 0.9806 
2025-07-13 05:12:12.394483:  
2025-07-13 05:12:12.394920: Epoch 988 
2025-07-13 05:12:12.395034: Current learning rate: 0.00019 
2025-07-13 05:14:36.713351: train_loss -0.816 
2025-07-13 05:14:36.714450: val_loss -0.8477 
2025-07-13 05:14:36.714539: Pseudo dice [0.9804] 
2025-07-13 05:14:36.714662: Epoch time: 144.32 s 
2025-07-13 05:14:38.496546:  
2025-07-13 05:14:38.497391: Epoch 989 
2025-07-13 05:14:38.497735: Current learning rate: 0.00017 
2025-07-13 05:17:01.688659: train_loss -0.803 
2025-07-13 05:17:01.690016: val_loss -0.8257 
2025-07-13 05:17:01.690128: Pseudo dice [0.9813] 
2025-07-13 05:17:01.690336: Epoch time: 143.19 s 
2025-07-13 05:17:01.690419: Yayy! New best EMA pseudo Dice: 0.9806 
2025-07-13 05:17:05.221806:  
2025-07-13 05:17:05.222616: Epoch 990 
2025-07-13 05:17:05.222921: Current learning rate: 0.00016 
2025-07-13 05:19:25.296908: train_loss -0.8071 
2025-07-13 05:19:25.298084: val_loss -0.8443 
2025-07-13 05:19:25.298194: Pseudo dice [0.9813] 
2025-07-13 05:19:25.298299: Epoch time: 140.08 s 
2025-07-13 05:19:25.298347: Yayy! New best EMA pseudo Dice: 0.9807 
2025-07-13 05:19:28.633762:  
2025-07-13 05:19:28.634155: Epoch 991 
2025-07-13 05:19:28.634300: Current learning rate: 0.00014 
2025-07-13 05:21:54.757665: train_loss -0.81 
2025-07-13 05:21:54.758933: val_loss -0.8244 
2025-07-13 05:21:54.759028: Pseudo dice [0.9798] 
2025-07-13 05:21:54.759132: Epoch time: 146.12 s 
2025-07-13 05:21:56.620338:  
2025-07-13 05:21:56.620972: Epoch 992 
2025-07-13 05:21:56.621344: Current learning rate: 0.00013 
2025-07-13 05:24:21.661648: train_loss -0.8021 
2025-07-13 05:24:21.662918: val_loss -0.8013 
2025-07-13 05:24:21.663080: Pseudo dice [0.9815] 
2025-07-13 05:24:21.663244: Epoch time: 145.04 s 
2025-07-13 05:24:21.663348: Yayy! New best EMA pseudo Dice: 0.9807 
2025-07-13 05:24:24.861307:  
2025-07-13 05:24:24.861802: Epoch 993 
2025-07-13 05:24:24.861990: Current learning rate: 0.00011 
2025-07-13 05:26:49.170531: train_loss -0.8182 
2025-07-13 05:26:49.172578: val_loss -0.8211 
2025-07-13 05:26:49.172867: Pseudo dice [0.9813] 
2025-07-13 05:26:49.173148: Epoch time: 144.31 s 
2025-07-13 05:26:49.173322: Yayy! New best EMA pseudo Dice: 0.9807 
2025-07-13 05:26:52.342973:  
2025-07-13 05:26:52.343511: Epoch 994 
2025-07-13 05:26:52.343721: Current learning rate: 0.0001 
2025-07-13 05:29:14.133026: train_loss -0.819 
2025-07-13 05:29:14.133852: val_loss -0.8605 
2025-07-13 05:29:14.133932: Pseudo dice [0.9812] 
2025-07-13 05:29:14.134024: Epoch time: 141.79 s 
2025-07-13 05:29:14.134070: Yayy! New best EMA pseudo Dice: 0.9808 
2025-07-13 05:29:18.250710:  
2025-07-13 05:29:18.251099: Epoch 995 
2025-07-13 05:29:18.251172: Current learning rate: 8e-05 
2025-07-13 05:31:39.888719: train_loss -0.8174 
2025-07-13 05:31:39.890452: val_loss -0.804 
2025-07-13 05:31:39.890709: Pseudo dice [0.9814] 
2025-07-13 05:31:39.890923: Epoch time: 141.64 s 
2025-07-13 05:31:39.891046: Yayy! New best EMA pseudo Dice: 0.9809 
2025-07-13 05:31:43.281503:  
2025-07-13 05:31:43.282136: Epoch 996 
2025-07-13 05:31:43.282511: Current learning rate: 7e-05 
2025-07-13 05:34:06.842126: train_loss -0.8128 
2025-07-13 05:34:06.843805: val_loss -0.825 
2025-07-13 05:34:06.844059: Pseudo dice [0.9804] 
2025-07-13 05:34:06.844258: Epoch time: 143.56 s 
2025-07-13 05:34:08.837931:  
2025-07-13 05:34:08.839165: Epoch 997 
2025-07-13 05:34:08.839570: Current learning rate: 5e-05 
2025-07-13 05:36:32.711051: train_loss -0.799 
2025-07-13 05:36:32.713581: val_loss -0.8121 
2025-07-13 05:36:32.713891: Pseudo dice [0.9812] 
2025-07-13 05:36:32.714187: Epoch time: 143.88 s 
2025-07-13 05:36:34.465136:  
2025-07-13 05:36:34.466048: Epoch 998 
2025-07-13 05:36:34.466316: Current learning rate: 4e-05 
2025-07-13 05:38:56.382903: train_loss -0.8076 
2025-07-13 05:38:56.384407: val_loss -0.8375 
2025-07-13 05:38:56.384491: Pseudo dice [0.9817] 
2025-07-13 05:38:56.384577: Epoch time: 141.92 s 
2025-07-13 05:38:56.384622: Yayy! New best EMA pseudo Dice: 0.9809 
2025-07-13 05:38:59.406851:  
2025-07-13 05:38:59.407650: Epoch 999 
2025-07-13 05:38:59.407915: Current learning rate: 2e-05 
2025-07-13 05:41:22.896165: train_loss -0.8107 
2025-07-13 05:41:22.897370: val_loss -0.8171 
2025-07-13 05:41:22.897516: Pseudo dice [0.9813] 
2025-07-13 05:41:22.897640: Epoch time: 143.49 s 
2025-07-13 05:41:22.897711: Yayy! New best EMA pseudo Dice: 0.981 
2025-07-13 05:41:25.308255: Training done. 
2025-07-13 05:41:25.961709: Using splits from existing split file: /home/finds/Finds_share/nnUNet_environment/nnUNet_preprocessed/Dataset999_drl/splits_final.json 
2025-07-13 05:41:25.963345: The split file contains 5 splits. 
2025-07-13 05:41:25.963428: Desired fold for training: 4 
2025-07-13 05:41:25.963450: This split has 746 training and 186 validation cases. 
2025-07-13 05:41:25.965091: predicting FINDS_0005 
2025-07-13 05:41:25.968095: FINDS_0005, shape torch.Size([1, 563, 183, 116]), rank 0 
2025-07-13 05:41:41.539890: predicting FINDS_0029 
2025-07-13 05:41:41.541702: FINDS_0029, shape torch.Size([1, 693, 161, 133]), rank 0 
2025-07-13 05:41:46.050093: predicting FINDS_0034 
2025-07-13 05:41:46.052362: FINDS_0034, shape torch.Size([1, 642, 163, 119]), rank 0 
2025-07-13 05:41:49.061193: predicting FINDS_0043 
2025-07-13 05:41:49.063305: FINDS_0043, shape torch.Size([1, 748, 181, 133]), rank 0 
2025-07-13 05:41:55.868801: predicting FINDS_0059 
2025-07-13 05:41:55.871332: FINDS_0059, shape torch.Size([1, 399, 147, 128]), rank 0 
2025-07-13 05:41:58.617193: predicting FINDS_0069 
2025-07-13 05:41:58.619595: FINDS_0069, shape torch.Size([1, 453, 149, 116]), rank 0 
2025-07-13 05:42:00.450718: predicting FINDS_0076 
2025-07-13 05:42:00.453584: FINDS_0076, shape torch.Size([1, 565, 156, 114]), rank 0 
2025-07-13 05:42:02.911741: predicting FINDS_0078 
2025-07-13 05:42:02.914500: FINDS_0078, shape torch.Size([1, 565, 156, 114]), rank 0 
2025-07-13 05:42:05.381884: predicting FINDS_0083 
2025-07-13 05:42:05.384305: FINDS_0083, shape torch.Size([1, 589, 182, 108]), rank 0 
2025-07-13 05:42:09.093716: predicting FINDS_0091 
2025-07-13 05:42:09.096099: FINDS_0091, shape torch.Size([1, 640, 195, 131]), rank 0 
2025-07-13 05:42:14.711720: predicting FINDS_0094 
2025-07-13 05:42:14.714358: FINDS_0094, shape torch.Size([1, 553, 167, 132]), rank 0 
2025-07-13 05:42:18.460001: predicting FINDS_0105 
2025-07-13 05:42:18.462797: FINDS_0105, shape torch.Size([1, 566, 139, 134]), rank 0 
2025-07-13 05:42:22.240164: predicting FINDS_0108 
2025-07-13 05:42:22.242511: FINDS_0108, shape torch.Size([1, 534, 135, 116]), rank 0 
2025-07-13 05:42:24.754151: predicting FINDS_0118 
2025-07-13 05:42:24.756406: FINDS_0118, shape torch.Size([1, 630, 168, 128]), rank 0 
2025-07-13 05:42:28.524826: predicting FINDS_0124 
2025-07-13 05:42:28.527015: FINDS_0124, shape torch.Size([1, 508, 237, 132]), rank 0 
2025-07-13 05:42:34.165230: predicting FINDS_0126 
2025-07-13 05:42:34.167919: FINDS_0126, shape torch.Size([1, 508, 237, 132]), rank 0 
2025-07-13 05:42:39.819007: predicting FINDS_0143 
2025-07-13 05:42:39.824756: FINDS_0143, shape torch.Size([1, 540, 188, 133]), rank 0 
2025-07-13 05:42:45.534329: predicting FINDS_0155 
2025-07-13 05:42:45.536796: FINDS_0155, shape torch.Size([1, 636, 148, 121]), rank 0 
2025-07-13 05:42:49.337418: predicting FINDS_0167 
2025-07-13 05:42:49.339763: FINDS_0167, shape torch.Size([1, 613, 220, 132]), rank 0 
2025-07-13 05:42:55.038065: predicting FINDS_0176 
2025-07-13 05:42:55.040474: FINDS_0176, shape torch.Size([1, 467, 147, 112]), rank 0 
2025-07-13 05:42:56.953851: predicting FINDS_0208 
2025-07-13 05:42:56.955273: FINDS_0208, shape torch.Size([1, 536, 201, 128]), rank 0 
2025-07-13 05:43:02.669854: predicting FINDS_0214 
2025-07-13 05:43:02.672840: FINDS_0214, shape torch.Size([1, 555, 149, 116]), rank 0 
2025-07-13 05:43:05.219570: predicting FINDS_0225 
2025-07-13 05:43:05.221197: FINDS_0225, shape torch.Size([1, 522, 125, 126]), rank 0 
2025-07-13 05:43:09.037989: predicting FINDS_0227 
2025-07-13 05:43:09.039952: FINDS_0227, shape torch.Size([1, 522, 125, 126]), rank 0 
2025-07-13 05:43:12.858717: predicting FINDS_0231 
2025-07-13 05:43:12.860986: FINDS_0231, shape torch.Size([1, 548, 140, 126]), rank 0 
2025-07-13 05:43:16.698692: predicting FINDS_0236 
2025-07-13 05:43:16.700941: FINDS_0236, shape torch.Size([1, 610, 164, 133]), rank 0 
2025-07-13 05:43:20.544167: predicting FINDS_0245 
2025-07-13 05:43:20.546394: FINDS_0245, shape torch.Size([1, 586, 146, 116]), rank 0 
2025-07-13 05:43:23.105509: predicting FINDS_0259 
2025-07-13 05:43:23.107625: FINDS_0259, shape torch.Size([1, 534, 156, 108]), rank 0 
2025-07-13 05:43:25.657070: predicting FINDS_0263 
2025-07-13 05:43:25.659126: FINDS_0263, shape torch.Size([1, 501, 175, 118]), rank 0 
2025-07-13 05:43:28.533534: predicting FINDS_0267 
2025-07-13 05:43:28.535976: FINDS_0267, shape torch.Size([1, 462, 210, 113]), rank 0 
2025-07-13 05:43:31.393864: predicting FINDS_0279 
2025-07-13 05:43:31.396030: FINDS_0279, shape torch.Size([1, 517, 168, 133]), rank 0 
2025-07-13 05:43:35.233880: predicting FINDS_0287 
2025-07-13 05:43:35.236552: FINDS_0287, shape torch.Size([1, 611, 142, 127]), rank 0 
2025-07-13 05:43:39.093292: predicting FINDS_0293 
2025-07-13 05:43:39.094930: FINDS_0293, shape torch.Size([1, 531, 116, 103]), rank 0 
2025-07-13 05:43:41.645375: predicting FINDS_0297 
2025-07-13 05:43:41.646742: FINDS_0297, shape torch.Size([1, 507, 151, 134]), rank 0 
2025-07-13 05:43:44.528265: predicting FINDS_0302 
2025-07-13 05:43:44.530470: FINDS_0302, shape torch.Size([1, 548, 187, 123]), rank 0 
2025-07-13 05:43:50.290068: predicting FINDS_0309 
2025-07-13 05:43:50.292623: FINDS_0309, shape torch.Size([1, 484, 214, 107]), rank 0 
2025-07-13 05:43:53.153488: predicting FINDS_0318 
2025-07-13 05:43:53.155603: FINDS_0318, shape torch.Size([1, 620, 169, 132]), rank 0 
2025-07-13 05:43:58.935566: predicting FINDS_0333 
2025-07-13 05:43:58.937786: FINDS_0333, shape torch.Size([1, 551, 151, 134]), rank 0 
2025-07-13 05:44:02.775852: predicting FINDS_0340 
2025-07-13 05:44:02.777462: FINDS_0340, shape torch.Size([1, 549, 159, 121]), rank 0 
2025-07-13 05:44:06.624775: predicting FINDS_0353 
2025-07-13 05:44:06.627182: FINDS_0353, shape torch.Size([1, 643, 120, 90]), rank 0 
2025-07-13 05:44:09.814695: predicting FINDS_0369 
2025-07-13 05:44:09.816084: FINDS_0369, shape torch.Size([1, 477, 138, 134]), rank 0 
2025-07-13 05:44:12.689323: predicting FINDS_0374 
2025-07-13 05:44:12.691300: FINDS_0374, shape torch.Size([1, 502, 158, 121]), rank 0 
2025-07-13 05:44:15.567782: predicting FINDS_0387 
2025-07-13 05:44:15.569798: FINDS_0387, shape torch.Size([1, 506, 182, 96]), rank 0 
2025-07-13 05:44:18.411431: predicting FINDS_0392 
2025-07-13 05:44:18.413378: FINDS_0392, shape torch.Size([1, 583, 143, 122]), rank 0 
2025-07-13 05:44:22.253980: predicting FINDS_0398 
2025-07-13 05:44:22.256384: FINDS_0398, shape torch.Size([1, 490, 168, 133]), rank 0 
2025-07-13 05:44:25.125782: predicting FINDS_0405 
2025-07-13 05:44:25.128277: FINDS_0405, shape torch.Size([1, 421, 123, 109]), rank 0 
2025-07-13 05:44:27.035472: predicting FINDS_0410 
2025-07-13 05:44:27.037310: FINDS_0410, shape torch.Size([1, 384, 114, 108]), rank 0 
2025-07-13 05:44:28.309200: predicting FINDS_0420 
2025-07-13 05:44:28.310930: FINDS_0420, shape torch.Size([1, 482, 140, 122]), rank 0 
2025-07-13 05:44:31.194041: predicting FINDS_0439 
2025-07-13 05:44:31.195988: FINDS_0439, shape torch.Size([1, 383, 133, 128]), rank 0 
2025-07-13 05:44:33.112158: predicting FINDS_0448 
2025-07-13 05:44:33.114267: FINDS_0448, shape torch.Size([1, 506, 122, 127]), rank 0 
2025-07-13 05:44:35.971422: predicting FINDS_0459 
2025-07-13 05:44:35.973628: FINDS_0459, shape torch.Size([1, 439, 120, 109]), rank 0 
2025-07-13 05:44:37.890246: predicting FINDS_0482 
2025-07-13 05:44:37.891585: FINDS_0482, shape torch.Size([1, 367, 131, 134]), rank 0 
2025-07-13 05:44:39.799402: predicting FINDS_0492 
2025-07-13 05:44:39.801772: FINDS_0492, shape torch.Size([1, 419, 160, 112]), rank 0 
2025-07-13 05:44:41.703748: predicting FINDS_0512 
2025-07-13 05:44:41.705924: FINDS_0512, shape torch.Size([1, 395, 100, 96]), rank 0 
2025-07-13 05:44:42.664983: predicting FINDS_0518 
2025-07-13 05:44:42.666937: FINDS_0518, shape torch.Size([1, 534, 116, 110]), rank 0 
2025-07-13 05:44:45.224273: predicting FINDS_0536 
2025-07-13 05:44:45.226311: FINDS_0536, shape torch.Size([1, 410, 186, 107]), rank 0 
2025-07-13 05:44:48.079614: predicting FINDS_0541 
2025-07-13 05:44:48.081142: FINDS_0541, shape torch.Size([1, 497, 102, 92]), rank 0 
2025-07-13 05:44:49.036856: predicting FINDS_0555 
2025-07-13 05:44:49.039057: FINDS_0555, shape torch.Size([1, 492, 141, 106]), rank 0 
2025-07-13 05:44:50.953421: predicting FINDS_0574 
2025-07-13 05:44:50.955517: FINDS_0574, shape torch.Size([1, 439, 123, 94]), rank 0 
2025-07-13 05:44:52.869438: predicting FINDS_0577 
2025-07-13 05:44:52.870960: FINDS_0577, shape torch.Size([1, 506, 239, 112]), rank 0 
2025-07-13 05:44:56.704889: predicting FINDS_0591 
2025-07-13 05:44:56.707129: FINDS_0591, shape torch.Size([1, 502, 158, 101]), rank 0 
2025-07-13 05:44:58.607549: predicting FINDS_0594 
2025-07-13 05:44:58.609433: FINDS_0594, shape torch.Size([1, 437, 142, 129]), rank 0 
2025-07-13 05:45:01.475588: predicting FINDS_0610 
2025-07-13 05:45:01.477115: FINDS_0610, shape torch.Size([1, 507, 123, 96]), rank 0 
2025-07-13 05:45:03.399141: predicting FINDS_0621 
2025-07-13 05:45:03.401405: FINDS_0621, shape torch.Size([1, 447, 119, 92]), rank 0 
2025-07-13 05:45:05.322298: predicting FINDS_0630 
2025-07-13 05:45:05.324157: FINDS_0630, shape torch.Size([1, 476, 152, 93]), rank 0 
2025-07-13 05:45:07.245071: predicting FINDS_0643 
2025-07-13 05:45:07.246414: FINDS_0643, shape torch.Size([1, 464, 160, 97]), rank 0 
2025-07-13 05:45:09.158636: predicting FINDS_0650 
2025-07-13 05:45:09.160956: FINDS_0650, shape torch.Size([1, 459, 111, 85]), rank 0 
2025-07-13 05:45:10.116693: predicting FINDS_0654 
2025-07-13 05:45:10.118759: FINDS_0654, shape torch.Size([1, 477, 146, 119]), rank 0 
2025-07-13 05:45:12.032109: predicting FINDS_0658 
2025-07-13 05:45:12.034327: FINDS_0658, shape torch.Size([1, 541, 151, 112]), rank 0 
2025-07-13 05:45:14.590085: predicting FINDS_0683 
2025-07-13 05:45:14.592582: FINDS_0683, shape torch.Size([1, 512, 163, 105]), rank 0 
2025-07-13 05:45:16.504886: predicting FINDS_0690 
2025-07-13 05:45:16.507271: FINDS_0690, shape torch.Size([1, 450, 145, 124]), rank 0 
2025-07-13 05:45:19.395721: predicting FINDS_0704 
2025-07-13 05:45:19.397992: FINDS_0704, shape torch.Size([1, 405, 110, 90]), rank 0 
2025-07-13 05:45:20.363668: predicting FINDS_0706 
2025-07-13 05:45:20.368689: FINDS_0706, shape torch.Size([1, 405, 110, 90]), rank 0 
2025-07-13 05:45:21.314863: predicting FINDS_0712 
2025-07-13 05:45:21.317917: FINDS_0712, shape torch.Size([1, 425, 127, 113]), rank 0 
2025-07-13 05:45:23.238183: predicting FINDS_0722 
2025-07-13 05:45:23.240088: FINDS_0722, shape torch.Size([1, 425, 152, 112]), rank 0 
2025-07-13 05:45:25.165923: predicting FINDS_0730 
2025-07-13 05:45:25.168239: FINDS_0730, shape torch.Size([1, 493, 151, 125]), rank 0 
2025-07-13 05:45:28.048897: predicting FINDS_0745 
2025-07-13 05:45:28.050997: FINDS_0745, shape torch.Size([1, 353, 171, 74]), rank 0 
2025-07-13 05:45:31.487709: predicting FINDS_0750 
2025-07-13 05:45:31.489060: FINDS_0750, shape torch.Size([1, 447, 122, 98]), rank 0 
2025-07-13 05:45:33.390922: predicting FINDS_0760 
2025-07-13 05:45:33.392969: FINDS_0760, shape torch.Size([1, 585, 138, 115]), rank 0 
2025-07-13 05:45:35.915314: predicting FINDS_0764 
2025-07-13 05:45:35.917310: FINDS_0764, shape torch.Size([1, 468, 142, 112]), rank 0 
2025-07-13 05:45:39.730454: predicting FINDS_0772 
2025-07-13 05:45:39.731758: FINDS_0772, shape torch.Size([1, 450, 178, 121]), rank 0 
2025-07-13 05:45:43.965775: predicting FINDS_0775 
2025-07-13 05:45:43.967245: FINDS_0775, shape torch.Size([1, 450, 178, 121]), rank 0 
2025-07-13 05:45:48.218303: predicting FINDS_0789 
2025-07-13 05:45:48.220315: FINDS_0789, shape torch.Size([1, 457, 144, 95]), rank 0 
2025-07-13 05:45:50.109427: predicting FINDS_0805 
2025-07-13 05:45:50.111337: FINDS_0805, shape torch.Size([1, 572, 133, 105]), rank 0 
2025-07-13 05:45:52.652091: predicting FINDS_0817 
2025-07-13 05:45:52.654294: FINDS_0817, shape torch.Size([1, 427, 162, 100]), rank 0 
2025-07-13 05:45:54.534348: predicting FINDS_0849 
2025-07-13 05:45:54.536201: FINDS_0849, shape torch.Size([1, 463, 142, 108]), rank 0 
2025-07-13 05:45:56.432668: predicting FINDS_0855 
2025-07-13 05:45:56.435023: FINDS_0855, shape torch.Size([1, 409, 110, 79]), rank 0 
2025-07-13 05:46:02.344166: predicting FINDS_0861 
2025-07-13 05:46:02.345968: FINDS_0861, shape torch.Size([1, 458, 133, 112]), rank 0 
2025-07-13 05:46:04.219739: predicting FINDS_0868 
2025-07-13 05:46:04.221128: FINDS_0868, shape torch.Size([1, 511, 131, 99]), rank 0 
2025-07-13 05:46:06.081225: predicting FINDS_0870 
2025-07-13 05:46:06.083076: FINDS_0870, shape torch.Size([1, 511, 131, 99]), rank 0 
2025-07-13 05:46:07.950469: predicting FINDS_0873 
2025-07-13 05:46:07.952355: FINDS_0873, shape torch.Size([1, 453, 189, 102]), rank 0 
2025-07-13 05:46:10.762733: predicting FINDS_0880 
2025-07-13 05:46:10.765874: FINDS_0880, shape torch.Size([1, 551, 154, 128]), rank 0 
2025-07-13 05:46:14.549512: predicting FINDS_0883 
2025-07-13 05:46:14.551292: FINDS_0883, shape torch.Size([1, 551, 154, 128]), rank 0 
2025-07-13 05:46:59.517586: Validation complete 
2025-07-13 05:46:59.517709: Mean Validation Dice:  0.9829565471185853 
